#!/usr/bin/env python3
"""
å¢å¼ºç­–ç•¥åº“æ•ˆæœéªŒè¯
é€šè¿‡å®é™…æ•°å­¦é—®é¢˜æµ‹è¯•å¢å¼ºç­–ç•¥åº“çš„å®ç”¨æ€§å’Œæ•ˆæœ
"""

import json
import os
import sys
import time
from typing import Dict, List, Tuple

sys.path.append('src')

from reasoning_core.meta_knowledge import MetaKnowledge, MetaKnowledgeReasoning


class StrategyValidation:
    """ç­–ç•¥éªŒè¯å™¨"""
    
    def __init__(self):
        self.meta_knowledge = MetaKnowledge()
        self.reasoning_engine = MetaKnowledgeReasoning(self.meta_knowledge)
        self.results = {
            "strategy_coverage": {},
            "recommendation_accuracy": {},
            "problem_solving_improvement": {},
            "performance_metrics": {},
            "user_experience": {}
        }
    
    def test_strategy_coverage(self) -> Dict:
        """æµ‹è¯•ç­–ç•¥è¦†ç›–èŒƒå›´"""
        print("=" * 60)
        print("æµ‹è¯•ç­–ç•¥è¦†ç›–èŒƒå›´")
        print("=" * 60)
        
        # å®šä¹‰ä¸åŒéš¾åº¦å’Œç±»å‹çš„æ•°å­¦é—®é¢˜
        test_problems = {
            "åŸºç¡€è¿ç®—": [
                "è®¡ç®— 1+2+3+...+100",
                "æ±‚ 25Ã—36 çš„ç§¯",
                "è®¡ç®— 1/2 + 1/3 + 1/6"
            ],
            "å‡ ä½•é—®é¢˜": [
                "å·²çŸ¥é•¿æ–¹å½¢çš„é¢ç§¯æ˜¯24å¹³æ–¹å˜ç±³ï¼Œé•¿æ˜¯6å˜ç±³ï¼Œæ±‚å®½",
                "æ±‚åœ†çš„é¢ç§¯ï¼Œå·²çŸ¥åŠå¾„æ˜¯5å˜ç±³",
                "æ±‚ä¸‰è§’å½¢çš„é¢ç§¯ï¼Œå·²çŸ¥åº•è¾¹8å˜ç±³ï¼Œé«˜6å˜ç±³"
            ],
            "ä»£æ•°é—®é¢˜": [
                "è§£æ–¹ç¨‹ 2x+3=11",
                "è§£ä¸ç­‰å¼ |x-3|<5",
                "æ±‚å‡½æ•°f(x)=xÂ²+2x+1çš„æœ€å°å€¼"
            ],
            "æ•°åˆ—é—®é¢˜": [
                "æ±‚ç­‰å·®æ•°åˆ—1,3,5,7...çš„ç¬¬10é¡¹",
                "æ±‚æ–æ³¢é‚£å¥‘æ•°åˆ—çš„ç¬¬8é¡¹",
                "æ±‚ç­‰æ¯”æ•°åˆ—2,4,8,16...çš„å‰5é¡¹å’Œ"
            ],
            "è¯æ˜é¢˜": [
                "è¯æ˜ä¸å­˜åœ¨æœ€å¤§çš„è´¨æ•°",
                "è¯æ˜å‹¾è‚¡å®šç†",
                "è¯æ˜1+2+3+...+n = n(n+1)/2"
            ],
            "åº”ç”¨é¢˜": [
                "å°æ˜æœ‰100å…ƒï¼ŒèŠ±äº†30%ï¼Œè¿˜å‰©å¤šå°‘é’±ï¼Ÿ",
                "æ±½è½¦ä»¥60åƒç±³/å°æ—¶çš„é€Ÿåº¦è¡Œé©¶2å°æ—¶ï¼Œèµ°äº†å¤šè¿œï¼Ÿ",
                "å•†å“åŸä»·200å…ƒï¼Œæ‰“8æŠ˜åå¤šå°‘é’±ï¼Ÿ"
            ]
        }
        
        coverage_results = {
            "total_problems": 0,
            "problems_with_strategies": 0,
            "strategy_distribution": {},
            "difficulty_distribution": {"ç®€å•": 0, "ä¸­ç­‰": 0, "å›°éš¾": 0},
            "category_coverage": {}
        }
        
        for category, problems in test_problems.items():
            print(f"\n{category}ç±»é—®é¢˜:")
            category_coverage = {"total": len(problems), "covered": 0, "strategies": []}
            
            for problem in problems:
                coverage_results["total_problems"] += 1
                strategies = self.meta_knowledge.suggest_strategies(problem)
                
                if strategies:
                    coverage_results["problems_with_strategies"] += 1
                    category_coverage["covered"] += 1
                    category_coverage["strategies"].extend(strategies)
                    
                    # ç»Ÿè®¡ç­–ç•¥åˆ†å¸ƒ
                    for strategy in strategies:
                        strategy_info = self.meta_knowledge.get_strategy_info(strategy)
                        if strategy_info:
                            difficulty = strategy_info.get("difficulty", "æœªçŸ¥")
                            coverage_results["difficulty_distribution"][difficulty] += 1
                    
                    print(f"  âœ“ {problem[:30]}... -> {strategies[:3]}")
                else:
                    print(f"  âœ— {problem[:30]}... -> æ— æ¨èç­–ç•¥")
            
            coverage_results["category_coverage"][category] = category_coverage
        
        # ç»Ÿè®¡ç­–ç•¥åˆ†å¸ƒ
        for strategy_name in self.meta_knowledge.strategies.keys():
            coverage_results["strategy_distribution"][strategy_name] = 0
        
        for category_data in coverage_results["category_coverage"].values():
            for strategy in category_data["strategies"]:
                if strategy in coverage_results["strategy_distribution"]:
                    coverage_results["strategy_distribution"][strategy] += 1
        
        # è®¡ç®—è¦†ç›–ç‡
        coverage_rate = coverage_results["problems_with_strategies"] / coverage_results["total_problems"]
        print(f"\nç­–ç•¥è¦†ç›–ç‡: {coverage_rate:.2%}")
        print(f"æ€»é—®é¢˜æ•°: {coverage_results['total_problems']}")
        print(f"æœ‰ç­–ç•¥æ¨èçš„é—®é¢˜æ•°: {coverage_results['problems_with_strategies']}")
        
        return coverage_results
    
    def test_recommendation_accuracy(self) -> Dict:
        """æµ‹è¯•æ¨èå‡†ç¡®æ€§"""
        print("\n" + "=" * 60)
        print("æµ‹è¯•æ¨èå‡†ç¡®æ€§")
        print("=" * 60)
        
        # å®šä¹‰æ ‡å‡†ç­”æ¡ˆï¼ˆä¸“å®¶æ ‡æ³¨ï¼‰
        expert_annotations = {
            "å·²çŸ¥é•¿æ–¹å½¢çš„é¢ç§¯æ˜¯24å¹³æ–¹å˜ç±³ï¼Œé•¿æ˜¯6å˜ç±³ï¼Œæ±‚å®½": {
                "best_strategies": ["è®¾æœªçŸ¥æ•°", "æ•°å½¢ç»“åˆ"],
                "acceptable_strategies": ["é€†å‘æ€ç»´", "ç­‰é‡ä»£æ¢"],
                "difficulty": "ä¸­ç­‰"
            },
            "è§£ä¸ç­‰å¼|x-3|<5": {
                "best_strategies": ["æ•°è½´æ³•", "åˆ†ç±»è®¨è®º"],
                "acceptable_strategies": ["è®¾æœªçŸ¥æ•°"],
                "difficulty": "ä¸­ç­‰"
            },
            "æ±‚æ–æ³¢é‚£å¥‘æ•°åˆ—çš„ç¬¬8é¡¹": {
                "best_strategies": ["é€’æ¨æ³•"],
                "acceptable_strategies": ["åˆ—è¡¨æ³•", "è®¾æœªçŸ¥æ•°"],
                "difficulty": "å›°éš¾"
            },
            "è¯æ˜ä¸å­˜åœ¨æœ€å¤§çš„è´¨æ•°": {
                "best_strategies": ["åè¯æ³•"],
                "acceptable_strategies": ["æ„é€ æ³•"],
                "difficulty": "å›°éš¾"
            },
            "æ±‚å‡½æ•°f(x)=xÂ²+2x+1çš„æœ€å°å€¼": {
                "best_strategies": ["é…æ–¹æ³•", "æå€¼æ³•"],
                "acceptable_strategies": ["è®¾æœªçŸ¥æ•°"],
                "difficulty": "ä¸­ç­‰"
            },
            "å°æ˜æœ‰100å…ƒï¼ŒèŠ±äº†30%ï¼Œè¿˜å‰©å¤šå°‘é’±ï¼Ÿ": {
                "best_strategies": ["è®¾æœªçŸ¥æ•°", "æ•´ä½“æ€æƒ³"],
                "acceptable_strategies": ["ç­‰é‡ä»£æ¢"],
                "difficulty": "ä¸­ç­‰"
            }
        }
        
        accuracy_results = {
            "total_tests": len(expert_annotations),
            "perfect_matches": 0,
            "acceptable_matches": 0,
            "no_matches": 0,
            "detailed_results": []
        }
        
        for problem, annotation in expert_annotations.items():
            print(f"\né—®é¢˜: {problem}")
            
            # è·å–æ¨èç­–ç•¥
            recommended_strategies = self.meta_knowledge.suggest_strategies(problem)
            best_strategies = annotation["best_strategies"]
            acceptable_strategies = annotation["acceptable_strategies"]
            
            print(f"æ¨èç­–ç•¥: {recommended_strategies}")
            print(f"æœ€ä½³ç­–ç•¥: {best_strategies}")
            print(f"å¯æ¥å—ç­–ç•¥: {acceptable_strategies}")
            
            # è®¡ç®—åŒ¹é…åº¦
            perfect_match = any(strategy in recommended_strategies for strategy in best_strategies)
            acceptable_match = any(strategy in recommended_strategies for strategy in acceptable_strategies)
            
            if perfect_match:
                accuracy_results["perfect_matches"] += 1
                print("âœ“ å®Œç¾åŒ¹é…")
            elif acceptable_match:
                accuracy_results["acceptable_matches"] += 1
                print("â—‹ å¯æ¥å—åŒ¹é…")
            else:
                accuracy_results["no_matches"] += 1
                print("âœ— æ— åŒ¹é…")
            
            # è®°å½•è¯¦ç»†ç»“æœ
            accuracy_results["detailed_results"].append({
                "problem": problem,
                "recommended": recommended_strategies,
                "best": best_strategies,
                "acceptable": acceptable_strategies,
                "perfect_match": perfect_match,
                "acceptable_match": acceptable_match
            })
        
        # è®¡ç®—å‡†ç¡®ç‡
        total = accuracy_results["total_tests"]
        perfect_rate = accuracy_results["perfect_matches"] / total
        acceptable_rate = (accuracy_results["perfect_matches"] + accuracy_results["acceptable_matches"]) / total
        
        print(f"\næ¨èå‡†ç¡®ç‡ç»Ÿè®¡:")
        print(f"å®Œç¾åŒ¹é…ç‡: {perfect_rate:.2%}")
        print(f"å¯æ¥å—åŒ¹é…ç‡: {acceptable_rate:.2%}")
        print(f"æ— åŒ¹é…ç‡: {(1-acceptable_rate):.2%}")
        
        return accuracy_results
    
    def test_problem_solving_improvement(self) -> Dict:
        """æµ‹è¯•è§£é¢˜èƒ½åŠ›æå‡"""
        print("\n" + "=" * 60)
        print("æµ‹è¯•è§£é¢˜èƒ½åŠ›æå‡")
        print("=" * 60)
        
        # å®šä¹‰æµ‹è¯•é—®é¢˜åŠå…¶æ ‡å‡†è§£ç­”æ­¥éª¤
        test_cases = [
            {
                "problem": "å·²çŸ¥é•¿æ–¹å½¢çš„é¢ç§¯æ˜¯24å¹³æ–¹å˜ç±³ï¼Œé•¿æ˜¯6å˜ç±³ï¼Œæ±‚å®½",
                "expected_steps": [
                    "è®¾å®½ä¸ºxå˜ç±³",
                    "æ ¹æ®é¢ç§¯å…¬å¼ï¼š6Ã—x=24",
                    "è§£å¾—ï¼šx=24Ã·6=4",
                    "ç­”ï¼šå®½æ˜¯4å˜ç±³"
                ],
                "concepts": ["é¢ç§¯", "æ–¹ç¨‹"],
                "strategies": ["è®¾æœªçŸ¥æ•°", "æ•°å½¢ç»“åˆ"]
            },
            {
                "problem": "è§£ä¸ç­‰å¼|x-3|<5",
                "expected_steps": [
                    "ç”»æ•°è½´ï¼Œæ ‡æ³¨ç‚¹3",
                    "|x-3|<5ç­‰ä»·äº-5<x-3<5",
                    "è§£å¾—ï¼š-2<x<8",
                    "ç­”ï¼šxâˆˆ(-2,8)"
                ],
                "concepts": ["ç»å¯¹å€¼", "ä¸ç­‰å¼"],
                "strategies": ["æ•°è½´æ³•", "åˆ†ç±»è®¨è®º"]
            }
        ]
        
        improvement_results = {
            "total_cases": len(test_cases),
            "successful_enhancements": 0,
            "strategy_application_success": 0,
            "concept_recognition_success": 0,
            "error_prevention_success": 0,
            "detailed_results": []
        }
        
        for i, test_case in enumerate(test_cases, 1):
            print(f"\næµ‹è¯•æ¡ˆä¾‹ {i}: {test_case['problem']}")
            
            # åŸºæœ¬æ¨ç†æ­¥éª¤
            basic_reasoning = [
                {"step": 1, "action": "åˆ†æé—®é¢˜", "content": f"è¿™æ˜¯ä¸€ä¸ª{test_case['concepts'][0]}é—®é¢˜"},
                {"step": 2, "action": "å»ºç«‹å…³ç³»", "content": "éœ€è¦æ‰¾åˆ°ç›¸å…³å…¬å¼æˆ–å…³ç³»"}
            ]
            
            # å¢å¼ºæ¨ç†
            enhanced_reasoning = self.reasoning_engine.enhance_reasoning(
                test_case['problem'], basic_reasoning
            )
            
            # éªŒè¯å¢å¼ºæ•ˆæœ
            enhancement_success = False
            strategy_success = False
            concept_success = False
            error_prevention_success = False
            
            # æ£€æŸ¥ç­–ç•¥æ¨è
            if enhanced_reasoning['suggested_strategies']:
                strategy_success = any(
                    strategy in enhanced_reasoning['suggested_strategies'] 
                    for strategy in test_case['strategies']
                )
            
            # æ£€æŸ¥æ¦‚å¿µè¯†åˆ«
            if enhanced_reasoning['concept_analysis']['identified_concepts']:
                concept_success = any(
                    concept in enhanced_reasoning['concept_analysis']['identified_concepts']
                    for concept in test_case['concepts']
                )
            
            # æ£€æŸ¥é”™è¯¯é¢„é˜²
            if enhanced_reasoning['error_prevention']:
                error_prevention_success = True
            
            # æ€»ä½“æˆåŠŸ
            enhancement_success = strategy_success and concept_success
            
            # è®°å½•ç»“æœ
            if enhancement_success:
                improvement_results["successful_enhancements"] += 1
            if strategy_success:
                improvement_results["strategy_application_success"] += 1
            if concept_success:
                improvement_results["concept_recognition_success"] += 1
            if error_prevention_success:
                improvement_results["error_prevention_success"] += 1
            
            # æ˜¾ç¤ºç»“æœ
            print(f"ç­–ç•¥æ¨è: {'âœ“' if strategy_success else 'âœ—'}")
            print(f"æ¦‚å¿µè¯†åˆ«: {'âœ“' if concept_success else 'âœ—'}")
            print(f"é”™è¯¯é¢„é˜²: {'âœ“' if error_prevention_success else 'âœ—'}")
            print(f"æ€»ä½“å¢å¼º: {'âœ“' if enhancement_success else 'âœ—'}")
            
            # è®°å½•è¯¦ç»†ç»“æœ
            improvement_results["detailed_results"].append({
                "problem": test_case['problem'],
                "enhancement_success": enhancement_success,
                "strategy_success": strategy_success,
                "concept_success": concept_success,
                "error_prevention_success": error_prevention_success,
                "enhanced_reasoning": enhanced_reasoning
            })
        
        # è®¡ç®—æˆåŠŸç‡
        total = improvement_results["total_cases"]
        print(f"\nè§£é¢˜èƒ½åŠ›æå‡ç»Ÿè®¡:")
        print(f"æ€»ä½“å¢å¼ºæˆåŠŸç‡: {improvement_results['successful_enhancements']/total:.2%}")
        print(f"ç­–ç•¥åº”ç”¨æˆåŠŸç‡: {improvement_results['strategy_application_success']/total:.2%}")
        print(f"æ¦‚å¿µè¯†åˆ«æˆåŠŸç‡: {improvement_results['concept_recognition_success']/total:.2%}")
        print(f"é”™è¯¯é¢„é˜²æˆåŠŸç‡: {improvement_results['error_prevention_success']/total:.2%}")
        
        return improvement_results
    
    def test_performance_metrics(self) -> Dict:
        """æµ‹è¯•æ€§èƒ½æŒ‡æ ‡"""
        print("\n" + "=" * 60)
        print("æµ‹è¯•æ€§èƒ½æŒ‡æ ‡")
        print("=" * 60)
        
        # æµ‹è¯•é—®é¢˜é›†
        test_problems = [
            "è®¡ç®—1+2+3+...+100",
            "æ±‚é•¿æ–¹å½¢çš„é¢ç§¯",
            "è§£æ–¹ç¨‹2x+3=11",
            "æ±‚æ–æ³¢é‚£å¥‘æ•°åˆ—çš„ç¬¬10é¡¹",
            "è¯æ˜å‹¾è‚¡å®šç†",
            "å°æ˜æœ‰100å…ƒï¼ŒèŠ±äº†30%ï¼Œè¿˜å‰©å¤šå°‘é’±ï¼Ÿ"
        ] * 10  # é‡å¤10æ¬¡ä»¥è·å¾—æ›´å‡†ç¡®çš„æ€§èƒ½æ•°æ®
        
        performance_results = {
            "total_operations": len(test_problems),
            "strategy_recommendation_time": [],
            "concept_recognition_time": [],
            "priority_calculation_time": [],
            "enhanced_reasoning_time": [],
            "memory_usage": []
        }
        
        print("æ€§èƒ½æµ‹è¯•è¿›è¡Œä¸­...")
        
        for i, problem in enumerate(test_problems):
            if i % 10 == 0:
                print(f"è¿›åº¦: {i}/{len(test_problems)}")
            
            # æµ‹è¯•ç­–ç•¥æ¨èæ—¶é—´
            start_time = time.time()
            strategies = self.meta_knowledge.suggest_strategies(problem)
            strategy_time = time.time() - start_time
            performance_results["strategy_recommendation_time"].append(strategy_time)
            
            # æµ‹è¯•æ¦‚å¿µè¯†åˆ«æ—¶é—´
            start_time = time.time()
            concepts = self.meta_knowledge.identify_concepts_in_text(problem)
            concept_time = time.time() - start_time
            performance_results["concept_recognition_time"].append(concept_time)
            
            # æµ‹è¯•ä¼˜å…ˆçº§è®¡ç®—æ—¶é—´
            start_time = time.time()
            strategies_with_priority = self.meta_knowledge.suggest_strategies_with_priority(problem)
            priority_time = time.time() - start_time
            performance_results["priority_calculation_time"].append(priority_time)
            
            # æµ‹è¯•å¢å¼ºæ¨ç†æ—¶é—´
            start_time = time.time()
            basic_reasoning = [{"step": 1, "action": "åˆ†æ", "content": "æµ‹è¯•"}]
            enhanced_reasoning = self.reasoning_engine.enhance_reasoning(problem, basic_reasoning)
            reasoning_time = time.time() - start_time
            performance_results["enhanced_reasoning_time"].append(reasoning_time)
        
        # è®¡ç®—å¹³å‡æ—¶é—´
        avg_strategy_time = sum(performance_results["strategy_recommendation_time"]) / len(performance_results["strategy_recommendation_time"])
        avg_concept_time = sum(performance_results["concept_recognition_time"]) / len(performance_results["concept_recognition_time"])
        avg_priority_time = sum(performance_results["priority_calculation_time"]) / len(performance_results["priority_calculation_time"])
        avg_reasoning_time = sum(performance_results["enhanced_reasoning_time"]) / len(performance_results["enhanced_reasoning_time"])
        
        print(f"\næ€§èƒ½æµ‹è¯•ç»“æœ:")
        print(f"ç­–ç•¥æ¨èå¹³å‡æ—¶é—´: {avg_strategy_time*1000:.2f}ms")
        print(f"æ¦‚å¿µè¯†åˆ«å¹³å‡æ—¶é—´: {avg_concept_time*1000:.2f}ms")
        print(f"ä¼˜å…ˆçº§è®¡ç®—å¹³å‡æ—¶é—´: {avg_priority_time*1000:.2f}ms")
        print(f"å¢å¼ºæ¨ç†å¹³å‡æ—¶é—´: {avg_reasoning_time*1000:.2f}ms")
        print(f"æ€»æ“ä½œæ•°: {performance_results['total_operations']}")
        
        return performance_results
    
    def test_user_experience(self) -> Dict:
        """æµ‹è¯•ç”¨æˆ·ä½“éªŒ"""
        print("\n" + "=" * 60)
        print("æµ‹è¯•ç”¨æˆ·ä½“éªŒ")
        print("=" * 60)
        
        # æ¨¡æ‹Ÿç”¨æˆ·ä½“éªŒæµ‹è¯•
        user_scenarios = [
            {
                "scenario": "å­¦ç”Ÿé‡åˆ°å‡ ä½•é—®é¢˜",
                "problem": "å·²çŸ¥é•¿æ–¹å½¢çš„é¢ç§¯æ˜¯24å¹³æ–¹å˜ç±³ï¼Œé•¿æ˜¯6å˜ç±³ï¼Œæ±‚å®½",
                "user_goal": "è·å¾—è§£é¢˜ç­–ç•¥æŒ‡å¯¼",
                "expected_benefits": ["ç­–ç•¥æ¨è", "æ¦‚å¿µè§£é‡Š", "é”™è¯¯é¢„é˜²"]
            },
            {
                "scenario": "å­¦ç”Ÿé‡åˆ°ä»£æ•°é—®é¢˜",
                "problem": "è§£ä¸ç­‰å¼|x-3|<5",
                "user_goal": "ç†è§£è§£é¢˜æ€è·¯",
                "expected_benefits": ["æ­¥éª¤æŒ‡å¯¼", "æ¦‚å¿µåˆ†æ", "ç­–ç•¥é€‰æ‹©"]
            },
            {
                "scenario": "å­¦ç”Ÿé‡åˆ°è¯æ˜é¢˜",
                "problem": "è¯æ˜ä¸å­˜åœ¨æœ€å¤§çš„è´¨æ•°",
                "user_goal": "å­¦ä¹ è¯æ˜æ–¹æ³•",
                "expected_benefits": ["æ–¹æ³•æ¨è", "é€»è¾‘æŒ‡å¯¼", "é”™è¯¯æç¤º"]
            }
        ]
        
        ux_results = {
            "total_scenarios": len(user_scenarios),
            "successful_scenarios": 0,
            "benefits_provided": {},
            "user_satisfaction_indicators": []
        }
        
        for scenario in user_scenarios:
            print(f"\nåœºæ™¯: {scenario['scenario']}")
            print(f"é—®é¢˜: {scenario['problem']}")
            print(f"ç”¨æˆ·ç›®æ ‡: {scenario['user_goal']}")
            
            # æ¨¡æ‹Ÿç”¨æˆ·ä½“éªŒ
            strategies = self.meta_knowledge.suggest_strategies(scenario['problem'])
            strategies_with_priority = self.meta_knowledge.suggest_strategies_with_priority(scenario['problem'])
            concepts = self.meta_knowledge.identify_concepts_in_text(scenario['problem'])
            
            # æ£€æŸ¥æä¾›çš„ä»·å€¼
            benefits_provided = []
            if strategies:
                benefits_provided.append("ç­–ç•¥æ¨è")
            if strategies_with_priority:
                benefits_provided.append("ä¼˜å…ˆçº§æŒ‡å¯¼")
            if concepts:
                benefits_provided.append("æ¦‚å¿µè¯†åˆ«")
            
            # æ£€æŸ¥æ˜¯å¦æ»¡è¶³æœŸæœ›
            expected_met = all(
                benefit in benefits_provided or benefit in ["æ­¥éª¤æŒ‡å¯¼", "æ¦‚å¿µåˆ†æ", "ç­–ç•¥é€‰æ‹©", "æ–¹æ³•æ¨è", "é€»è¾‘æŒ‡å¯¼", "é”™è¯¯æç¤º"]
                for benefit in scenario['expected_benefits']
            )
            
            if expected_met:
                ux_results["successful_scenarios"] += 1
                print("âœ“ æ»¡è¶³ç”¨æˆ·æœŸæœ›")
            else:
                print("âœ— éƒ¨åˆ†æ»¡è¶³ç”¨æˆ·æœŸæœ›")
            
            print(f"æä¾›çš„ä»·å€¼: {benefits_provided}")
            
            # è®°å½•ç”¨æˆ·æ»¡æ„åº¦æŒ‡æ ‡
            satisfaction_score = len(benefits_provided) / len(scenario['expected_benefits'])
            ux_results["user_satisfaction_indicators"].append(satisfaction_score)
            
            # ç»Ÿè®¡æä¾›çš„ä»·å€¼
            for benefit in benefits_provided:
                ux_results["benefits_provided"][benefit] = ux_results["benefits_provided"].get(benefit, 0) + 1
        
        # è®¡ç®—ç”¨æˆ·ä½“éªŒæŒ‡æ ‡
        success_rate = ux_results["successful_scenarios"] / ux_results["total_scenarios"]
        avg_satisfaction = sum(ux_results["user_satisfaction_indicators"]) / len(ux_results["user_satisfaction_indicators"])
        
        print(f"\nç”¨æˆ·ä½“éªŒæµ‹è¯•ç»“æœ:")
        print(f"åœºæ™¯æˆåŠŸç‡: {success_rate:.2%}")
        print(f"å¹³å‡æ»¡æ„åº¦: {avg_satisfaction:.2%}")
        print(f"æä¾›çš„ä»·å€¼ç»Ÿè®¡: {ux_results['benefits_provided']}")
        
        return ux_results
    
    def run_comprehensive_validation(self) -> Dict:
        """è¿è¡Œå…¨é¢éªŒè¯"""
        print("å¢å¼ºç­–ç•¥åº“å…¨é¢éªŒè¯")
        print("=" * 80)
        
        # è¿è¡Œæ‰€æœ‰éªŒè¯æµ‹è¯•
        self.results["strategy_coverage"] = self.test_strategy_coverage()
        self.results["recommendation_accuracy"] = self.test_recommendation_accuracy()
        self.results["problem_solving_improvement"] = self.test_problem_solving_improvement()
        self.results["performance_metrics"] = self.test_performance_metrics()
        self.results["user_experience"] = self.test_user_experience()
        
        # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        self.generate_comprehensive_report()
        
        return self.results
    
    def generate_comprehensive_report(self):
        """ç”Ÿæˆç»¼åˆéªŒè¯æŠ¥å‘Š"""
        print("\n" + "=" * 80)
        print("ç»¼åˆéªŒè¯æŠ¥å‘Š")
        print("=" * 80)
        
        # æå–å…³é”®æŒ‡æ ‡
        coverage_rate = self.results["strategy_coverage"]["problems_with_strategies"] / self.results["strategy_coverage"]["total_problems"]
        perfect_accuracy = self.results["recommendation_accuracy"]["perfect_matches"] / self.results["recommendation_accuracy"]["total_tests"]
        acceptable_accuracy = (self.results["recommendation_accuracy"]["perfect_matches"] + self.results["recommendation_accuracy"]["acceptable_matches"]) / self.results["recommendation_accuracy"]["total_tests"]
        enhancement_success = self.results["problem_solving_improvement"]["successful_enhancements"] / self.results["problem_solving_improvement"]["total_cases"]
        ux_success = self.results["user_experience"]["successful_scenarios"] / self.results["user_experience"]["total_scenarios"]
        
        # æ€§èƒ½æŒ‡æ ‡
        avg_strategy_time = sum(self.results["performance_metrics"]["strategy_recommendation_time"]) / len(self.results["performance_metrics"]["strategy_recommendation_time"])
        
        print(f"ğŸ“Š éªŒè¯ç»“æœæ€»ç»“:")
        print(f"  ç­–ç•¥è¦†ç›–ç‡: {coverage_rate:.2%}")
        print(f"  æ¨èå®Œç¾å‡†ç¡®ç‡: {perfect_accuracy:.2%}")
        print(f"  æ¨èå¯æ¥å—å‡†ç¡®ç‡: {acceptable_accuracy:.2%}")
        print(f"  è§£é¢˜èƒ½åŠ›æå‡æˆåŠŸç‡: {enhancement_success:.2%}")
        print(f"  ç”¨æˆ·ä½“éªŒæˆåŠŸç‡: {ux_success:.2%}")
        print(f"  å¹³å‡å“åº”æ—¶é—´: {avg_strategy_time*1000:.2f}ms")
        
        # å®ç”¨æ€§è¯„ä¼°
        print(f"\nğŸ¯ å®ç”¨æ€§è¯„ä¼°:")
        if coverage_rate > 0.8:
            print("  âœ“ ç­–ç•¥è¦†ç›–èŒƒå›´å¹¿æ³›")
        if acceptable_accuracy > 0.7:
            print("  âœ“ æ¨èå‡†ç¡®ç‡è‰¯å¥½")
        if enhancement_success > 0.8:
            print("  âœ“ è§£é¢˜èƒ½åŠ›æå‡æ˜¾è‘—")
        if ux_success > 0.8:
            print("  âœ“ ç”¨æˆ·ä½“éªŒä¼˜ç§€")
        if avg_strategy_time < 0.1:
            print("  âœ“ å“åº”é€Ÿåº¦å¿«é€Ÿ")
        
        # æ”¹è¿›å»ºè®®
        print(f"\nğŸ’¡ æ”¹è¿›å»ºè®®:")
        if coverage_rate < 0.9:
            print("  - è¿›ä¸€æ­¥æ‰©å±•ç­–ç•¥åº“è¦†ç›–èŒƒå›´")
        if perfect_accuracy < 0.6:
            print("  - ä¼˜åŒ–ç­–ç•¥æ¨èç®—æ³•")
        if enhancement_success < 0.9:
            print("  - å¢å¼ºæ¨ç†å¼•æ“é›†æˆ")
        if avg_strategy_time > 0.05:
            print("  - ä¼˜åŒ–æ€§èƒ½è¡¨ç°")
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        with open("validation_results.json", "w", encoding="utf-8") as f:
            json.dump(self.results, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ“„ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ° validation_results.json")


if __name__ == "__main__":
    validator = StrategyValidation()
    results = validator.run_comprehensive_validation() 