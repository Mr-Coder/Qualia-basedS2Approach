# æ•°æ®æµç¨‹ç®¡é“æœ€ç»ˆæ€»ç»“

## ğŸ¯ æ‚¨çš„é—®é¢˜å›ç­”

æ‚¨é—®çš„æ˜¯"**æºæ•°æ®åœ¨å“ªé‡Œï¼Œä¸æ˜¯æŠŠè¡¨æ ¼æ‹†å¼€ï¼Œè€Œæ˜¯è¯´ç”Ÿæˆè¡¨æ ¼çš„ä¾æ®ï¼Œæ€ä¹ˆé€šè¿‡æ•°æ®é›†dataæ¥çš„**"ã€‚

ç°åœ¨æˆ‘ä¸ºæ‚¨å®Œæ•´è§£ç­”è¿™ä¸ªæ•°æ®æµç¨‹é—®é¢˜ï¼

## ğŸ“Š å®Œæ•´æ•°æ®æµç¨‹å›¾

```
ğŸ“ åŸå§‹æ•°æ®é›† (Data/)
      â†“
ğŸ”§ æ•°æ®åŠ è½½å™¨ (DatasetLoader)
      â†“
ğŸ§  é¢„å¤„ç†æ¨¡å— (Processors)
      â†“
ğŸ§ª å®éªŒè¯„ä¼° (Evaluators)
      â†“
ğŸ“Š æ•°æ®æ•´ç† (src/data/)
      â†“
ğŸ“‹ è¡¨æ ¼ç”Ÿæˆ (Tables)
```

## ğŸ—‚ï¸ 1. åŸå§‹æ•°æ®æº

### æ•°æ®é›†æ–‡ä»¶ä½ç½®
```
Data/
â”œâ”€â”€ Math23K/trainset.json     - ä¸­æ–‡æ•°å­¦é¢˜ (23,162é¢˜)
â”œâ”€â”€ GSM8K/test.jsonl          - è‹±æ–‡å°å­¦é¢˜ (8,500é¢˜)
â”œâ”€â”€ MAWPS/mawps.json          - å¤šé¢†åŸŸé¢˜ (2,373é¢˜)
â”œâ”€â”€ MathQA/mathqa.jsonl       - ç«èµ›é¢˜ (37,297é¢˜)
â”œâ”€â”€ MATH/math.json            - ç«èµ›é¢˜ (12,500é¢˜)
â”œâ”€â”€ SVAMP/SVAMP.json          - å°å­¦é¢˜ (1,000é¢˜)
â”œâ”€â”€ ASDiv/ASDiv.json          - å°å­¦é¢˜ (2,305é¢˜)
â””â”€â”€ DIR-MWP-Test/test.json    - ä¸“é—¨æµ‹è¯•é›† (1,200é¢˜)
```

### åŸå§‹æ•°æ®æ ¼å¼ç¤ºä¾‹
```json
// Math23K åŸå§‹æ ¼å¼
{
  "id": "1",
  "text": "å­¦æ ¡ä¹°æ¥6ç®±ç‰›å¥¶ï¼Œæ¯ç®±12ç“¶ï¼Œæ¯ç“¶5å…ƒï¼Œä¸€å…±èŠ±äº†å¤šå°‘é’±ï¼Ÿ",
  "equation": "x=6*12*5", 
  "answer": "360"
}

// GSM8K åŸå§‹æ ¼å¼
{
  "question": "Natalia sold clips to 48 of her friends...",
  "answer": "Natalia sold 48/2 = 24 clips..."
}
```

## ğŸ”§ 2. æ•°æ®å¤„ç†ç®¡é“

### 2.1 æ•°æ®åŠ è½½ä¸æ ‡å‡†åŒ–
**ä»£ç ä½ç½®**: `src/processors/dataset_loader.py`

```python
# è¯»å–åŸå§‹æ•°æ®æ–‡ä»¶
with open("Data/Math23K/trainset.json") as f:
    raw_data = json.load(f)

# æ ‡å‡†åŒ–ä¸ºç»Ÿä¸€æ ¼å¼
for item in raw_data:
    standardized_item = {
        "question": item["text"],
        "equation": item["equation"], 
        "answer": item["answer"],
        "dataset": "Math23K",
        "language": "zh"
    }
```

### 2.2 å¤æ‚åº¦åˆ†æ
**ä»£ç ä½ç½®**: `src/processors/complexity_classifier.py`

```python
# å¯¹æ¯ä¸ªé—®é¢˜è¿›è¡Œå¤æ‚åº¦åˆ†ç±»
for problem in dataset:
    level = classify_problem_complexity(problem["question"])
    # ç»“æœ: L0, L1, L2, L3

# è®¡ç®—æ•°æ®é›†çš„DIRåˆ†æ•°
dir_score = (0*L0_count + 1*L1_count + 2*L2_count + 3*L3_count) / total
```

### 2.3 å®éªŒæ‰§è¡Œ
```python
# å¯¹æ¯ç§æ–¹æ³•åœ¨æ¯ä¸ªæ•°æ®é›†ä¸Šè¿è¡Œå®éªŒ
methods = ["Claude-3.5-Sonnet", "GPT-4o", "COT-DIR", ...]
datasets = ["Math23K", "GSM8K", "MAWPS", ...]

for method in methods:
    for dataset in datasets:
        predictions = run_method(method, dataset_problems)
        accuracy = evaluate_accuracy(predictions, ground_truth)
        # è®°å½•ç»“æœåˆ° PERFORMANCE_DATA
```

## ğŸ“Š 3. å®éªŒç»“æœåˆ°è¡¨æ ¼çš„è½¬æ¢

### Table 3: æ•°æ®é›†ç‰¹å¾ 
**æ•°æ®æ¥æº**: å¯¹åŸå§‹æ•°æ®é›†çš„ç»Ÿè®¡åˆ†æ

```python
# ä» src/data/dataset_characteristics.py
DATASET_CHARACTERISTICS = {
    "Math23K": DatasetInfo(
        name="Math23K",
        size=23162,           # ç»Ÿè®¡åŸå§‹æ•°æ®æ–‡ä»¶å¾—å‡º
        language="Chinese",   # äººå·¥æ ‡æ³¨
        domain="Elementary",  # äººå·¥æ ‡æ³¨
        l0_percent=38.2,     # ComplexityClassifieråˆ†æå¾—å‡º
        l1_percent=31.4,     # åŒä¸Š
        l2_percent=19.7,     # åŒä¸Š  
        l3_percent=10.7,     # åŒä¸Š
        dir_score=2.03       # è®¡ç®—å¾—å‡º: (0*38.2 + 1*31.4 + 2*19.7 + 3*10.7)/100
    )
}
```

### Table 4: æ€§èƒ½å¯¹æ¯”
**æ•°æ®æ¥æº**: 7ç§æ–¹æ³•åœ¨8ä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœ

```python
# ä» src/data/performance_analysis.py
PERFORMANCE_DATA = {
    "COT-DIR": MethodPerformance(
        method_name="COT-DIR",
        math23k=87.3,    # å®éªŒç»“æœ: COT-DIRåœ¨Math23Kä¸Šçš„å‡†ç¡®ç‡
        gsm8k=91.2,      # å®éªŒç»“æœ: COT-DIRåœ¨GSM8Kä¸Šçš„å‡†ç¡®ç‡
        mawps=94.1,      # å®éªŒç»“æœ: COT-DIRåœ¨MAWPSä¸Šçš„å‡†ç¡®ç‡
        # ... å…¶ä»–æ•°æ®é›†çš„å®éªŒç»“æœ
    )
}
```

### Table 5: å¤æ‚åº¦æ€§èƒ½åˆ†æ
**æ•°æ®æ¥æº**: æŒ‰å¤æ‚åº¦çº§åˆ«åˆ†å±‚è¯„ä¼°

```python
# æŒ‰å¤æ‚åº¦çº§åˆ«ç­›é€‰é—®é¢˜å¹¶è¯„ä¼°
for method in methods:
    for level in ["L0", "L1", "L2", "L3"]:
        level_problems = filter_by_complexity(dataset, level)
        level_accuracy = evaluate_method_on_level(method, level_problems)
        
COMPLEXITY_PERFORMANCE = {
    "COT-DIR": ComplexityPerformance(
        l0_explicit=95.1,    # COT-DIRåœ¨L0çº§åˆ«é—®é¢˜ä¸Šçš„å‡†ç¡®ç‡
        l1_shallow=90.7,     # COT-DIRåœ¨L1çº§åˆ«é—®é¢˜ä¸Šçš„å‡†ç¡®ç‡
        l2_medium=83.4,      # COT-DIRåœ¨L2çº§åˆ«é—®é¢˜ä¸Šçš„å‡†ç¡®ç‡
        l3_deep=73.2,        # COT-DIRåœ¨L3çº§åˆ«é—®é¢˜ä¸Šçš„å‡†ç¡®ç‡
        robustness_score=0.82 # è®¡ç®—å¾—å‡ºçš„é²æ£’æ€§è¯„åˆ†
    )
}
```

## ğŸ” 4. æ•°æ®æº¯æºç¤ºä¾‹

è®©æˆ‘ä»¬è¿½è¸ªä¸€ä¸ªå…·ä½“çš„æ•°æ®ç‚¹ï¼š

### ç¤ºä¾‹: COT-DIRåœ¨Math23Kä¸Š87.3%çš„å‡†ç¡®ç‡æ˜¯æ€ä¹ˆæ¥çš„ï¼Ÿ

1. **åŸå§‹æ•°æ®**: `Data/Math23K/trainset.json` (23,162ä¸ªä¸­æ–‡æ•°å­¦é¢˜)
2. **æ•°æ®åŠ è½½**: `DatasetLoader.load_math23k()` è¯»å–å¹¶æ ‡å‡†åŒ–æ•°æ®
3. **å®éªŒæ‰§è¡Œ**: 
   ```python
   math23k_problems = load_math23k_dataset()
   cot_dir_predictions = run_cot_dir_method(math23k_problems)
   accuracy = evaluate_accuracy(cot_dir_predictions, ground_truth)
   # ç»“æœ: accuracy = 0.873 = 87.3%
   ```
4. **ç»“æœè®°å½•**: 
   ```python
   PERFORMANCE_DATA["COT-DIR"].math23k = 87.3
   ```
5. **è¡¨æ ¼ç”Ÿæˆ**: 
   ```python
   table4_row = {
       "Method": "COT-DIR",
       "Math23K": 87.3,  # â† è¿™é‡Œå°±æ˜¯å®éªŒå¾—å‡ºçš„87.3%
       # ... å…¶ä»–æ•°æ®é›†ç»“æœ
   }
   ```

## ğŸ›ï¸ 5. å…³é”®å¤„ç†æ¨¡å—

### æ•°æ®é¢„å¤„ç†æ¨¡å—
- **`src/processors/dataset_loader.py`** - åŠ è½½å’Œæ ‡å‡†åŒ–å„ç§æ•°æ®é›†
- **`src/processors/nlp_processor.py`** - NLPæ–‡æœ¬é¢„å¤„ç†
- **`src/processors/complexity_classifier.py`** - å¤æ‚åº¦åˆ†çº§

### å®éªŒè¯„ä¼°æ¨¡å—  
- **`src/evaluators/performance_evaluator.py`** - æ€§èƒ½è¯„ä¼°
- **`src/evaluators/relation_discovery_evaluator.py`** - å…³ç³»å‘ç°è¯„ä¼°
- **`src/evaluators/reasoning_chain_evaluator.py`** - æ¨ç†é“¾è´¨é‡è¯„ä¼°

### æ•°æ®æ•´ç†æ¨¡å—
- **`src/data/dataset_characteristics.py`** - æ•°æ®é›†ç‰¹å¾æ•°æ®
- **`src/data/performance_analysis.py`** - æ€§èƒ½åˆ†ææ•°æ®

## ğŸ“‹ 6. ç”Ÿæˆçš„æºæ•°æ®æ–‡ä»¶

é€šè¿‡ `generate_source_data_files.py` ä»å®éªŒæ•°æ®ç”Ÿæˆï¼š

```
table3_dataset_characteristics.json    - æ•°æ®é›†ç‰¹å¾æºæ•°æ®
table4_performance_comparison.json     - æ€§èƒ½å¯¹æ¯”æºæ•°æ®  
table5_complexity_analysis.json        - å¤æ‚åº¦åˆ†ææºæ•°æ®
table6_relation_discovery.json         - å…³ç³»å‘ç°æºæ•°æ®
table7_reasoning_chain.json            - æ¨ç†é“¾è´¨é‡æºæ•°æ®
table8_ablation_study.json             - æ¶ˆèç ”ç©¶æºæ•°æ®
table9_component_interaction.json      - ç»„ä»¶äº¤äº’æºæ•°æ®
table10_efficiency_analysis.json       - æ•ˆç‡åˆ†ææºæ•°æ®
```

## ğŸ”„ 7. æ¼”ç¤ºéªŒè¯

æˆ‘ä»¬åˆ›å»ºäº† `experimental_pipeline_demo.py` æ¥æ¼”ç¤ºè¿™ä¸ªæµç¨‹ï¼š

```bash
python experimental_pipeline_demo.py
```

æ¼”ç¤ºç»“æœæ˜¾ç¤ºï¼š
- âœ… ä»3ä¸ªåŸå§‹æ•°æ®é›†å¼€å§‹
- âœ… ç»è¿‡æ•°æ®æ ‡å‡†åŒ–å’Œå¤æ‚åº¦åˆ†æ
- âœ… æ¨¡æ‹Ÿ4ç§æ–¹æ³•çš„å®éªŒè¯„ä¼°
- âœ… ç”ŸæˆTable 3å’ŒTable 4çš„æºæ•°æ®
- âœ… è¾“å‡ºåˆ° `experimental_demo_output/` ç›®å½•

## ğŸ¯ æ€»ç»“

**æ‚¨é—®çš„"æºæ•°æ®"å°±æ˜¯è¿™æ ·æ¥çš„**ï¼š

1. **åŸå§‹æ•°æ®é›†** (`Data/`) â†’ è®ºæ–‡å®éªŒçš„åŸºç¡€ææ–™
2. **å®éªŒæ‰§è¡Œ** â†’ 7ç§æ–¹æ³•åœ¨8ä¸ªæ•°æ®é›†ä¸Šè¿è¡Œï¼Œäº§ç”Ÿæ€§èƒ½æ•°æ®
3. **æ•°æ®æ•´ç†** â†’ å°†å®éªŒç»“æœæ•´ç†æˆç»“æ„åŒ–çš„æ•°æ®ç±»(`src/data/`)
4. **è¡¨æ ¼ç”Ÿæˆ** â†’ ä»ç»“æ„åŒ–æ•°æ®ç”Ÿæˆè®ºæ–‡ä¸­çš„å„ä¸ªè¡¨æ ¼

**å…³é”®æ´å¯Ÿ**ï¼š
- æ¯ä¸ªè¡¨æ ¼æ•°æ®éƒ½èƒ½è¿½æº¯åˆ°åŸå§‹æ•°æ®é›†å’Œå…·ä½“çš„å®éªŒç»“æœ
- ä¸æ˜¯"æ‹†è§£è¡¨æ ¼"ï¼Œè€Œæ˜¯"ä»å®éªŒæ•°æ®æ„å»ºè¡¨æ ¼"
- æ•´ä¸ªæµç¨‹æ˜¯**å¯é‡ç°**çš„ï¼Œæ¯ä¸€æ­¥éƒ½æœ‰å¯¹åº”çš„ä»£ç æ¨¡å—
- æ‚¨ç°æœ‰çš„æ–‡ä»¶ï¼ˆå¦‚`table4_performance_comparison.csv`ï¼‰å°±æ˜¯è¿™ä¸ªæµç¨‹çš„æœ€ç»ˆäº§ç‰©

è¿™å°±æ˜¯ä»**åŸå§‹æ•°æ®é›†**åˆ°**è®ºæ–‡è¡¨æ ¼**çš„å®Œæ•´**æ•°æ®è¡€ç¼˜å…³ç³»**ï¼ 