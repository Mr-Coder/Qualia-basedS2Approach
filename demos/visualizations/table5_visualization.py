#!/usr/bin/env python3
"""
Table 5 æ•°æ®å¯è§†åŒ–å·¥å…·
ç”ŸæˆCOT-DIRæ¡†æ¶æ€§èƒ½éªŒè¯çš„ç¾è§‚è¡¨æ ¼å’Œå›¾è¡¨
"""

import json
from typing import Any, Dict

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns


class Table5Visualizer:
    """Table 5 å¯è§†åŒ–å™¨"""
    
    def __init__(self):
        # è®¾ç½®ä¸­æ–‡å­—ä½“å’Œæ ·å¼
        plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        sns.set_style("whitegrid")
        sns.set_palette("husl")
    
    def create_table5_dataframe(self, table_data: Dict[str, Any]) -> pd.DataFrame:
        """åˆ›å»ºTable 5çš„DataFrame"""
        
        # è½¬æ¢æ•°æ®ä¸ºDataFrameæ ¼å¼
        rows = []
        for method, data in table_data.items():
            row = {
                'Method': method,
                'L0': float(data['L0'].rstrip('%')) / 100,
                'L1': float(data['L1'].rstrip('%')) / 100,
                'L2': float(data['L2'].rstrip('%')) / 100,
                'L3': float(data['L3'].rstrip('%')) / 100,
                'Overall': float(data['Overall'].rstrip('%')) / 100
            }
            rows.append(row)
        
        df = pd.DataFrame(rows)
        df = df.set_index('Method')
        
        return df
    
    def print_formatted_table5(self, table_data: Dict[str, Any]):
        """æ‰“å°æ ¼å¼åŒ–çš„Table 5"""
        
        print("\n" + "="*85)
        print("Table 5: Framework Performance Validation (n=200)")
        print("="*85)
        
        # è¡¨å¤´
        print(f"{'Method':<20} {'L0':<10} {'L1':<10} {'L2':<10} {'L3':<10} {'Overall':<10}")
        print("-" * 85)
        
        # æŒ‰æ€§èƒ½æ’åº
        sorted_methods = sorted(table_data.items(), 
                              key=lambda x: x[1]['raw_overall'], 
                              reverse=True)
        
        # æ•°æ®è¡Œ
        for method, data in sorted_methods:
            print(f"{method:<20} {data['L0']:<10} {data['L1']:<10} {data['L2']:<10} {data['L3']:<10} {data['Overall']:<10}")
        
        print("="*85)
    
    def plot_performance_heatmap(self, df: pd.DataFrame, save_path: str = None):
        """ç»˜åˆ¶æ€§èƒ½çƒ­åŠ›å›¾"""
        
        fig, ax = plt.subplots(figsize=(12, 8))
        
        # åˆ›å»ºçƒ­åŠ›å›¾
        sns.heatmap(df, 
                   annot=True, 
                   fmt='.1%', 
                   cmap='YlOrRd',
                   cbar_kws={'label': 'Accuracy'},
                   linewidths=0.5,
                   ax=ax)
        
        ax.set_title('Table 5: Framework Performance Validation Heatmap', 
                    fontsize=16, fontweight='bold', pad=20)
        ax.set_xlabel('Complexity Levels', fontsize=12, fontweight='bold')
        ax.set_ylabel('Methods', fontsize=12, fontweight='bold')
        
        # æ—‹è½¬xè½´æ ‡ç­¾
        plt.xticks(rotation=0)
        plt.yticks(rotation=0)
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ’¾ çƒ­åŠ›å›¾å·²ä¿å­˜åˆ°: {save_path}")
        
        plt.show()
    
    def plot_complexity_degradation(self, df: pd.DataFrame, save_path: str = None):
        """ç»˜åˆ¶å¤æ‚åº¦æ€§èƒ½é€€åŒ–å›¾"""
        
        fig, ax = plt.subplots(figsize=(12, 8))
        
        # é€‰æ‹©å…³é”®æ–¹æ³•è¿›è¡Œæ¯”è¾ƒ
        key_methods = ['Basic Symbolic', 'GPT-3.5 + CoT', 'IRD + MLR', 'Full COT-DIR']
        complexity_levels = ['L0', 'L1', 'L2', 'L3']
        
        for method in key_methods:
            if method in df.index:
                values = [df.loc[method, level] for level in complexity_levels]
                ax.plot(complexity_levels, values, 
                       marker='o', linewidth=2.5, markersize=8, 
                       label=method)
        
        ax.set_title('Performance Degradation Across Complexity Levels', 
                    fontsize=16, fontweight='bold')
        ax.set_xlabel('Complexity Level', fontsize=12, fontweight='bold')
        ax.set_ylabel('Accuracy', fontsize=12, fontweight='bold')
        ax.set_ylim(0, 1)
        ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: '{:.0%}'.format(y)))
        
        ax.legend(loc='upper right', fontsize=10)
        ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ’¾ å¤æ‚åº¦é€€åŒ–å›¾å·²ä¿å­˜åˆ°: {save_path}")
        
        plt.show()
    
    def plot_component_comparison(self, df: pd.DataFrame, save_path: str = None):
        """ç»˜åˆ¶ç»„ä»¶å¯¹æ¯”å›¾"""
        
        fig, ax = plt.subplots(figsize=(14, 8))
        
        # ç»„ä»¶æ–¹æ³•åˆ†ç»„
        single_components = ['IRD only', 'MLR only', 'CV only']
        combinations = ['IRD + MLR', 'Full COT-DIR']
        baselines = ['Basic Symbolic', 'Simple Neural', 'GPT-3.5 + CoT']
        
        # è®¾ç½®ä½ç½®
        x_pos = np.arange(len(df.index))
        bar_width = 0.6
        
        # ç»˜åˆ¶æ¡å½¢å›¾
        bars = ax.bar(x_pos, df['Overall'], 
                     width=bar_width, alpha=0.8)
        
        # æ ¹æ®æ–¹æ³•ç±»å‹ç€è‰²
        colors = []
        for method in df.index:
            if method in baselines:
                colors.append('#FF6B6B')  # çº¢è‰² - åŸºå‡†æ–¹æ³•
            elif method in single_components:
                colors.append('#4ECDC4')  # é’è‰² - å•ç»„ä»¶
            elif method in combinations:
                colors.append('#45B7D1')  # è“è‰² - ç»„åˆæ–¹æ³•
            else:
                colors.append('#96CEB4')  # ç»¿è‰² - å…¶ä»–
        
        for bar, color in zip(bars, colors):
            bar.set_color(color)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, bar in enumerate(bars):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                   f'{height:.1%}', ha='center', va='bottom', fontweight='bold')
        
        ax.set_title('Framework Component Performance Comparison', 
                    fontsize=16, fontweight='bold')
        ax.set_xlabel('Methods', fontsize=12, fontweight='bold')
        ax.set_ylabel('Overall Accuracy', fontsize=12, fontweight='bold')
        ax.set_ylim(0, 1)
        ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: '{:.0%}'.format(y)))
        
        # è®¾ç½®xè½´æ ‡ç­¾
        ax.set_xticks(x_pos)
        ax.set_xticklabels(df.index, rotation=45, ha='right')
        
        # æ·»åŠ å›¾ä¾‹
        legend_elements = [
            plt.Rectangle((0,0),1,1, facecolor='#FF6B6B', alpha=0.8, label='Baseline Methods'),
            plt.Rectangle((0,0),1,1, facecolor='#4ECDC4', alpha=0.8, label='Single Components'),
            plt.Rectangle((0,0),1,1, facecolor='#45B7D1', alpha=0.8, label='Combined Methods')
        ]
        ax.legend(handles=legend_elements, loc='upper left')
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ’¾ ç»„ä»¶å¯¹æ¯”å›¾å·²ä¿å­˜åˆ°: {save_path}")
        
        plt.show()
    
    def plot_synergy_analysis(self, df: pd.DataFrame, save_path: str = None):
        """ç»˜åˆ¶ååŒæ•ˆåº”åˆ†æå›¾"""
        
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))
        
        # å·¦å›¾: ç»„ä»¶ç´¯ç§¯æ•ˆåº”
        cumulative_methods = ['IRD only', 'MLR only', 'IRD + MLR', 'Full COT-DIR']
        cumulative_data = []
        
        for method in cumulative_methods:
            if method in df.index:
                cumulative_data.append(df.loc[method, 'Overall'])
        
        ax1.plot(range(len(cumulative_data)), cumulative_data, 
                marker='o', linewidth=3, markersize=10, color='#45B7D1')
        
        for i, val in enumerate(cumulative_data):
            ax1.annotate(f'{val:.1%}', (i, val), 
                        textcoords="offset points", xytext=(0,10), ha='center',
                        fontweight='bold', fontsize=11)
        
        ax1.set_title('Component Synergy Effect', fontsize=14, fontweight='bold')
        ax1.set_xlabel('Component Combination', fontsize=12)
        ax1.set_ylabel('Overall Accuracy', fontsize=12)
        ax1.set_xticks(range(len(cumulative_methods)))
        ax1.set_xticklabels([m.replace(' ', '\n') for m in cumulative_methods], fontsize=10)
        ax1.yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: '{:.0%}'.format(y)))
        ax1.grid(True, alpha=0.3)
        
        # å³å›¾: L3æ·±åº¦æ¨ç†æ€§èƒ½å¯¹æ¯”
        l3_methods = ['Basic Symbolic', 'Simple Neural', 'GPT-3.5 + CoT', 'Full COT-DIR']
        l3_values = []
        
        for method in l3_methods:
            if method in df.index:
                l3_values.append(df.loc[method, 'L3'])
        
        bars = ax2.bar(range(len(l3_values)), l3_values, 
                      color=['#FF6B6B', '#FF6B6B', '#FFD93D', '#45B7D1'],
                      alpha=0.8)
        
        for i, bar in enumerate(bars):
            height = bar.get_height()
            ax2.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                    f'{height:.1%}', ha='center', va='bottom', fontweight='bold')
        
        ax2.set_title('L3 Deep Reasoning Performance', fontsize=14, fontweight='bold')
        ax2.set_xlabel('Methods', fontsize=12)
        ax2.set_ylabel('L3 Accuracy', fontsize=12)
        ax2.set_xticks(range(len(l3_methods)))
        ax2.set_xticklabels([m.replace(' ', '\n') for m in l3_methods], fontsize=10)
        ax2.yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: '{:.0%}'.format(y)))
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ’¾ ååŒæ•ˆåº”åˆ†æå›¾å·²ä¿å­˜åˆ°: {save_path}")
        
        plt.show()
    
    def generate_comprehensive_report(self, evaluation_report: Dict[str, Any], output_dir: str = "."):
        """ç”Ÿæˆç»¼åˆæŠ¥å‘Š"""
        
        table_data = evaluation_report['table5_results']
        analysis = evaluation_report['analysis']
        
        # åˆ›å»ºDataFrame
        df = self.create_table5_dataframe(table_data)
        
        print("ğŸ“Š ç”ŸæˆTable 5ç»¼åˆå¯è§†åŒ–æŠ¥å‘Š")
        
        # 1. æ‰“å°æ ¼å¼åŒ–è¡¨æ ¼
        self.print_formatted_table5(table_data)
        
        # 2. ç”Ÿæˆçƒ­åŠ›å›¾
        print("\nğŸ¨ ç”Ÿæˆæ€§èƒ½çƒ­åŠ›å›¾...")
        self.plot_performance_heatmap(df, f"{output_dir}/table5_heatmap.png")
        
        # 3. ç”Ÿæˆå¤æ‚åº¦é€€åŒ–å›¾
        print("\nğŸ“‰ ç”Ÿæˆå¤æ‚åº¦é€€åŒ–åˆ†æå›¾...")
        self.plot_complexity_degradation(df, f"{output_dir}/complexity_degradation.png")
        
        # 4. ç”Ÿæˆç»„ä»¶å¯¹æ¯”å›¾
        print("\nğŸ”§ ç”Ÿæˆç»„ä»¶æ€§èƒ½å¯¹æ¯”å›¾...")
        self.plot_component_comparison(df, f"{output_dir}/component_comparison.png")
        
        # 5. ç”ŸæˆååŒæ•ˆåº”åˆ†æå›¾
        print("\nğŸ¤ ç”ŸæˆååŒæ•ˆåº”åˆ†æå›¾...")
        self.plot_synergy_analysis(df, f"{output_dir}/synergy_analysis.png")
        
        # 6. æ‰“å°å…³é”®å‘ç°
        print("\nğŸ” å…³é”®å‘ç°:")
        for finding in analysis['key_findings']:
            print(f"   â€¢ {finding}")
        
        # 7. ååŒæ•ˆåº”ç»Ÿè®¡
        if 'synergistic_effects' in analysis:
            synergy = analysis['synergistic_effects']
            print(f"\nğŸš€ ååŒæ•ˆåº”ç»Ÿè®¡:")
            print(f"   â€¢ å®Œæ•´COT-DIRæ¡†æ¶: {synergy['full_framework']:.1%}")
            print(f"   â€¢ æœ€ä½³åŒç»„ä»¶ç»„åˆ: {synergy['best_two_component']:.1%}")
            print(f"   â€¢ ååŒæå‡æ•ˆæœ: +{synergy['synergy_boost']:.1%} ({synergy['synergy_percentage']:.1f}%)")
        
        print(f"\nâœ… æ‰€æœ‰å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜åˆ° {output_dir}/ ç›®å½•")

def main():
    """ä¸»å‡½æ•° - è¿è¡Œå¯è§†åŒ–æ¼”ç¤º"""
    
    # ç¤ºä¾‹æ•°æ® - å¯¹åº”åŸå§‹Table 5
    sample_table_data = {
        'Basic Symbolic': {'L0': '90.0%', 'L1': '64.0%', 'L2': '35.0%', 'L3': '15.0%', 'Overall': '46.5%', 'raw_overall': 0.465},
        'Simple Neural': {'L0': '83.0%', 'L1': '70.0%', 'L2': '40.0%', 'L3': '25.0%', 'Overall': '51.0%', 'raw_overall': 0.51},
        'GPT-3.5 + CoT': {'L0': '87.0%', 'L1': '76.0%', 'L2': '52.5%', 'L3': '45.0%', 'Overall': '62.0%', 'raw_overall': 0.62},
        'IRD only': {'L0': '73.0%', 'L1': '56.0%', 'L2': '42.5%', 'L3': '27.5%', 'Overall': '47.5%', 'raw_overall': 0.475},
        'MLR only': {'L0': '80.0%', 'L1': '62.0%', 'L2': '37.5%', 'L3': '22.5%', 'Overall': '47.0%', 'raw_overall': 0.47},
        'CV only': {'L0': '67.0%', 'L1': '52.0%', 'L2': '32.5%', 'L3': '17.5%', 'Overall': '39.5%', 'raw_overall': 0.395},
        'IRD + MLR': {'L0': '93.0%', 'L1': '84.0%', 'L2': '65.0%', 'L3': '55.0%', 'Overall': '72.0%', 'raw_overall': 0.72},
        'Full COT-DIR': {'L0': '96.7%', 'L1': '90.0%', 'L2': '72.5%', 'L3': '65.0%', 'Overall': '79.0%', 'raw_overall': 0.79}
    }
    
    # ç¤ºä¾‹åˆ†ææ•°æ®
    sample_analysis = {
        'key_findings': [
            'Best performing method: Full COT-DIR with 79.0% overall accuracy',
            'Synergistic effect: Full COT-DIR (79.0%) vs best two-component (72.0%), boost: +7.0%',
            'Performance degradation from L0 to L3: 96.7% â†’ 65.0% (-31.7%)'
        ],
        'synergistic_effects': {
            'full_framework': 0.79,
            'best_two_component': 0.72,
            'synergy_boost': 0.07,
            'synergy_percentage': 9.7
        }
    }
    
    sample_report = {
        'table5_results': sample_table_data,
        'analysis': sample_analysis
    }
    
    # åˆ›å»ºå¯è§†åŒ–å™¨å¹¶ç”ŸæˆæŠ¥å‘Š
    visualizer = Table5Visualizer()
    visualizer.generate_comprehensive_report(sample_report)

if __name__ == "__main__":
    main() 