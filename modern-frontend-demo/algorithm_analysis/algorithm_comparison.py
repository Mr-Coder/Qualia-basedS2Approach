#!/usr/bin/env python3
"""
ç®—æ³•æ–¹æ¡ˆå¯¹æ¯”åˆ†æ
ä»æ³›åŒ–æ€§å’Œå¯è§£é‡Šæ€§è§’åº¦è¯„ä¼°å››ç§ç®—æ³•å¢å¼ºæ–¹æ¡ˆ
"""

import numpy as np
import matplotlib.pyplot as plt
from typing import Dict, List, Any
from dataclasses import dataclass
import logging

logger = logging.getLogger(__name__)

@dataclass
class AlgorithmEvaluation:
    """ç®—æ³•è¯„ä¼°æŒ‡æ ‡"""
    name: str
    generalizability: Dict[str, float]  # æ³›åŒ–æ€§æŒ‡æ ‡
    interpretability: Dict[str, float]  # å¯è§£é‡Šæ€§æŒ‡æ ‡
    implementation: Dict[str, float]    # å®ç°éš¾åº¦æŒ‡æ ‡
    overall_score: float

class AlgorithmComparator:
    """ç®—æ³•å¯¹æ¯”åˆ†æå™¨"""
    
    def __init__(self):
        self.logger = logging.getLogger(f"{__name__}.{self.__class__.__name__}")
        self.algorithms = self._initialize_algorithms()
        
    def _initialize_algorithms(self) -> List[AlgorithmEvaluation]:
        """åˆå§‹åŒ–ç®—æ³•è¯„ä¼°"""
        
        # 1. å¢å¼ºQSÂ²è¯­ä¹‰åˆ†æå™¨
        enhanced_qs2 = AlgorithmEvaluation(
            name="å¢å¼ºQSÂ²è¯­ä¹‰åˆ†æå™¨",
            generalizability={
                "cross_domain_adaptability": 0.85,  # è·¨é¢†åŸŸé€‚åº”æ€§
                "problem_type_expansion": 0.80,     # é—®é¢˜ç±»å‹æ‰©å±•
                "data_efficiency": 0.60,            # æ•°æ®æ•ˆç‡ï¼ˆéœ€è¦å¤§é‡è®­ç»ƒæ•°æ®ï¼‰
                "zero_shot_capability": 0.70,       # é›¶æ ·æœ¬èƒ½åŠ›
                "domain_transfer": 0.75             # é¢†åŸŸè¿ç§»èƒ½åŠ›
            },
            interpretability={
                "reasoning_transparency": 0.70,     # æ¨ç†é€æ˜åº¦ï¼ˆæ·±åº¦ç¥ç»ç½‘ç»œé»‘ç›’ï¼‰
                "frontend_visualization": 0.85,     # å‰ç«¯å¯è§†åŒ–å‹å¥½åº¦
                "user_comprehension": 0.65,         # ç”¨æˆ·ç†è§£åº¦
                "educational_value": 0.80,          # æ•™è‚²ä»·å€¼
                "step_explainability": 0.75         # æ­¥éª¤å¯è§£é‡Šæ€§
            },
            implementation={
                "engineering_complexity": 0.30,     # å·¥ç¨‹å¤æ‚åº¦ï¼ˆé«˜å¤æ‚åº¦=ä½åˆ†ï¼‰
                "computational_cost": 0.40,         # è®¡ç®—æˆæœ¬
                "maintenance_difficulty": 0.35,     # ç»´æŠ¤éš¾åº¦
                "scalability": 0.70,               # å¯æ‰©å±•æ€§
                "stability": 0.60                   # ç¨³å®šæ€§
            },
            overall_score=0.0
        )
        
        # 2. GNNå¢å¼ºIRDå…³ç³»å‘ç°å™¨
        gnn_ird = AlgorithmEvaluation(
            name="GNNå¢å¼ºIRDå…³ç³»å‘ç°å™¨",
            generalizability={
                "cross_domain_adaptability": 0.75,  # å›¾ç»“æ„é€‚ç”¨æ€§å¼º
                "problem_type_expansion": 0.85,     # å…³ç³»æ¨ç†æ³›åŒ–æ€§å¥½
                "data_efficiency": 0.50,            # éœ€è¦å›¾ç»“æ„æ•°æ®
                "zero_shot_capability": 0.65,       # å›¾æ¨¡å¼æ³›åŒ–
                "domain_transfer": 0.80             # å›¾ç»“æ„è¿ç§»æ€§å¥½
            },
            interpretability={
                "reasoning_transparency": 0.60,     # GNNç›¸å¯¹é»‘ç›’
                "frontend_visualization": 0.90,     # å›¾å¯è§†åŒ–æ•ˆæœå¥½
                "user_comprehension": 0.70,         # å›¾ç»“æ„ç›´è§‚
                "educational_value": 0.85,          # å…³ç³»å›¾æ•™è‚²ä»·å€¼é«˜
                "step_explainability": 0.65         # æ³¨æ„åŠ›æƒé‡å¯è§£é‡Š
            },
            implementation={
                "engineering_complexity": 0.25,     # GNNå®ç°å¤æ‚
                "computational_cost": 0.35,         # å›¾è®¡ç®—å¼€é”€å¤§
                "maintenance_difficulty": 0.30,     # å›¾æ•°æ®ç»´æŠ¤å¤æ‚
                "scalability": 0.60,               # å›¾è§„æ¨¡é™åˆ¶
                "stability": 0.55                   # è®­ç»ƒä¸ç¨³å®š
            },
            overall_score=0.0
        )
        
        # 3. å¼ºåŒ–å­¦ä¹ å¢å¼ºCOT-DIR
        rl_cotdir = AlgorithmEvaluation(
            name="å¼ºåŒ–å­¦ä¹ å¢å¼ºCOT-DIR",
            generalizability={
                "cross_domain_adaptability": 0.90,  # RLé€‚åº”æ€§æå¼º
                "problem_type_expansion": 0.95,     # ç­–ç•¥å­¦ä¹ æ³›åŒ–æ€§å¥½
                "data_efficiency": 0.70,            # åœ¨çº¿å­¦ä¹ æ•ˆç‡é«˜
                "zero_shot_capability": 0.60,       # éœ€è¦æ¢ç´¢å­¦ä¹ 
                "domain_transfer": 0.85             # ç­–ç•¥è¿ç§»èƒ½åŠ›å¼º
            },
            interpretability={
                "reasoning_transparency": 0.45,     # RLç­–ç•¥é»‘ç›’åŒ–ä¸¥é‡
                "frontend_visualization": 0.60,     # ç­–ç•¥å¯è§†åŒ–å›°éš¾
                "user_comprehension": 0.40,         # RLæ¦‚å¿µæŠ½è±¡
                "educational_value": 0.50,          # æ•™è‚²ä»·å€¼æœ‰é™
                "step_explainability": 0.55         # åŠ¨ä½œé€‰æ‹©éš¾è§£é‡Š
            },
            implementation={
                "engineering_complexity": 0.15,     # RLå®ç°æœ€å¤æ‚
                "computational_cost": 0.20,         # è®­ç»ƒæˆæœ¬æé«˜
                "maintenance_difficulty": 0.20,     # è¶…å‚æ•°è°ƒä¼˜å›°éš¾
                "scalability": 0.50,               # çŠ¶æ€ç©ºé—´çˆ†ç‚¸
                "stability": 0.40                   # è®­ç»ƒä¸ç¨³å®š
            },
            overall_score=0.0
        )
        
        # 4. ç‰©ç†çº¦æŸä¼ æ’­ç½‘ç»œ
        physics_network = AlgorithmEvaluation(
            name="ç‰©ç†çº¦æŸä¼ æ’­ç½‘ç»œ",
            generalizability={
                "cross_domain_adaptability": 0.95,  # ç‰©ç†å®šå¾‹æ™®é€‚æ€§å¼º
                "problem_type_expansion": 0.75,     # é™äºç‰©ç†ç›¸å…³é—®é¢˜
                "data_efficiency": 0.90,            # åŸºäºè§„åˆ™ï¼Œæ•°æ®éœ€æ±‚ä½
                "zero_shot_capability": 0.85,       # ç‰©ç†è§„åˆ™é›¶æ ·æœ¬åº”ç”¨
                "domain_transfer": 0.70             # ç‰©ç†é¢†åŸŸå†…è¿ç§»å¥½
            },
            interpretability={
                "reasoning_transparency": 0.95,     # åŸºäºç‰©ç†å®šå¾‹ï¼Œé€æ˜åº¦æé«˜
                "frontend_visualization": 0.90,     # çº¦æŸå¯è§†åŒ–æ•ˆæœå¥½
                "user_comprehension": 0.85,         # ç‰©ç†æ¦‚å¿µæ˜“ç†è§£
                "educational_value": 0.95,          # æ•™è‚²ä»·å€¼æœ€é«˜
                "step_explainability": 0.90         # æ¯æ­¥éƒ½æœ‰ç‰©ç†ä¾æ®
            },
            implementation={
                "engineering_complexity": 0.75,     # è§„åˆ™å¼•æ“ç›¸å¯¹ç®€å•
                "computational_cost": 0.80,         # çº¦æŸæ±‚è§£æ•ˆç‡é«˜
                "maintenance_difficulty": 0.70,     # è§„åˆ™ç»´æŠ¤ç›¸å¯¹å®¹æ˜“
                "scalability": 0.85,               # çº¦æŸæ•°é‡å¯æ§
                "stability": 0.90                   # åŸºäºè§„åˆ™ï¼Œç¨³å®šæ€§é«˜
            },
            overall_score=0.0
        )
        
        algorithms = [enhanced_qs2, gnn_ird, rl_cotdir, physics_network]
        
        # è®¡ç®—ç»¼åˆå¾—åˆ†
        for algo in algorithms:
            generalizability_score = np.mean(list(algo.generalizability.values()))
            interpretability_score = np.mean(list(algo.interpretability.values()))
            implementation_score = np.mean(list(algo.implementation.values()))
            
            # åŠ æƒè®¡ç®—æ€»åˆ†ï¼ˆæ³›åŒ–æ€§40%ï¼Œå¯è§£é‡Šæ€§40%ï¼Œå®ç°éš¾åº¦20%ï¼‰
            algo.overall_score = (
                generalizability_score * 0.4 + 
                interpretability_score * 0.4 + 
                implementation_score * 0.2
            )
        
        return algorithms
    
    def generate_comparison_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆå¯¹æ¯”åˆ†ææŠ¥å‘Š"""
        
        self.logger.info("ç”Ÿæˆç®—æ³•å¯¹æ¯”åˆ†ææŠ¥å‘Š")
        
        # 1. ç»¼åˆæ’å
        ranked_algorithms = sorted(self.algorithms, key=lambda x: x.overall_score, reverse=True)
        
        # 2. ç»´åº¦åˆ†æ
        dimension_analysis = self._analyze_by_dimensions()
        
        # 3. ä½¿ç”¨åœºæ™¯æ¨è
        scenario_recommendations = self._generate_scenario_recommendations()
        
        # 4. å®æ–½å»ºè®®
        implementation_advice = self._generate_implementation_advice()
        
        return {
            "overall_ranking": [
                {
                    "rank": i + 1,
                    "name": algo.name,
                    "overall_score": round(algo.overall_score, 3),
                    "generalizability": round(np.mean(list(algo.generalizability.values())), 3),
                    "interpretability": round(np.mean(list(algo.interpretability.values())), 3),
                    "implementation": round(np.mean(list(algo.implementation.values())), 3)
                }
                for i, algo in enumerate(ranked_algorithms)
            ],
            "dimension_analysis": dimension_analysis,
            "scenario_recommendations": scenario_recommendations,
            "implementation_advice": implementation_advice,
            "detailed_scores": self._get_detailed_scores()
        }
    
    def _analyze_by_dimensions(self) -> Dict[str, Any]:
        """æŒ‰ç»´åº¦åˆ†æ"""
        
        # æ³›åŒ–æ€§æœ€ä½³
        best_generalizability = max(self.algorithms, 
            key=lambda x: np.mean(list(x.generalizability.values())))
        
        # å¯è§£é‡Šæ€§æœ€ä½³
        best_interpretability = max(self.algorithms, 
            key=lambda x: np.mean(list(x.interpretability.values())))
        
        # å®ç°éš¾åº¦æœ€ä½ï¼ˆåˆ†æ•°æœ€é«˜ï¼‰
        easiest_implementation = max(self.algorithms, 
            key=lambda x: np.mean(list(x.implementation.values())))
        
        return {
            "best_generalizability": {
                "algorithm": best_generalizability.name,
                "score": round(np.mean(list(best_generalizability.generalizability.values())), 3),
                "strengths": self._get_top_strengths(best_generalizability.generalizability)
            },
            "best_interpretability": {
                "algorithm": best_interpretability.name,
                "score": round(np.mean(list(best_interpretability.interpretability.values())), 3),
                "strengths": self._get_top_strengths(best_interpretability.interpretability)
            },
            "easiest_implementation": {
                "algorithm": easiest_implementation.name,
                "score": round(np.mean(list(easiest_implementation.implementation.values())), 3),
                "advantages": self._get_top_strengths(easiest_implementation.implementation)
            }
        }
    
    def _generate_scenario_recommendations(self) -> Dict[str, str]:
        """ç”Ÿæˆä½¿ç”¨åœºæ™¯æ¨è"""
        
        return {
            "æ•™è‚²åº”ç”¨ä¼˜å…ˆ": "ç‰©ç†çº¦æŸä¼ æ’­ç½‘ç»œ - æœ€é«˜çš„å¯è§£é‡Šæ€§å’Œæ•™è‚²ä»·å€¼ï¼Œå­¦ç”Ÿèƒ½ç›´è§‚ç†è§£æ¨ç†è¿‡ç¨‹",
            "ç ”ç©¶åŸå‹å¼€å‘": "ç‰©ç†çº¦æŸä¼ æ’­ç½‘ç»œ - å®ç°éš¾åº¦æœ€ä½ï¼Œå¯å¿«é€ŸéªŒè¯æ¦‚å¿µå’Œç®—æ³•æ•ˆæœ",
            "å·¥ä¸šçº§éƒ¨ç½²": "å¢å¼ºQSÂ²è¯­ä¹‰åˆ†æå™¨ - å¹³è¡¡äº†æ€§èƒ½å’Œå¯è§£é‡Šæ€§ï¼Œå·¥ç¨‹åŒ–ç¨‹åº¦è¾ƒé«˜",
            "å‰æ²¿ç ”ç©¶æ¢ç´¢": "å¼ºåŒ–å­¦ä¹ å¢å¼ºCOT-DIR - æ³›åŒ–æ€§æœ€å¼ºï¼Œä½†éœ€è¦é•¿æœŸæŠ•å…¥å’Œä¸“ä¸šå›¢é˜Ÿ",
            "å…³ç³»æŒ–æ˜é‡ç‚¹": "GNNå¢å¼ºIRDå…³ç³»å‘ç°å™¨ - åœ¨å…³ç³»å‘ç°æ–¹é¢è¡¨ç°çªå‡ºï¼Œå›¾å¯è§†åŒ–æ•ˆæœå¥½",
            "å¿«é€ŸåŸå‹éªŒè¯": "ç‰©ç†çº¦æŸä¼ æ’­ç½‘ç»œ - åŸºäºè§„åˆ™ï¼Œå¼€å‘å‘¨æœŸçŸ­ï¼Œæ•ˆæœå¯é¢„æœŸ"
        }
    
    def _generate_implementation_advice(self) -> Dict[str, List[str]]:
        """ç”Ÿæˆå®æ–½å»ºè®®"""
        
        return {
            "çŸ­æœŸå®æ–½(1-2ä¸ªæœˆ)": [
                "ä¼˜å…ˆé€‰æ‹©ç‰©ç†çº¦æŸä¼ æ’­ç½‘ç»œ",
                "åŸºäºç°æœ‰QSÂ²+IRD+COT-DIRæ¡†æ¶æ‰©å±•",
                "é‡ç‚¹å®ç°æ ¸å¿ƒç‰©ç†å®šå¾‹çº¦æŸ",
                "å®Œå–„å‰ç«¯å¯è§†åŒ–å±•ç¤º"
            ],
            "ä¸­æœŸå‘å±•(3-6ä¸ªæœˆ)": [
                "é›†æˆå¢å¼ºQSÂ²è¯­ä¹‰åˆ†æå™¨çš„éƒ¨åˆ†åŠŸèƒ½",
                "æ·»åŠ æ³¨æ„åŠ›æœºåˆ¶å’Œå¤šå±‚çº§è¯­ä¹‰å‘é‡",
                "ä¼˜åŒ–ç‰©ç†çº¦æŸç½‘ç»œçš„æ€§èƒ½",
                "æ‰©å±•æ”¯æŒçš„é—®é¢˜ç±»å‹"
            ],
            "é•¿æœŸè§„åˆ’(6ä¸ªæœˆä»¥ä¸Š)": [
                "æ¢ç´¢GNNåœ¨ç‰¹å®šåœºæ™¯ä¸‹çš„åº”ç”¨",
                "ç ”ç©¶å¼ºåŒ–å­¦ä¹ åœ¨æ¨ç†ä¼˜åŒ–ä¸­çš„æ½œåŠ›",
                "æ„å»ºå®Œæ•´çš„å¤šç®—æ³•èåˆæ¡†æ¶",
                "æŒç»­ä¼˜åŒ–å’Œç”¨æˆ·åé¦ˆè¿­ä»£"
            ],
            "æŠ€æœ¯é£é™©æ§åˆ¶": [
                "é¿å…è¿‡åº¦å¤æ‚åŒ–ç³»ç»Ÿæ¶æ„",
                "ä¿æŒç®—æ³•ç»“æœçš„å¯è§£é‡Šæ€§",
                "ç¡®ä¿ç³»ç»Ÿç¨³å®šæ€§å’Œå¯ç»´æŠ¤æ€§",
                "å¹³è¡¡åˆ›æ–°æ€§å’Œå®ç”¨æ€§"
            ]
        }
    
    def _get_top_strengths(self, scores_dict: Dict[str, float], top_k: int = 3) -> List[str]:
        """è·å–topä¼˜åŠ¿"""
        sorted_items = sorted(scores_dict.items(), key=lambda x: x[1], reverse=True)
        return [item[0] for item in sorted_items[:top_k]]
    
    def _get_detailed_scores(self) -> Dict[str, Dict[str, float]]:
        """è·å–è¯¦ç»†å¾—åˆ†"""
        detailed_scores = {}
        
        for algo in self.algorithms:
            detailed_scores[algo.name] = {
                **algo.generalizability,
                **algo.interpretability,
                **algo.implementation,
                "overall_score": algo.overall_score
            }
        
        return detailed_scores
    
    def visualize_comparison(self) -> Dict[str, Any]:
        """ç”Ÿæˆå¯è§†åŒ–å¯¹æ¯”æ•°æ®"""
        
        # å‡†å¤‡é›·è¾¾å›¾æ•°æ®
        algorithms = [algo.name for algo in self.algorithms]
        
        generalizability_scores = [np.mean(list(algo.generalizability.values())) for algo in self.algorithms]
        interpretability_scores = [np.mean(list(algo.interpretability.values())) for algo in self.algorithms]
        implementation_scores = [np.mean(list(algo.implementation.values())) for algo in self.algorithms]
        
        return {
            "radar_chart_data": {
                "algorithms": algorithms,
                "dimensions": ["æ³›åŒ–æ€§", "å¯è§£é‡Šæ€§", "å®ç°éš¾åº¦"],
                "scores": [
                    generalizability_scores,
                    interpretability_scores,
                    implementation_scores
                ]
            },
            "bar_chart_data": {
                "algorithms": algorithms,
                "overall_scores": [algo.overall_score for algo in self.algorithms]
            },
            "detailed_metrics": {
                algo.name: {
                    "æ³›åŒ–æ€§æŒ‡æ ‡": algo.generalizability,
                    "å¯è§£é‡Šæ€§æŒ‡æ ‡": algo.interpretability,
                    "å®ç°éš¾åº¦æŒ‡æ ‡": algo.implementation
                }
                for algo in self.algorithms
            }
        }

# ä½¿ç”¨ç¤ºä¾‹å’Œæµ‹è¯•
if __name__ == "__main__":
    comparator = AlgorithmComparator()
    
    # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
    report = comparator.generate_comparison_report()
    
    print("=" * 60)
    print("ç®—æ³•å¯¹æ¯”åˆ†ææŠ¥å‘Š")
    print("=" * 60)
    
    print("\nğŸ† ç»¼åˆæ’å:")
    for item in report["overall_ranking"]:
        print(f"{item['rank']}. {item['name']}")
        print(f"   ç»¼åˆå¾—åˆ†: {item['overall_score']}")
        print(f"   æ³›åŒ–æ€§: {item['generalizability']} | å¯è§£é‡Šæ€§: {item['interpretability']} | å®ç°éš¾åº¦: {item['implementation']}")
        print()
    
    print("\nğŸ“Š ç»´åº¦åˆ†æ:")
    for dimension, info in report["dimension_analysis"].items():
        print(f"{dimension}: {info['algorithm']} (å¾—åˆ†: {info['score']})")
    
    print("\nğŸ¯ ä½¿ç”¨åœºæ™¯æ¨è:")
    for scenario, recommendation in report["scenario_recommendations"].items():
        print(f"{scenario}: {recommendation}")
    
    print("\nğŸ’¡ å®æ–½å»ºè®®:")
    for phase, advice_list in report["implementation_advice"].items():
        print(f"{phase}:")
        for advice in advice_list:
            print(f"  â€¢ {advice}")
        print()
    
    # å¯è§†åŒ–æ•°æ®
    viz_data = comparator.visualize_comparison()
    print("\nğŸ“ˆ å¯è§†åŒ–æ•°æ®å·²ç”Ÿæˆï¼Œå¯ç”¨äºå‰ç«¯å›¾è¡¨å±•ç¤º")