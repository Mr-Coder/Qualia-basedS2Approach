"""
Improved vs Robust System Comparison Test
========================================

æ¯”è¾ƒæ”¹è¿›çš„æ¨ç†ç³»ç»Ÿä¸é²æ£’ç³»ç»Ÿåœ¨ä»¥ä¸‹æ–¹é¢çš„æ€§èƒ½ï¼š
1. è¯­ä¹‰ç†è§£å‡†ç¡®æ€§
2. æ¨ç†é€»è¾‘è¿è´¯æ€§  
3. æ­§ä¹‰è§£å†³èƒ½åŠ›
4. å¤šæ­¥æ¨ç†å‡†ç¡®æ€§
5. ç­”æ¡ˆå‡†ç¡®æ€§

Author: Math Problem Solver Team
Version: 1.0.0
"""

import json
import logging
import time
from pathlib import Path
from typing import Any, Dict, List, Tuple

from improved_reasoning_system import ImprovedMathematicalReasoningSystem
from robust_reasoning_system import RobustMathematicalReasoningSystem

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('improved_vs_robust_test.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class SystemComparisonTester:
    """ç³»ç»Ÿæ¯”è¾ƒæµ‹è¯•å™¨"""
    
    def __init__(self):
        self.improved_system = ImprovedMathematicalReasoningSystem()
        self.robust_system = RobustMathematicalReasoningSystem()
        
    def get_test_problems(self) -> List[Dict[str, Any]]:
        """è·å–æµ‹è¯•é—®é¢˜"""
        return [
            {
                'id': 0,
                'question': "John has 25 apples. He gives 8 apples to Mary and then buys 12 more apples. How many apples does John have now?",
                'expected_numeric': 29,
                'focus': 'multi_step_sequential'
            },
            {
                'id': 1,
                'question': "A store sells notebooks for $3 each. If Sarah buys 4 notebooks and pays with a $20 bill, how much change does she receive?",
                'expected_numeric': 8,
                'focus': 'calculation_with_change'
            },
            {
                'id': 2,
                'question': "There are 15 students in a class. 3 students are absent today. If the remaining students are divided into groups of 4, how many complete groups can be formed?",
                'expected_numeric': 3,
                'focus': 'division_with_remainder'
            },
            {
                'id': 3,
                'question': "Mike saves $5 every week. After 6 weeks, he spends $18 on a book. How much money does he have left?",
                'expected_numeric': 12,
                'focus': 'savings_and_spending'
            },
            {
                'id': 4,
                'question': "A recipe calls for 2 cups of flour. If Lisa wants to make 3 times the recipe, how many cups of flour does she need in total?",
                'expected_numeric': 6,
                'focus': 'scaling_recipe'
            }
        ]
    
    def compare_systems_on_problem(self, problem: Dict[str, Any]) -> Dict[str, Any]:
        """æ¯”è¾ƒä¸¤ä¸ªç³»ç»Ÿåœ¨å•ä¸ªé—®é¢˜ä¸Šçš„è¡¨ç°"""
        
        # æµ‹è¯•æ”¹è¿›ç³»ç»Ÿ
        improved_start = time.time()
        try:
            improved_result = self.improved_system.solve_mathematical_problem(problem['question'])
            improved_time = time.time() - improved_start
            improved_success = True
        except Exception as e:
            logger.error(f"Improved system failed on problem {problem['id']}: {e}")
            improved_result = {'error': str(e)}
            improved_time = time.time() - improved_start
            improved_success = False
        
        # æµ‹è¯•é²æ£’ç³»ç»Ÿ
        robust_start = time.time()
        try:
            robust_result = self.robust_system.solve_mathematical_problem(problem['question'])
            robust_time = time.time() - robust_start
            robust_success = True
        except Exception as e:
            logger.error(f"Robust system failed on problem {problem['id']}: {e}")
            robust_result = {'error': str(e)}
            robust_time = time.time() - robust_start
            robust_success = False
        
        # åˆ†ææ¯”è¾ƒç»“æœ
        comparison = self._analyze_comparison(
            problem, improved_result, robust_result, improved_success, robust_success
        )
        
        return {
            'problem_id': problem['id'],
            'question': problem['question'],
            'expected_answer': problem['expected_numeric'],
            'improved_system': {
                'result': improved_result,
                'processing_time': improved_time,
                'success': improved_success
            },
            'robust_system': {
                'result': robust_result,
                'processing_time': robust_time,
                'success': robust_success
            },
            'comparison': comparison
        }
    
    def _analyze_comparison(self, problem: Dict[str, Any], 
                          improved_result: Dict[str, Any], 
                          robust_result: Dict[str, Any],
                          improved_success: bool,
                          robust_success: bool) -> Dict[str, Any]:
        """åˆ†ææ¯”è¾ƒç»“æœ"""
        
        comparison = {
            'accuracy_comparison': {},
            'semantic_analysis_comparison': {},
            'reasoning_quality_comparison': {},
            'winner': 'tie'
        }
        
        expected = problem['expected_numeric']
        
        # å‡†ç¡®æ€§æ¯”è¾ƒ
        if improved_success and robust_success:
            improved_answer = improved_result.get('final_answer', 0)
            robust_answer = robust_result.get('final_answer', 0)
            
            improved_correct = abs(improved_answer - expected) < 0.01 if isinstance(improved_answer, (int, float)) else False
            robust_correct = abs(robust_answer - expected) < 0.01 if isinstance(robust_answer, (int, float)) else False
            
            comparison['accuracy_comparison'] = {
                'improved_correct': improved_correct,
                'robust_correct': robust_correct,
                'improved_answer': improved_answer,
                'robust_answer': robust_answer,
                'expected_answer': expected
            }
            
            # è¯­ä¹‰åˆ†ææ¯”è¾ƒ
            improved_semantic = improved_result.get('semantic_context', {})
            
            comparison['semantic_analysis_comparison'] = {
                'improved_has_intent_analysis': bool(improved_semantic.get('problem_intent')),
                'improved_has_ambiguity_resolution': bool(improved_semantic.get('ambiguity_resolution')),
                'improved_has_implicit_operations': bool(improved_semantic.get('implicit_operations')),
                'improved_reasoning_steps_count': len(improved_result.get('reasoning_steps', [])),
                'robust_reasoning_steps_count': len(robust_result.get('reasoning_steps', []))
            }
            
            # æ¨ç†è´¨é‡æ¯”è¾ƒ
            improved_confidence = improved_result.get('confidence', 0)
            improved_verification = improved_result.get('verification_summary', {})
            
            comparison['reasoning_quality_comparison'] = {
                'improved_confidence': improved_confidence,
                'improved_verification_passed': improved_verification.get('verification_passed', False),
                'improved_has_semantic_justification': any(
                    step.get('semantic_justification') for step in improved_result.get('reasoning_steps', [])
                )
            }
            
            # ç¡®å®šè·èƒœè€…
            if improved_correct and not robust_correct:
                comparison['winner'] = 'improved'
            elif robust_correct and not improved_correct:
                comparison['winner'] = 'robust'
            elif improved_correct and robust_correct:
                # ä¸¤è€…éƒ½æ­£ç¡®ï¼Œæ¯”è¾ƒå…¶ä»–å› ç´ 
                if improved_confidence > 0.8 and improved_semantic.get('problem_intent'):
                    comparison['winner'] = 'improved'
                else:
                    comparison['winner'] = 'tie'
            else:
                comparison['winner'] = 'both_failed'
        
        elif improved_success and not robust_success:
            comparison['winner'] = 'improved'
        elif robust_success and not improved_success:
            comparison['winner'] = 'robust'
        else:
            comparison['winner'] = 'both_failed'
        
        return comparison
    
    def run_comprehensive_comparison(self) -> Dict[str, Any]:
        """è¿è¡Œç»¼åˆæ¯”è¾ƒæµ‹è¯•"""
        
        logger.info("Starting comprehensive comparison test")
        
        # è·å–æµ‹è¯•é—®é¢˜
        problems = self.get_test_problems()
        
        # æ¯”è¾ƒæ¯ä¸ªé—®é¢˜
        comparison_results = []
        for problem in problems:
            logger.info(f"Testing problem {problem['id']}: {problem['question'][:50]}...")
            result = self.compare_systems_on_problem(problem)
            comparison_results.append(result)
        
        # è®¡ç®—æ€»ä½“ç»Ÿè®¡
        overall_stats = self._calculate_overall_statistics(comparison_results)
        
        # ç”Ÿæˆæ¯”è¾ƒæŠ¥å‘Š
        comparison_report = self._generate_comparison_report(comparison_results, overall_stats)
        
        return {
            'comparison_results': comparison_results,
            'overall_statistics': overall_stats,
            'comparison_report': comparison_report
        }
    
    def _calculate_overall_statistics(self, results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """è®¡ç®—æ€»ä½“ç»Ÿè®¡"""
        
        total_problems = len(results)
        improved_wins = sum(1 for r in results if r['comparison']['winner'] == 'improved')
        robust_wins = sum(1 for r in results if r['comparison']['winner'] == 'robust')
        ties = sum(1 for r in results if r['comparison']['winner'] == 'tie')
        
        # å‡†ç¡®æ€§ç»Ÿè®¡
        improved_correct = sum(1 for r in results 
                             if r['comparison']['accuracy_comparison'].get('improved_correct', False))
        robust_correct = sum(1 for r in results 
                           if r['comparison']['accuracy_comparison'].get('robust_correct', False))
        
        # è¯­ä¹‰åˆ†æç»Ÿè®¡
        problems_with_intent = sum(1 for r in results 
                                 if r['comparison']['semantic_analysis_comparison'].get('improved_has_intent_analysis', False))
        problems_with_ambiguity_resolution = sum(1 for r in results 
                                               if r['comparison']['semantic_analysis_comparison'].get('improved_has_ambiguity_resolution', False))
        
        return {
            'total_problems': total_problems,
            'winner_statistics': {
                'improved_wins': improved_wins,
                'robust_wins': robust_wins,
                'ties': ties,
                'improved_win_rate': improved_wins / total_problems,
                'robust_win_rate': robust_wins / total_problems
            },
            'accuracy_statistics': {
                'improved_accuracy': improved_correct / total_problems,
                'robust_accuracy': robust_correct / total_problems,
                'improved_correct_count': improved_correct,
                'robust_correct_count': robust_correct
            },
            'semantic_analysis_statistics': {
                'problems_with_intent_analysis': problems_with_intent,
                'problems_with_ambiguity_resolution': problems_with_ambiguity_resolution,
                'intent_analysis_rate': problems_with_intent / total_problems,
                'ambiguity_resolution_rate': problems_with_ambiguity_resolution / total_problems
            }
        }
    
    def _generate_comparison_report(self, results: List[Dict[str, Any]], stats: Dict[str, Any]) -> str:
        """ç”Ÿæˆæ¯”è¾ƒæŠ¥å‘Š"""
        
        report = f"""
=== Improved vs Robust System Comparison Report ===
Test Date: {time.strftime('%Y-%m-%d %H:%M:%S')}
Total Problems Tested: {stats['total_problems']}

=== OVERALL WINNER STATISTICS ===
ğŸ† Improved System Wins: {stats['winner_statistics']['improved_wins']} ({stats['winner_statistics']['improved_win_rate']:.1%})
ğŸ† Robust System Wins: {stats['winner_statistics']['robust_wins']} ({stats['winner_statistics']['robust_win_rate']:.1%})
ğŸ¤ Ties: {stats['winner_statistics']['ties']}

=== ACCURACY COMPARISON ===
âœ… Improved System Accuracy: {stats['accuracy_statistics']['improved_accuracy']:.1%} ({stats['accuracy_statistics']['improved_correct_count']}/{stats['total_problems']})
âœ… Robust System Accuracy: {stats['accuracy_statistics']['robust_accuracy']:.1%} ({stats['accuracy_statistics']['robust_correct_count']}/{stats['total_problems']})
ğŸ“ˆ Accuracy Improvement: {(stats['accuracy_statistics']['improved_accuracy'] - stats['accuracy_statistics']['robust_accuracy']):.1%}

=== SEMANTIC ANALYSIS ENHANCEMENT ===
ğŸ§  Problems with Intent Analysis: {stats['semantic_analysis_statistics']['problems_with_intent_analysis']} ({stats['semantic_analysis_statistics']['intent_analysis_rate']:.1%})
ğŸ” Problems with Ambiguity Resolution: {stats['semantic_analysis_statistics']['problems_with_ambiguity_resolution']} ({stats['semantic_analysis_statistics']['ambiguity_resolution_rate']:.1%})

=== DETAILED PROBLEM ANALYSIS ==="""
        
        # è¯¦ç»†é—®é¢˜åˆ†æ
        for result in results:
            report += f"\n\nProblem {result['problem_id']}: {result['question'][:60]}..."
            report += f"\nExpected: {result['expected_answer']}"
            
            if result['improved_system']['success']:
                improved_answer = result['improved_system']['result'].get('final_answer', 'N/A')
                report += f"\nImproved: {improved_answer} ({'âœ…' if result['comparison']['accuracy_comparison'].get('improved_correct', False) else 'âŒ'})"
            
            if result['robust_system']['success']:
                robust_answer = result['robust_system']['result'].get('final_answer', 'N/A')
                report += f"\nRobust: {robust_answer} ({'âœ…' if result['comparison']['accuracy_comparison'].get('robust_correct', False) else 'âŒ'})"
            
            report += f"\nWinner: {result['comparison']['winner']}"
        
        return report

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("=== Improved vs Robust System Comparison Test ===")
    print("Testing improvements in:")
    print("1. è¯­ä¹‰ç†è§£å‡†ç¡®æ€§")
    print("2. æ¨ç†é€»è¾‘è¿è´¯æ€§")
    print("3. æ­§ä¹‰è§£å†³èƒ½åŠ›")
    print("4. å¤šæ­¥æ¨ç†å‡†ç¡®æ€§")
    print("5. ç­”æ¡ˆå‡†ç¡®æ€§")
    print("=" * 55)
    
    # åˆ›å»ºæ¯”è¾ƒæµ‹è¯•å™¨
    tester = SystemComparisonTester()
    
    # è¿è¡Œæ¯”è¾ƒæµ‹è¯•
    results = tester.run_comprehensive_comparison()
    
    print(results['comparison_report'])
    
    print("\n=== Comparison Test Completed Successfully ===")
    stats = results['overall_statistics']
    print(f"Improved System Win Rate: {stats['winner_statistics']['improved_win_rate']:.1%}")
    print(f"Accuracy Improvement: {(stats['accuracy_statistics']['improved_accuracy'] - stats['accuracy_statistics']['robust_accuracy']):.1%}")
    print(f"Semantic Analysis Coverage: {stats['semantic_analysis_statistics']['intent_analysis_rate']:.1%}")

if __name__ == "__main__":
    main() 