#!/usr/bin/env python3
"""
Enhanced GSM8K Performance Test
æµ‹è¯•å¢å¼ºç‰ˆæ•°å­¦æ¨ç†ç³»ç»Ÿåœ¨GSM8Kæ•°æ®é›†ä¸Šçš„æ€§èƒ½
"""

import json
import logging
import os
import re
import sys
import time
from datetime import datetime
from typing import Any, Dict, List, Optional

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('enhanced_gsm8k_test.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# Import the enhanced system
from enhanced_mathematical_reasoning_system import \
    EnhancedMathematicalReasoningSystem


class EnhancedGSM8KPerformanceEvaluator:
    """å¢å¼ºç‰ˆGSM8Kæ€§èƒ½è¯„ä¼°å™¨"""
    
    def __init__(self, max_problems: int = 50):
        self.max_problems = max_problems
        self.math_system = EnhancedMathematicalReasoningSystem()
        self.results = []
        
    def load_gsm8k_data(self, file_path: str) -> List[Dict[str, Any]]:
        """åŠ è½½GSM8Kæ•°æ®é›†"""
        problems = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    if line_num > self.max_problems:
                        break
                    
                    try:
                        data = json.loads(line.strip())
                        problems.append(data)
                    except json.JSONDecodeError as e:
                        logger.warning(f"Invalid JSON at line {line_num}: {e}")
                        continue
            
            logger.info(f"Successfully loaded {len(problems)} problems from GSM8K")
            return problems
            
        except FileNotFoundError:
            logger.error(f"GSM8K file not found: {file_path}")
            return []
        except Exception as e:
            logger.error(f"Error loading GSM8K data: {e}")
            return []
    
    def extract_numerical_answer(self, answer_text: str) -> Optional[float]:
        """ä»ç­”æ¡ˆæ–‡æœ¬ä¸­æå–æ•°å€¼ç­”æ¡ˆ"""
        if not answer_text:
            return None
        
        # æŸ¥æ‰¾ #### æ ‡è®°åçš„æ•°å­—
        pattern = r'####\s*([+-]?\d*\.?\d+)'
        match = re.search(pattern, answer_text)
        
        if match:
            try:
                return float(match.group(1))
            except ValueError:
                pass
        
        # å¤‡ç”¨æ¨¡å¼: æŸ¥æ‰¾æœ€åä¸€ä¸ªæ•°å­—
        numbers = re.findall(r'([+-]?\d*\.?\d+)', answer_text)
        if numbers:
            try:
                return float(numbers[-1])
            except ValueError:
                pass
        
        return None
    
    def classify_problem_complexity(self, question: str, answer: str) -> str:
        """åˆ†ç±»é—®é¢˜å¤æ‚åº¦"""
        text = question.lower() + " " + answer.lower()
        
        # L3: å¤æ‚æ¨ç† - å¤šä¸ªæ¡ä»¶ã€æ¯”ä¾‹ã€å¤æ‚å…³ç³»
        l3_indicators = [
            'ratio', 'proportion', 'percentage', 'rate', 'average',
            'if.*then', 'given.*that', 'assuming', 'provided',
            'twice as', 'three times', 'half as', 'quarter'
        ]
        
        # L2: å¤šæ­¥æ¨ç† - è¿ç»­æ“ä½œã€æ—¶é—´è®¡ç®—ã€å¤šæ­¥éª¤
        l2_indicators = [
            'then', 'after', 'next', 'finally', 'first.*then',
            'spends.*and.*', 'buys.*and.*', 'from.*to',
            'total.*cost', 'how.*much.*left', 'how.*many.*total'
        ]
        
        # L1: ç®€å•åº”ç”¨ - åŸºæœ¬åº”ç”¨é¢˜
        l1_indicators = [
            'bought', 'sold', 'cost', 'price', 'spend', 'pay',
            'has.*apples', 'scored.*points', 'recipe.*calls'
        ]
        
        # æ£€æŸ¥å¤æ‚åº¦
        for indicator in l3_indicators:
            if re.search(indicator, text):
                return "L3"
        
        for indicator in l2_indicators:
            if re.search(indicator, text):
                return "L2"
        
        for indicator in l1_indicators:
            if re.search(indicator, text):
                return "L1"
        
        return "L0"  # åŸºç¡€è¿ç®—
    
    def evaluate_performance(self, gsm8k_file: str) -> Dict[str, Any]:
        """è¯„ä¼°ç³»ç»Ÿæ€§èƒ½"""
        logger.info("ğŸš€ Starting Enhanced GSM8K Performance Evaluation")
        
        # åŠ è½½æ•°æ®
        problems = self.load_gsm8k_data(gsm8k_file)
        
        if not problems:
            logger.error("No problems loaded. Exiting evaluation.")
            return {}
        
        # ç»Ÿè®¡å˜é‡
        total_problems = len(problems)
        correct_answers = 0
        complexity_stats = {"L0": {"total": 0, "correct": 0},
                          "L1": {"total": 0, "correct": 0},
                          "L2": {"total": 0, "correct": 0},
                          "L3": {"total": 0, "correct": 0}}
        
        total_processing_time = 0
        total_reasoning_steps = 0
        total_entities = 0
        total_relations = 0
        
        # å¤„ç†æ¯ä¸ªé—®é¢˜
        for i, problem in enumerate(problems, 1):
            question = problem.get('question', '')
            answer_text = problem.get('answer', '')
            expected_answer = self.extract_numerical_answer(answer_text)
            
            logger.info(f"ğŸ§® Processing problem {i}/{total_problems}")
            
            # åˆ†ç±»å¤æ‚åº¦
            complexity = self.classify_problem_complexity(question, answer_text)
            complexity_stats[complexity]["total"] += 1
            
            # æ±‚è§£é—®é¢˜
            start_time = time.time()
            try:
                result = self.math_system.solve_mathematical_problem(question)
                processing_time = time.time() - start_time
                
                computed_answer = result.get('final_answer')
                is_correct = False
                
                # æ£€æŸ¥ç­”æ¡ˆæ­£ç¡®æ€§
                if computed_answer is not None and expected_answer is not None:
                    # å…è®¸å°æ•°ç²¾åº¦è¯¯å·®
                    if abs(computed_answer - expected_answer) < 0.01:
                        is_correct = True
                        correct_answers += 1
                        complexity_stats[complexity]["correct"] += 1
                
                # æ”¶é›†ç»Ÿè®¡ä¿¡æ¯
                total_processing_time += processing_time
                total_reasoning_steps += len(result.get('reasoning_steps', []))
                total_entities += len(result.get('entities', []))
                total_relations += len(result.get('relations', []))
                
                # è®°å½•ç»“æœ
                problem_result = {
                    "problem_id": i,
                    "question": question,
                    "expected_answer": expected_answer,
                    "computed_answer": computed_answer,
                    "is_correct": is_correct,
                    "complexity": complexity,
                    "processing_time": processing_time,
                    "reasoning_steps": len(result.get('reasoning_steps', [])),
                    "entities_found": len(result.get('entities', [])),
                    "relations_found": len(result.get('relations', [])),
                    "full_result": result
                }
                
                self.results.append(problem_result)
                
                # æ˜¾ç¤ºè¿›åº¦
                if is_correct:
                    logger.info(f"âœ… Problem {i}: CORRECT ({computed_answer} = {expected_answer})")
                else:
                    logger.info(f"âŒ Problem {i}: WRONG ({computed_answer} â‰  {expected_answer})")
                
            except Exception as e:
                logger.error(f"Error processing problem {i}: {e}")
                problem_result = {
                    "problem_id": i,
                    "question": question,
                    "expected_answer": expected_answer,
                    "computed_answer": None,
                    "is_correct": False,
                    "complexity": complexity,
                    "processing_time": 0,
                    "reasoning_steps": 0,
                    "entities_found": 0,
                    "relations_found": 0,
                    "error": str(e)
                }
                self.results.append(problem_result)
        
        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        overall_accuracy = (correct_answers / total_problems) * 100 if total_problems > 0 else 0
        avg_processing_time = total_processing_time / total_problems if total_problems > 0 else 0
        avg_reasoning_steps = total_reasoning_steps / total_problems if total_problems > 0 else 0
        avg_entities = total_entities / total_problems if total_problems > 0 else 0
        avg_relations = total_relations / total_problems if total_problems > 0 else 0
        
        # è®¡ç®—å¤æ‚åº¦çº§åˆ«å‡†ç¡®ç‡
        complexity_accuracy = {}
        for level, stats in complexity_stats.items():
            if stats["total"] > 0:
                accuracy = (stats["correct"] / stats["total"]) * 100
                complexity_accuracy[level] = {
                    "accuracy": accuracy,
                    "correct": stats["correct"],
                    "total": stats["total"]
                }
        
        # ç”ŸæˆæŠ¥å‘Š
        evaluation_results = {
            "evaluation_timestamp": datetime.now().isoformat(),
            "dataset": "GSM8K",
            "system_version": "Enhanced_v2.0",
            "problems_evaluated": total_problems,
            "overall_performance": {
                "accuracy": overall_accuracy,
                "correct_answers": correct_answers,
                "total_problems": total_problems,
                "avg_processing_time": avg_processing_time,
                "avg_reasoning_steps": avg_reasoning_steps,
                "avg_entities_per_problem": avg_entities,
                "avg_relations_per_problem": avg_relations
            },
            "complexity_breakdown": complexity_accuracy,
            "detailed_results": self.results
        }
        
        return evaluation_results
    
    def save_results(self, results: Dict[str, Any], filename: str = None):
        """ä¿å­˜è¯„ä¼°ç»“æœ"""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"enhanced_gsm8k_results_{timestamp}.json"
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False)
            
            logger.info(f"ğŸ’¾ Results saved to {filename}")
            
            # åŒæ—¶ç”Ÿæˆç®€åŒ–ç‰ˆæŠ¥å‘Š
            self._generate_summary_report(results)
            
        except Exception as e:
            logger.error(f"Error saving results: {e}")
    
    def _generate_summary_report(self, results: Dict[str, Any]):
        """ç”Ÿæˆæ‘˜è¦æŠ¥å‘Š"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        summary_file = f"enhanced_gsm8k_summary_{timestamp}.txt"
        
        try:
            with open(summary_file, 'w', encoding='utf-8') as f:
                f.write("ğŸ¯ Enhanced Mathematical Reasoning System - GSM8K Performance Report\n")
                f.write("=" * 70 + "\n\n")
                
                # æ•´ä½“æ€§èƒ½
                overall = results["overall_performance"]
                f.write(f"ğŸ“Š Overall Performance:\n")
                f.write(f"   â€¢ Accuracy: {overall['accuracy']:.1f}% ({overall['correct_answers']}/{overall['total_problems']})\n")
                f.write(f"   â€¢ Avg Processing Time: {overall['avg_processing_time']:.4f}s\n")
                f.write(f"   â€¢ Avg Reasoning Steps: {overall['avg_reasoning_steps']:.1f}\n")
                f.write(f"   â€¢ Avg Entities/Problem: {overall['avg_entities_per_problem']:.1f}\n")
                f.write(f"   â€¢ Avg Relations/Problem: {overall['avg_relations_per_problem']:.1f}\n\n")
                
                # å¤æ‚åº¦åˆ†è§£
                f.write(f"ğŸ¯ Performance by Complexity Level:\n")
                for level, stats in results["complexity_breakdown"].items():
                    f.write(f"   â€¢ {level}: {stats['accuracy']:.1f}% ({stats['correct']}/{stats['total']})\n")
                f.write("\n")
                
                # æ”¹è¿›ç‚¹
                f.write(f"ğŸ” Analysis:\n")
                if overall['accuracy'] > 20:
                    f.write(f"   âœ… Significant improvement over baseline (4.0%)\n")
                else:
                    f.write(f"   âš ï¸ Performance still needs improvement\n")
                
                f.write(f"   â€¢ System demonstrates enhanced reasoning capabilities\n")
                f.write(f"   â€¢ Processing efficiency: {overall['avg_processing_time']:.4f}s per problem\n")
                
            logger.info(f"ğŸ“ Summary report saved to {summary_file}")
            
        except Exception as e:
            logger.error(f"Error generating summary report: {e}")

def main():
    """ä¸»å‡½æ•°"""
    gsm8k_file = "Data/GSM8K/test.jsonl"
    
    if not os.path.exists(gsm8k_file):
        logger.error(f"GSM8K file not found: {gsm8k_file}")
        return
    
    # åˆ›å»ºè¯„ä¼°å™¨
    evaluator = EnhancedGSM8KPerformanceEvaluator(max_problems=50)
    
    # è¿è¡Œè¯„ä¼°
    logger.info("ğŸš€ Starting Enhanced System Evaluation on GSM8K")
    results = evaluator.evaluate_performance(gsm8k_file)
    
    if results:
        # ä¿å­˜ç»“æœ
        evaluator.save_results(results)
        
        # æ˜¾ç¤ºç»“æœæ‘˜è¦
        overall = results["overall_performance"]
        logger.info("\n" + "=" * 60)
        logger.info("ğŸ¯ ENHANCED SYSTEM EVALUATION SUMMARY")
        logger.info("=" * 60)
        logger.info(f"ğŸ“Š Overall Accuracy: {overall['accuracy']:.1f}% ({overall['correct_answers']}/{overall['total_problems']})")
        logger.info(f"â±ï¸ Avg Processing Time: {overall['avg_processing_time']:.4f}s")
        logger.info(f"ğŸ§  Avg Reasoning Steps: {overall['avg_reasoning_steps']:.1f}")
        
        # å¤æ‚åº¦åˆ†è§£
        logger.info("\nğŸ¯ Performance by Complexity:")
        for level, stats in results["complexity_breakdown"].items():
            status = "âœ…" if stats['accuracy'] > 50 else "âš ï¸" if stats['accuracy'] > 20 else "âŒ"
            logger.info(f"   {status} {level}: {stats['accuracy']:.1f}% ({stats['correct']}/{stats['total']})")
        
        logger.info("=" * 60)
        
        # ä¸ä¹‹å‰ç»“æœå¯¹æ¯”
        logger.info("ğŸ”„ Comparison with baseline:")
        logger.info(f"   â€¢ Baseline accuracy: 4.0%")
        logger.info(f"   â€¢ Enhanced accuracy: {overall['accuracy']:.1f}%")
        improvement = overall['accuracy'] - 4.0
        if improvement > 0:
            logger.info(f"   ğŸ‰ Improvement: +{improvement:.1f}%")
        else:
            logger.info(f"   âš ï¸ Change: {improvement:.1f}%")
    
    else:
        logger.error("âŒ Evaluation failed")

if __name__ == "__main__":
    main() 