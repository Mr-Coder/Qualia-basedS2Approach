"""
ç»Ÿä¸€æ•°æ®é›†åŠ è½½å·¥å…·
æ”¯æŒåŠ è½½æ‰€æœ‰æ•°å­¦æ¨ç†æ•°æ®é›†
"""

import json
import os
from pathlib import Path
from typing import Dict, List, Optional, Union


class MathDatasetLoader:
    """æ•°å­¦æ¨ç†æ•°æ®é›†ç»Ÿä¸€åŠ è½½å™¨"""
    
    def __init__(self, data_dir: str = "Data"):
        self.data_dir = Path(data_dir)
        self.available_datasets = self._scan_available_datasets()
    
    def _scan_available_datasets(self) -> Dict[str, str]:
        """æ‰«æå¯ç”¨çš„æ•°æ®é›†"""
        datasets = {}
        
        # å®šä¹‰æ•°æ®é›†æ–‡ä»¶æ˜ å°„
        dataset_files = {
            "AddSub": "AddSub/AddSub.json",
            "SingleEq": "SingleEq/SingleEq.json", 
            "MultiArith": "MultiArith/MultiArith.json",
            "GSM8K": "GSM8K/test.jsonl",
            "GSM-hard": "GSM-hard/gsmhard.jsonl",
            "SVAMP": "SVAMP/SVAMP.json",
            "AQuA": "AQuA/AQuA.json",
            "MAWPS": "MAWPS/mawps.json",
            "MathQA": "MathQA/mathqa.json",
            "MATH": "MATH/math_dataset.json",
            "Math23K": "Math23K/math23k.json",
            "ASDiv": "ASDiv/asdiv.json",
            "DIR-MWP": "DIR-MWP/dir_mwp_complete_dataset.json"
        }
        
        for name, file_path in dataset_files.items():
            full_path = self.data_dir / file_path
            if full_path.exists():
                datasets[name] = str(full_path)
        
        return datasets
    
    def list_datasets(self) -> List[str]:
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æ•°æ®é›†"""
        return list(self.available_datasets.keys())
    
    def load_dataset(self, dataset_name: str, max_samples: Optional[int] = None) -> List[Dict]:
        """
        åŠ è½½æŒ‡å®šæ•°æ®é›†
        
        Args:
            dataset_name: æ•°æ®é›†åç§°
            max_samples: æœ€å¤§æ ·æœ¬æ•°ï¼ŒNoneè¡¨ç¤ºåŠ è½½å…¨éƒ¨
            
        Returns:
            æ•°æ®é›†æ ·æœ¬åˆ—è¡¨
        """
        if dataset_name not in self.available_datasets:
            raise ValueError(f"æ•°æ®é›† '{dataset_name}' ä¸å­˜åœ¨ã€‚å¯ç”¨æ•°æ®é›†: {self.list_datasets()}")
        
        file_path = self.available_datasets[dataset_name]
        
        # æ ¹æ®æ–‡ä»¶æ‰©å±•åé€‰æ‹©åŠ è½½æ–¹æ³•
        if file_path.endswith('.jsonl'):
            data = self._load_jsonl(file_path)
        else:
            data = self._load_json(file_path)
        
        # é™åˆ¶æ ·æœ¬æ•°
        if max_samples is not None:
            data = data[:max_samples]
        
        return data
    
    def _load_json(self, file_path: str) -> List[Dict]:
        """åŠ è½½JSONæ ¼å¼æ–‡ä»¶"""
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # å¦‚æœæ˜¯å•ä¸ªå­—å…¸ï¼Œè½¬æ¢ä¸ºåˆ—è¡¨
        if isinstance(data, dict):
            return [data]
        
        return data
    
    def _load_jsonl(self, file_path: str) -> List[Dict]:
        """åŠ è½½JSONLæ ¼å¼æ–‡ä»¶"""
        data = []
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line:
                    data.append(json.loads(line))
        return data
    
    def get_dataset_info(self, dataset_name: str) -> Dict:
        """è·å–æ•°æ®é›†ä¿¡æ¯"""
        if dataset_name not in self.available_datasets:
            raise ValueError(f"æ•°æ®é›† '{dataset_name}' ä¸å­˜åœ¨")
        
        data = self.load_dataset(dataset_name, max_samples=1)
        sample = data[0] if data else {}
        
        return {
            "name": dataset_name,
            "file_path": self.available_datasets[dataset_name],
            "sample_count": len(self.load_dataset(dataset_name)),
            "sample_fields": list(sample.keys()),
            "sample_example": sample
        }
    
    def get_all_datasets_info(self) -> Dict[str, Dict]:
        """è·å–æ‰€æœ‰æ•°æ®é›†ä¿¡æ¯"""
        info = {}
        for dataset_name in self.list_datasets():
            try:
                info[dataset_name] = self.get_dataset_info(dataset_name)
            except Exception as e:
                info[dataset_name] = {"error": str(e)}
        return info
    
    def load_multiple_datasets(self, dataset_names: List[str], 
                             max_samples_per_dataset: Optional[int] = None) -> Dict[str, List[Dict]]:
        """
        åŠ è½½å¤šä¸ªæ•°æ®é›†
        
        Args:
            dataset_names: æ•°æ®é›†åç§°åˆ—è¡¨
            max_samples_per_dataset: æ¯ä¸ªæ•°æ®é›†çš„æœ€å¤§æ ·æœ¬æ•°
            
        Returns:
            å­—å…¸ï¼Œé”®ä¸ºæ•°æ®é›†åç§°ï¼Œå€¼ä¸ºæ ·æœ¬åˆ—è¡¨
        """
        datasets = {}
        for name in dataset_names:
            try:
                datasets[name] = self.load_dataset(name, max_samples_per_dataset)
            except Exception as e:
                print(f"åŠ è½½æ•°æ®é›† '{name}' å¤±è´¥: {e}")
                datasets[name] = []
        
        return datasets
    
    def create_unified_format(self, dataset_name: str) -> List[Dict]:
        """
        å°†æ•°æ®é›†è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
        
        ç»Ÿä¸€æ ¼å¼:
        {
            "id": "å”¯ä¸€æ ‡è¯†",
            "problem": "é—®é¢˜æè¿°", 
            "answer": "ç­”æ¡ˆ",
            "metadata": {"åŸå§‹å­—æ®µ": "å€¼"}
        }
        """
        data = self.load_dataset(dataset_name)
        unified_data = []
        
        for i, item in enumerate(data):
            # æå–é—®é¢˜æè¿°
            problem = self._extract_problem(item)
            
            # æå–ç­”æ¡ˆ
            answer = self._extract_answer(item)
            
            # ç”Ÿæˆç»Ÿä¸€æ ¼å¼
            unified_item = {
                "id": item.get("id", f"{dataset_name}_{i}"),
                "problem": problem,
                "answer": str(answer) if answer is not None else "",
                "dataset": dataset_name,
                "metadata": item
            }
            
            unified_data.append(unified_item)
        
        return unified_data
    
    def _extract_problem(self, item: Dict) -> str:
        """ä»æ•°æ®é¡¹ä¸­æå–é—®é¢˜æè¿°"""
        # å¸¸è§çš„é—®é¢˜å­—æ®µå
        problem_fields = ["problem", "question", "body", "text"]
        
        for field in problem_fields:
            if field in item:
                return str(item[field])
        
        # å¦‚æœæœ‰bodyå’Œquestionï¼Œç»„åˆå®ƒä»¬
        if "body" in item and "question" in item:
            return f"{item['body']} {item['question']}"
        
        return str(item)
    
    def _extract_answer(self, item: Dict) -> Union[str, int, float]:
        """ä»æ•°æ®é¡¹ä¸­æå–ç­”æ¡ˆ"""
        # å¸¸è§çš„ç­”æ¡ˆå­—æ®µå
        answer_fields = ["answer", "solution", "correct", "target"]
        
        for field in answer_fields:
            if field in item:
                return item[field]
        
        return None


def demo_usage():
    """æ¼”ç¤ºä½¿ç”¨æ–¹æ³•"""
    loader = MathDatasetLoader()
    
    print("ğŸ“Š å¯ç”¨æ•°æ®é›†:")
    for dataset in loader.list_datasets():
        print(f"  â€¢ {dataset}")
    
    print("\nğŸ” æ•°æ®é›†è¯¦ç»†ä¿¡æ¯:")
    for name, info in loader.get_all_datasets_info().items():
        if "error" not in info:
            print(f"  {name}: {info['sample_count']} ä¸ªæ ·æœ¬")
        else:
            print(f"  {name}: åŠ è½½å¤±è´¥ - {info['error']}")
    
    # åŠ è½½ç¤ºä¾‹æ•°æ®é›†
    if "Math23K" in loader.list_datasets():
        print(f"\nğŸ“– Math23K ç¤ºä¾‹:")
        samples = loader.load_dataset("Math23K", max_samples=2)
        for sample in samples:
            print(f"  é—®é¢˜: {sample.get('problem', 'N/A')}")
            print(f"  ç­”æ¡ˆ: {sample.get('answer', 'N/A')}")
            print()


if __name__ == "__main__":
    demo_usage() 