#!/usr/bin/env python3
"""
é›†æˆæ¨ç†ç®¡é“
Integrated Reasoning Pipeline
å°†å¢å¼ºç‰©ç†çº¦æŸä¼ æ’­ç½‘ç»œé›†æˆåˆ°ç°æœ‰QSÂ²+IRD+COT-DIRæ¡†æ¶ä¸­
"""

import logging
import time
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from problem_preprocessor import ProcessedProblem, ProblemPreprocessor
from qs2_semantic_analyzer import QS2SemanticAnalyzer, SemanticEntity
from ird_relation_discovery import IRDRelationDiscovery, RelationNetwork
from enhanced_physical_constraint_network import EnhancedPhysicalConstraintNetwork
from physical_property_graph import PhysicalPropertyGraphBuilder, PropertyGraph

logger = logging.getLogger(__name__)

@dataclass
class IntegratedReasoningResult:
    """é›†æˆæ¨ç†ç»“æœ"""
    success: bool
    original_problem: str
    processed_problem: ProcessedProblem
    semantic_entities: List[SemanticEntity]
    relation_network: RelationNetwork
    property_graph: PropertyGraph
    enhanced_constraints: Dict[str, Any]
    final_solution: Dict[str, Any]
    reasoning_steps: List[Dict[str, Any]]
    execution_time: float
    confidence_score: float
    error_message: Optional[str] = None

class IntegratedReasoningPipeline:
    """é›†æˆæ¨ç†ç®¡é“"""
    
    def __init__(self):
        self.logger = logging.getLogger(f"{__name__}.{self.__class__.__name__}")
        
        # åˆå§‹åŒ–å„ä¸ªç»„ä»¶
        self.preprocessor = ProblemPreprocessor()
        self.qs2_analyzer = QS2SemanticAnalyzer()
        self.ird_discovery = IRDRelationDiscovery(self.qs2_analyzer)
        self.property_graph_builder = PhysicalPropertyGraphBuilder()
        self.enhanced_constraint_network = EnhancedPhysicalConstraintNetwork()
        
        self.reasoning_history = []
        
    def solve_problem(self, problem_text: str) -> IntegratedReasoningResult:
        """
        ä½¿ç”¨é›†æˆæ¨ç†æ¡†æ¶è§£å†³æ•°å­¦é—®é¢˜
        
        Args:
            problem_text: æ•°å­¦é—®é¢˜æ–‡æœ¬
            
        Returns:
            IntegratedReasoningResult: é›†æˆæ¨ç†ç»“æœ
        """
        start_time = time.time()
        reasoning_steps = []
        
        try:
            # è¾“å…¥éªŒè¯
            is_valid, error_message = self._validate_input(problem_text)
            if not is_valid:
                self.logger.warning(f"è¾“å…¥éªŒè¯å¤±è´¥: {error_message}")
                return IntegratedReasoningResult(
                    success=False,
                    original_problem=problem_text,
                    processed_problem=ProcessedProblem(
                        original_text=problem_text,
                        cleaned_text="",
                        entities=[],
                        numbers=[],
                        complexity_score=0.0,
                        keywords=[],
                        problem_type="invalid_input"
                    ),
                    semantic_entities=[],
                    relation_network=RelationNetwork(entities=[], relations=[], network_metrics={}),
                    property_graph=PropertyGraph([], [], [], [], {}, 0.0),
                    enhanced_constraints={},
                    final_solution={},
                    reasoning_steps=[],
                    execution_time=time.time() - start_time,
                    confidence_score=0.0,
                    error_message=f"è¾“å…¥éªŒè¯å¤±è´¥: {error_message}"
                )
            
            self.logger.info(f"å¼€å§‹é›†æˆæ¨ç†æ±‚è§£: {problem_text[:50]}...")
            
            # Step 1: é—®é¢˜é¢„å¤„ç†
            step1_start = time.time()
            processed_problem = self.preprocessor.preprocess(problem_text)
            step1_time = time.time() - step1_start
            
            reasoning_steps.append({
                "step": 1,
                "name": "é—®é¢˜é¢„å¤„ç†",
                "description": "æ¸…ç†å’Œæ ‡å‡†åŒ–é—®é¢˜æ–‡æœ¬ï¼Œæå–åŸºç¡€ä¿¡æ¯",
                "execution_time": step1_time,
                "success": True,
                "output_summary": f"æå–å®ä½“{len(processed_problem.entities)}ä¸ªï¼Œæ•°å­—{len(processed_problem.numbers)}ä¸ª"
            })
            
            # Step 2: QSÂ²è¯­ä¹‰åˆ†æ
            step2_start = time.time()
            semantic_entities = self.qs2_analyzer.analyze_semantics(processed_problem)
            step2_time = time.time() - step2_start
            
            reasoning_steps.append({
                "step": 2,
                "name": "QSÂ²è¯­ä¹‰åˆ†æ",
                "description": "åŸºäºQualiaç†è®ºè¿›è¡Œæ·±åº¦è¯­ä¹‰ç†è§£",
                "execution_time": step2_time,
                "success": True,
                "output_summary": f"è¯†åˆ«è¯­ä¹‰å®ä½“{len(semantic_entities)}ä¸ªï¼Œå¹³å‡ç½®ä¿¡åº¦{sum(e.confidence for e in semantic_entities)/len(semantic_entities):.3f}"
            })
            
            # Step 3: IRDéšå«å…³ç³»å‘ç°
            step3_start = time.time()
            relation_network = self.ird_discovery.discover_relations(semantic_entities, problem_text)
            step3_time = time.time() - step3_start
            
            reasoning_steps.append({
                "step": 3,
                "name": "IRDéšå«å…³ç³»å‘ç°",
                "description": "å‘ç°å®ä½“é—´çš„éšå«å…³ç³»ç½‘ç»œ",
                "execution_time": step3_time,
                "success": True,
                "output_summary": f"å‘ç°å…³ç³»{len(relation_network.relations) if relation_network else 0}ä¸ª"
            })
            
            # Step 3.5: ç‰©æ€§å›¾è°±æ„å»º
            step35_start = time.time()
            property_graph = self.property_graph_builder.build_property_graph(
                processed_problem, semantic_entities, relation_network
            )
            step35_time = time.time() - step35_start
            
            reasoning_steps.append({
                "step": 3.5,
                "name": "ç‰©æ€§å›¾è°±æ„å»º",
                "description": "æ„å»ºåŸºäºç‰©ç†å±æ€§çš„æ¨ç†å›¾è°±",
                "execution_time": step35_time,
                "success": True,
                "output_summary": f"ç”Ÿæˆå±æ€§{len(property_graph.properties)}ä¸ªï¼Œçº¦æŸ{len(property_graph.constraints)}ä¸ª"
            })
            
            # Step 4: å¢å¼ºç‰©ç†çº¦æŸç½‘ç»œ (æ–°å¢)
            step4_start = time.time()
            enhanced_constraints = self.enhanced_constraint_network.build_enhanced_constraint_network(
                processed_problem, semantic_entities, relation_network
            )
            step4_time = time.time() - step4_start
            
            reasoning_steps.append({
                "step": 4,
                "name": "å¢å¼ºç‰©ç†çº¦æŸç½‘ç»œ",
                "description": "åº”ç”¨ç‰©ç†å®šå¾‹ç”Ÿæˆæ™ºèƒ½çº¦æŸå’Œæ±‚è§£",
                "execution_time": step4_time,
                "success": enhanced_constraints.get("success", False),
                "output_summary": f"åº”ç”¨å®šå¾‹{enhanced_constraints.get('network_metrics', {}).get('laws_applied', 0)}ä¸ªï¼Œçº¦æŸæ»¡è¶³ç‡{enhanced_constraints.get('network_metrics', {}).get('satisfaction_rate', 0):.1%}"
            })
            
            # Step 5: COT-DIRæ¨ç†é“¾æ„å»ºå’Œæ±‚è§£
            step5_start = time.time()
            final_solution = self._build_reasoning_chain_and_solve(
                processed_problem, semantic_entities, relation_network, 
                property_graph, enhanced_constraints
            )
            step5_time = time.time() - step5_start
            
            reasoning_steps.append({
                "step": 5,
                "name": "COT-DIRæ¨ç†é“¾æ„å»º",
                "description": "æ„å»ºæ€ç»´é“¾å¹¶ç”Ÿæˆæœ€ç»ˆè§£ç­”",
                "execution_time": step5_time,
                "success": final_solution.get("success", False),
                "output_summary": f"æ¨ç†ç½®ä¿¡åº¦{final_solution.get('confidence', 0):.3f}ï¼Œç­”æ¡ˆï¼š{final_solution.get('answer', 'N/A')}"
            })
            
            # Step 6: ç»¼åˆéªŒè¯å’Œè§£é‡Šç”Ÿæˆ
            step6_start = time.time()
            verification_result = self._verify_and_explain_solution(
                final_solution, enhanced_constraints, property_graph
            )
            step6_time = time.time() - step6_start
            
            reasoning_steps.append({
                "step": 6,
                "name": "ç»¼åˆéªŒè¯å’Œè§£é‡Š",
                "description": "éªŒè¯è§£ç­”åˆç†æ€§å¹¶ç”Ÿæˆè¯¦ç»†è§£é‡Š",
                "execution_time": step6_time,
                "success": verification_result.get("verified", False),
                "output_summary": f"éªŒè¯é€šè¿‡ç‡{verification_result.get('verification_score', 0):.1%}"
            })
            
            # è®¡ç®—ç»¼åˆç½®ä¿¡åº¦
            confidence_score = self._calculate_overall_confidence(
                semantic_entities, relation_network, property_graph, 
                enhanced_constraints, final_solution
            )
            
            total_time = time.time() - start_time
            
            # æ›´æ–°æœ€ç»ˆè§£ç­”
            final_solution.update(verification_result)
            final_solution["enhanced_constraint_analysis"] = enhanced_constraints
            
            result = IntegratedReasoningResult(
                success=True,
                original_problem=problem_text,
                processed_problem=processed_problem,
                semantic_entities=semantic_entities,
                relation_network=relation_network,
                property_graph=property_graph,
                enhanced_constraints=enhanced_constraints,
                final_solution=final_solution,
                reasoning_steps=reasoning_steps,
                execution_time=total_time,
                confidence_score=confidence_score
            )
            
            self.reasoning_history.append(result)
            self.logger.info(f"é›†æˆæ¨ç†å®Œæˆï¼Œæ€»è€—æ—¶: {total_time:.3f}ç§’ï¼Œç½®ä¿¡åº¦: {confidence_score:.3f}")
            
            return result
            
        except Exception as e:
            self.logger.error(f"é›†æˆæ¨ç†å¤±è´¥: {e}")
            
            return IntegratedReasoningResult(
                success=False,
                original_problem=problem_text,
                processed_problem=ProcessedProblem(
                    original_text=problem_text,
                    cleaned_text="",
                    entities=[],
                    numbers=[],
                    complexity_score=0.0,
                    keywords=[],
                    problem_type="processing_error"
                ),
                semantic_entities=[],
                relation_network=RelationNetwork([]),
                property_graph=PropertyGraph([], [], [], [], {}, 0.0),
                enhanced_constraints={},
                final_solution={},
                reasoning_steps=reasoning_steps,
                execution_time=time.time() - start_time,
                confidence_score=0.0,
                error_message=str(e)
            )
    
    def _build_reasoning_chain_and_solve(self, processed_problem: ProcessedProblem,
                                       semantic_entities: List[SemanticEntity],
                                       relation_network: RelationNetwork,
                                       property_graph: PropertyGraph,
                                       enhanced_constraints: Dict[str, Any]) -> Dict[str, Any]:
        """æ„å»ºæ¨ç†é“¾å¹¶æ±‚è§£"""
        
        try:
            # åŸºç¡€æ•°å­¦è¿ç®—æ£€æµ‹
            if any(keyword in processed_problem.cleaned_text for keyword in ["å¤šå°‘", "æ€»å…±", "ä¸€å…±"]):
                numbers = processed_problem.numbers
                if len(numbers) >= 2:
                    # æ£€æŸ¥çº¦æŸæ˜¯å¦æ”¯æŒç®€å•åŠ æ³•
                    if enhanced_constraints.get("success", False):
                        constraint_solution = enhanced_constraints.get("constraint_solution", {})
                        if constraint_solution.get("success", False):
                            # çº¦æŸæ»¡è¶³ï¼Œæ‰§è¡Œè®¡ç®—
                            if "åŠ " in processed_problem.cleaned_text or "ä¹°" in processed_problem.cleaned_text:
                                answer = sum(numbers)
                            elif "å‡" in processed_problem.cleaned_text or "è¿˜å‰©" in processed_problem.cleaned_text:
                                answer = numbers[0] - sum(numbers[1:])
                            elif "ä¹˜" in processed_problem.cleaned_text or "å€" in processed_problem.cleaned_text:
                                answer = numbers[0] * numbers[1]
                            elif "é™¤" in processed_problem.cleaned_text or "åˆ†" in processed_problem.cleaned_text:
                                answer = numbers[0] / numbers[1] if numbers[1] != 0 else 0
                            else:
                                answer = sum(numbers)
                            
                            return {
                                "success": True,
                                "answer": answer,
                                "confidence": constraint_solution.get("confidence", 0.8),
                                "reasoning_method": "constraint_guided_arithmetic",
                                "solution_steps": [
                                    f"è¯†åˆ«æ•°å­—: {numbers}",
                                    f"ç‰©ç†çº¦æŸéªŒè¯é€šè¿‡",
                                    f"æ‰§è¡Œè®¡ç®—: {answer}",
                                    f"çº¦æŸæ»¡è¶³ç‡: {enhanced_constraints.get('network_metrics', {}).get('satisfaction_rate', 0):.1%}"
                                ]
                            }
            
            # å¦‚æœçº¦æŸæ±‚è§£å¤±è´¥ï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•
            numbers = processed_problem.numbers
            if numbers:
                answer = sum(numbers)  # ç®€åŒ–æ±‚è§£
                return {
                    "success": True,
                    "answer": answer,
                    "confidence": 0.6,
                    "reasoning_method": "fallback_arithmetic",
                    "solution_steps": [
                        f"çº¦æŸæ±‚è§£å¤±è´¥ï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•",
                        f"è®¡ç®—ç»“æœ: {answer}"
                    ]
                }
            
            return {
                "success": False,
                "answer": None,
                "confidence": 0.0,
                "reasoning_method": "failed",
                "solution_steps": ["æ— æ³•è¯†åˆ«æœ‰æ•ˆçš„æ•°å­¦è¿ç®—"]
            }
            
        except Exception as e:
            self.logger.error(f"æ¨ç†é“¾æ„å»ºå¤±è´¥: {e}")
            return {
                "success": False,
                "answer": None,
                "confidence": 0.0,
                "error": str(e)
            }
    
    def _verify_and_explain_solution(self, solution: Dict[str, Any],
                                   enhanced_constraints: Dict[str, Any],
                                   property_graph: PropertyGraph) -> Dict[str, Any]:
        """éªŒè¯å’Œè§£é‡Šè§£ç­”"""
        
        verification_checks = []
        verification_score = 0.0
        
        try:
            # æ£€æŸ¥åŸºç¡€è§£ç­”æœ‰æ•ˆæ€§
            if solution.get("success", False) and solution.get("answer") is not None:
                verification_checks.append({
                    "check": "åŸºç¡€è§£ç­”æœ‰æ•ˆæ€§",
                    "passed": True,
                    "details": f"æˆåŠŸç”Ÿæˆç­”æ¡ˆ: {solution['answer']}"
                })
                verification_score += 0.3
            else:
                verification_checks.append({
                    "check": "åŸºç¡€è§£ç­”æœ‰æ•ˆæ€§",
                    "passed": False,
                    "details": "æœªèƒ½ç”Ÿæˆæœ‰æ•ˆç­”æ¡ˆ"
                })
            
            # æ£€æŸ¥ç‰©ç†çº¦æŸä¸€è‡´æ€§
            if enhanced_constraints.get("success", False):
                constraint_solution = enhanced_constraints.get("constraint_solution", {})
                if constraint_solution.get("success", False):
                    verification_checks.append({
                        "check": "ç‰©ç†çº¦æŸä¸€è‡´æ€§",
                        "passed": True,
                        "details": f"çº¦æŸæ»¡è¶³ç‡: {enhanced_constraints.get('network_metrics', {}).get('satisfaction_rate', 0):.1%}"
                    })
                    verification_score += 0.4
                else:
                    verification_checks.append({
                        "check": "ç‰©ç†çº¦æŸä¸€è‡´æ€§",
                        "passed": False,
                        "details": f"å‘ç°{len(constraint_solution.get('violations', []))}ä¸ªçº¦æŸè¿èƒŒ"
                    })
            
            # æ£€æŸ¥å›¾è°±ä¸€è‡´æ€§
            if property_graph.consistency_score > 0.7:
                verification_checks.append({
                    "check": "å›¾è°±ä¸€è‡´æ€§",
                    "passed": True,
                    "details": f"ä¸€è‡´æ€§å¾—åˆ†: {property_graph.consistency_score:.3f}"
                })
                verification_score += 0.3
            else:
                verification_checks.append({
                    "check": "å›¾è°±ä¸€è‡´æ€§",
                    "passed": False,
                    "details": f"ä¸€è‡´æ€§å¾—åˆ†åä½: {property_graph.consistency_score:.3f}"
                })
            
            return {
                "verified": verification_score >= 0.6,
                "verification_score": verification_score,
                "verification_checks": verification_checks,
                "explanation": self._generate_solution_explanation(
                    solution, enhanced_constraints, verification_checks
                )
            }
            
        except Exception as e:
            self.logger.error(f"è§£ç­”éªŒè¯å¤±è´¥: {e}")
            return {
                "verified": False,
                "verification_score": 0.0,
                "verification_checks": [],
                "error": str(e)
            }
    
    def _generate_solution_explanation(self, solution: Dict[str, Any],
                                     enhanced_constraints: Dict[str, Any],
                                     verification_checks: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ç”Ÿæˆè§£ç­”è§£é‡Š"""
        
        explanation = {
            "solution_summary": f"ç­”æ¡ˆ: {solution.get('answer', 'N/A')}",
            "reasoning_method": solution.get('reasoning_method', 'æœªçŸ¥'),
            "confidence_analysis": f"æ•´ä½“ç½®ä¿¡åº¦: {solution.get('confidence', 0):.3f}",
            "physics_insights": [],
            "verification_summary": f"éªŒè¯é€šè¿‡: {len([c for c in verification_checks if c['passed']])}/{len(verification_checks)}é¡¹æ£€æŸ¥"
        }
        
        # æ·»åŠ ç‰©ç†çº¦æŸæ´å¯Ÿ
        if enhanced_constraints.get("physics_explanation"):
            physics_exp = enhanced_constraints["physics_explanation"]
            explanation["physics_insights"] = [
                f"åº”ç”¨ç‰©ç†å®šå¾‹: {len(physics_exp.get('physics_reasoning', []))}ä¸ª",
                f"ç”Ÿæˆçº¦æŸæ¡ä»¶: {len(physics_exp.get('constraint_explanations', []))}ä¸ª",
                physics_exp.get("solution_justification", "")
            ]
        
        return explanation
    
    def _validate_input(self, problem_text: str) -> Tuple[bool, Optional[str]]:
        """è¾“å…¥éªŒè¯"""
        
        # æ£€æŸ¥ç©ºè¾“å…¥
        if not problem_text or not problem_text.strip():
            return False, "è¾“å…¥ä¸èƒ½ä¸ºç©º"
        
        # æ£€æŸ¥é•¿åº¦
        if len(problem_text.strip()) < 5:
            return False, "è¾“å…¥è¿‡çŸ­ï¼Œæ— æ³•åˆ†æ"
        
        if len(problem_text) > 1000:
            return False, "è¾“å…¥è¿‡é•¿ï¼Œè¯·ç®€åŒ–é—®é¢˜"
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ•°å­—ï¼ˆæ•°å­¦é—®é¢˜çš„åŸºæœ¬è¦æ±‚ï¼‰
        import re
        has_numbers = bool(re.search(r'\d', problem_text))
        if not has_numbers:
            return False, "æœªæ£€æµ‹åˆ°æ•°å­—ï¼Œè¿™å¯èƒ½ä¸æ˜¯æ•°å­¦é—®é¢˜"
        
        # æ£€æŸ¥å±é™©å­—ç¬¦
        dangerous_patterns = ['<script', 'javascript:', 'eval(', 'exec(']
        for pattern in dangerous_patterns:
            if pattern.lower() in problem_text.lower():
                return False, "è¾“å…¥åŒ…å«ä¸å®‰å…¨å†…å®¹"
        
        return True, None
    
    def _safe_division(self, numerator: float, denominator: float, default: float = 0.0) -> float:
        """å®‰å…¨é™¤æ³•ï¼Œé¿å…é™¤é›¶é”™è¯¯"""
        try:
            if denominator == 0:
                self.logger.warning(f"é™¤é›¶æ“ä½œ: {numerator} / {denominator}ï¼Œè¿”å›é»˜è®¤å€¼ {default}")
                return default
            return numerator / denominator
        except (ZeroDivisionError, TypeError) as e:
            self.logger.warning(f"é™¤æ³•è¿ç®—é”™è¯¯: {e}ï¼Œè¿”å›é»˜è®¤å€¼ {default}")
            return default

    def _calculate_overall_confidence(self, semantic_entities: List[SemanticEntity],
                                    relation_network: RelationNetwork,
                                    property_graph: PropertyGraph,
                                    enhanced_constraints: Dict[str, Any],
                                    final_solution: Dict[str, Any]) -> float:
        """è®¡ç®—æ•´ä½“ç½®ä¿¡åº¦ - ä¼˜åŒ–ç‰ˆæœ¬"""
        
        try:
            # è¯­ä¹‰åˆ†æç½®ä¿¡åº¦ (35% - è¿›ä¸€æ­¥æé«˜æƒé‡)
            if semantic_entities:
                semantic_confidence = self._safe_division(
                    sum(e.confidence for e in semantic_entities), 
                    len(semantic_entities), 
                    0.6  # æé«˜é»˜è®¤å€¼
                )
                # å¢åŠ è¯­ä¹‰å®ä½“æ•°é‡çš„å¥–åŠ±
                entity_count_bonus = min(len(semantic_entities) / 8, 0.15)  # æé«˜å¥–åŠ±åˆ°15%
                semantic_confidence = min(semantic_confidence + entity_count_bonus, 1.0)
                
                # æ ¹æ®é—®é¢˜å¤æ‚åº¦è°ƒæ•´
                if len(semantic_entities) >= 3:
                    semantic_confidence = min(semantic_confidence + 0.05, 1.0)
            else:
                semantic_confidence = 0.2  # æé«˜æœ€ä½åˆ†
            
            # å…³ç³»ç½‘ç»œç½®ä¿¡åº¦ (20%)
            if relation_network and relation_network.relations:
                relation_confidence = self._safe_division(
                    sum(r.strength for r in relation_network.relations), 
                    len(relation_network.relations), 
                    0.5
                )
                # å¢åŠ å…³ç³»æ•°é‡çš„å¥–åŠ±
                relation_count_bonus = min(len(relation_network.relations) / 20, 0.1)  # æœ€å¤š10%å¥–åŠ±
                relation_confidence = min(relation_confidence + relation_count_bonus, 1.0)
            else:
                relation_confidence = 0.6  # æé«˜é»˜è®¤å€¼
            
            # ç‰©æ€§å›¾è°±ç½®ä¿¡åº¦ (25% - æé«˜æƒé‡)
            graph_confidence = property_graph.consistency_score if property_graph else 0.0
            if property_graph and property_graph.constraints:
                # å¢åŠ çº¦æŸæ•°é‡çš„å¥–åŠ±
                constraint_bonus = min(len(property_graph.constraints) / 15, 0.15)
                graph_confidence = min(graph_confidence + constraint_bonus, 1.0)
            
            # çº¦æŸæ±‚è§£ç½®ä¿¡åº¦ (30% - è°ƒæ•´æƒé‡)
            constraint_solution = enhanced_constraints.get("constraint_solution", {})
            constraint_confidence = constraint_solution.get("confidence", 0.3)  # æé«˜é»˜è®¤å€¼
            
            # å¢åŠ çº¦æŸæ»¡è¶³ç‡çš„å¥–åŠ±
            if enhanced_constraints.get("success", False):
                satisfaction_rate = enhanced_constraints.get("network_metrics", {}).get("satisfaction_rate", 0)
                if satisfaction_rate >= 1.0:
                    constraint_confidence = min(constraint_confidence + 0.25, 1.0)  # å®Œç¾æ»¡è¶³ç‡å¥–åŠ±
                elif satisfaction_rate > 0.9:
                    constraint_confidence = min(constraint_confidence + 0.2, 1.0)  # é«˜æ»¡è¶³ç‡å¥–åŠ±
                elif satisfaction_rate > 0.7:
                    constraint_confidence = min(constraint_confidence + 0.15, 1.0)  # ä¸­ç­‰æ»¡è¶³ç‡å¥–åŠ±
                
                # æ ¹æ®åº”ç”¨å®šå¾‹æ•°é‡ç»™äºˆå¥–åŠ±
                laws_applied = enhanced_constraints.get("network_metrics", {}).get("laws_applied", 0)
                if laws_applied >= 3:
                    constraint_confidence = min(constraint_confidence + 0.1, 1.0)
            
            # æœ€ç»ˆè§£ç­”ç½®ä¿¡åº¦æƒé‡ä¿æŒè¾ƒä½ (10%)
            solution_confidence = final_solution.get("confidence", 0)
            
            # é‡æ–°è°ƒæ•´æƒé‡åˆ†é… - ä¼˜åŒ–ç‰ˆæœ¬
            overall_confidence = (
                semantic_confidence * 0.35 +    # æé«˜åˆ°35%
                relation_confidence * 0.20 +    # ä¿æŒ20%
                graph_confidence * 0.20 +       # è°ƒæ•´åˆ°20%
                constraint_confidence * 0.30 +  # è°ƒæ•´åˆ°30%
                solution_confidence * 0.15       # æé«˜åˆ°15%
            )
            
            # æ·»åŠ é—®é¢˜ç±»å‹ç‰¹å®šçš„ç½®ä¿¡åº¦åŠ æˆ
            if final_solution.get("reasoning_method") == "constraint_guided_arithmetic":
                overall_confidence = min(overall_confidence + 0.1, 1.0)  # çº¦æŸå¼•å¯¼ç®—æœ¯å¥–åŠ±
            
            # æ·»åŠ å…¨å±€ä¸€è‡´æ€§å¥–åŠ±
            physical_validation = enhanced_constraints.get("physical_validation", {})
            if physical_validation.get("is_physically_consistent", False):
                consistency_bonus = physical_validation.get("consistency_score", 0) * 0.1
                overall_confidence = min(overall_confidence + consistency_bonus, 1.0)
            
            # ç¡®ä¿ç½®ä¿¡åº¦åœ¨åˆç†èŒƒå›´å†…
            overall_confidence = min(max(overall_confidence, 0.0), 1.0)
            
            self.logger.debug(f"ç½®ä¿¡åº¦åˆ†è§£: è¯­ä¹‰={semantic_confidence:.3f}, å…³ç³»={relation_confidence:.3f}, "
                            f"å›¾è°±={graph_confidence:.3f}, çº¦æŸ={constraint_confidence:.3f}, "
                            f"è§£ç­”={solution_confidence:.3f}, æ€»ä½“={overall_confidence:.3f}")
            
            return overall_confidence
            
        except Exception as e:
            self.logger.warning(f"ç½®ä¿¡åº¦è®¡ç®—å¤±è´¥: {e}")
            return 0.6  # æé«˜é»˜è®¤å€¼
    
    def get_reasoning_history(self) -> List[IntegratedReasoningResult]:
        """è·å–æ¨ç†å†å²"""
        return self.reasoning_history
    
    def clear_history(self):
        """æ¸…ç©ºæ¨ç†å†å²"""
        self.reasoning_history.clear()

# æµ‹è¯•å‡½æ•°
def test_integrated_pipeline():
    """æµ‹è¯•é›†æˆæ¨ç†ç®¡é“"""
    
    pipeline = IntegratedReasoningPipeline()
    
    test_problems = [
        "å°æ˜æœ‰5ä¸ªè‹¹æœï¼Œå°çº¢æœ‰3ä¸ªè‹¹æœï¼Œä»–ä»¬ä¸€å…±æœ‰å¤šå°‘ä¸ªè‹¹æœï¼Ÿ",
        "ä¸€ä¸ªç­çº§æœ‰30ä¸ªå­¦ç”Ÿï¼Œå…¶ä¸­15ä¸ªæ˜¯ç”·ç”Ÿï¼Œå¥³ç”Ÿæœ‰å¤šå°‘ä¸ªï¼Ÿ",
        "å•†åº—é‡Œæœ‰45ä¸ªæ©™å­ï¼Œå–æ‰äº†18ä¸ªï¼Œè¿˜å‰©å¤šå°‘ä¸ªæ©™å­ï¼Ÿ"
    ]
    
    print("ğŸ§ª é›†æˆæ¨ç†ç®¡é“æµ‹è¯•")
    print("=" * 60)
    
    for i, problem in enumerate(test_problems, 1):
        print(f"\næµ‹è¯•é—®é¢˜ {i}: {problem}")
        print("-" * 40)
        
        result = pipeline.solve_problem(problem)
        
        print(f"æ±‚è§£æˆåŠŸ: {result.success}")
        print(f"æœ€ç»ˆç­”æ¡ˆ: {result.final_solution.get('answer', 'N/A')}")
        print(f"æ•´ä½“ç½®ä¿¡åº¦: {result.confidence_score:.3f}")
        print(f"æ‰§è¡Œæ—¶é—´: {result.execution_time:.3f}ç§’")
        
        print(f"\næ¨ç†æ­¥éª¤:")
        for step in result.reasoning_steps:
            status = "âœ…" if step["success"] else "âŒ"
            print(f"  {status} Step {step['step']}: {step['name']} ({step['execution_time']:.3f}s)")
            print(f"     {step['output_summary']}")
        
        if result.enhanced_constraints.get("success"):
            metrics = result.enhanced_constraints.get("network_metrics", {})
            print(f"\nçº¦æŸç½‘ç»œåˆ†æ:")
            print(f"  åº”ç”¨å®šå¾‹: {metrics.get('laws_applied', 0)}ä¸ª")
            print(f"  ç”Ÿæˆçº¦æŸ: {metrics.get('constraints_count', 0)}ä¸ª")
            print(f"  æ»¡è¶³ç‡: {metrics.get('satisfaction_rate', 0):.1%}")
    
    print(f"\næ¨ç†å†å²: {len(pipeline.get_reasoning_history())}ä¸ªé—®é¢˜")

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    test_integrated_pipeline()