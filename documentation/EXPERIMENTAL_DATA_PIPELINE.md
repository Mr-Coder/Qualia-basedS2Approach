# å®éªŒæ•°æ®æµç¨‹ç®¡é“ (Experimental Data Pipeline)

ä»åŸå§‹æ•°æ®é›†åˆ°è®ºæ–‡è¡¨æ ¼ç»“æœçš„å®Œæ•´æ•°æ®å¤„ç†æµç¨‹

## ğŸ”„ æ•°æ®æµç¨‹æ€»è§ˆ

```
åŸå§‹æ•°æ®é›† â†’ æ•°æ®åŠ è½½ â†’ é¢„å¤„ç† â†’ å®éªŒè¯„ä¼° â†’ ç»“æœç»Ÿè®¡ â†’ è¡¨æ ¼ç”Ÿæˆ
   â†“           â†“         â†“         â†“         â†“         â†“
 Data/       DatasetLoader  Processors  Evaluators  Analysis   Tables
```

## ğŸ“ 1. åŸå§‹æ•°æ®é›†æ¥æº

### 1.1 æ•°æ®é›†æ–‡ä»¶ä½ç½®
```
Data/
â”œâ”€â”€ Math23K/       - ä¸­æ–‡æ•°å­¦é¢˜ (23,162é¢˜)
â”œâ”€â”€ GSM8K/         - è‹±æ–‡å°å­¦é¢˜ (8,500é¢˜)  
â”œâ”€â”€ MAWPS/         - å¤šé¢†åŸŸé¢˜ (2,373é¢˜)
â”œâ”€â”€ MathQA/        - ç«èµ›é¢˜ (37,297é¢˜)
â”œâ”€â”€ MATH/          - ç«èµ›é¢˜ (12,500é¢˜)
â”œâ”€â”€ SVAMP/         - å°å­¦é¢˜ (1,000é¢˜)
â”œâ”€â”€ ASDiv/         - å°å­¦é¢˜ (2,305é¢˜)
â””â”€â”€ DIR-MWP-Test/  - ä¸“é—¨æµ‹è¯•é›† (1,200é¢˜)
```

### 1.2 åŸå§‹æ•°æ®æ ¼å¼ç¤ºä¾‹
```json
// GSM8K åŸå§‹æ ¼å¼
{
  "question": "Natalia sold clips to 48 of her friends...",
  "answer": "Natalia sold 48/2 = 24 clips..."
}

// Math23K åŸå§‹æ ¼å¼  
{
  "id": "1",
  "text": "å­¦æ ¡ä¹°æ¥6ç®±ç‰›å¥¶...", 
  "equation": "x=6*12*5",
  "answer": "360"
}
```

## ğŸ”§ 2. æ•°æ®åŠ è½½ä¸æ ‡å‡†åŒ–

### 2.1 DatasetLoader å¤„ç†
**æ–‡ä»¶**: `src/processors/dataset_loader.py`

```python
class DatasetLoader:
    def load_math23k(self, file_path: str) -> List[Dict]:
        # 1. è¯»å–åŸå§‹JSON/JSONLæ–‡ä»¶
        # 2. æ ‡å‡†åŒ–æ•°æ®æ ¼å¼
        # 3. æå–å…³é”®å­—æ®µ: question, equation, answer
        # 4. æ·»åŠ å…ƒæ•°æ®: dataset, language, domain
```

**æ ‡å‡†åŒ–è¾“å‡ºæ ¼å¼**:
```json
{
  "question": "æ ‡å‡†åŒ–çš„é—®é¢˜æ–‡æœ¬",
  "equation": "æå–çš„æ•°å­¦æ–¹ç¨‹",
  "answer": "æ ‡å‡†åŒ–çš„ç­”æ¡ˆ",
  "dataset": "GSM8K",
  "language": "en",
  "domain": "elementary"
}
```

## ğŸ§  3. æ•°æ®é¢„å¤„ç†

### 3.1 NLP å¤„ç†
**æ–‡ä»¶**: `src/processors/nlp_processor.py`

```python
class NLPProcessor:
    def process_text(self, text: str) -> ProcessedText:
        # 1. ä¸­æ–‡åˆ†è¯/è‹±æ–‡æ ‡è®°åŒ–
        # 2. è¯æ€§æ ‡æ³¨ (POS tagging)
        # 3. ä¾å­˜å¥æ³•åˆ†æ
        # 4. å‘½åå®ä½“è¯†åˆ« (NER)
        # 5. è¯­ä¹‰è§’è‰²æ ‡æ³¨
```

**å¤„ç†ç»“æœ**:
```json
{
  "raw_text": "åŸå§‹æ–‡æœ¬",
  "segmentation": ["åˆ†", "è¯", "ç»“", "æœ"],
  "pos_tags": ["n", "v", "adj"],
  "dependencies": [["word1", "nsubj", "word2"]],
  "ner_tags": ["PERSON", "O", "NUMBER"],
  "semantic_roles": {"agent": "...", "theme": "..."}
}
```

### 3.2 å¤æ‚åº¦åˆ†ç±»
**æ–‡ä»¶**: `src/processors/complexity_classifier.py`

```python
class ComplexityClassifier:
    def classify_problem_complexity(self, text: str) -> str:
        # åŸºäºéšå¼å…³ç³»æ·±åº¦(Î´)å’Œæ¨ç†æ­¥éª¤(Îº)åˆ†ç±»
        # L0: Î´=0, Îº=0 (æ˜¾å¼é—®é¢˜)
        # L1: Î´=1, Îºâ‰¤1 (æµ…å±‚éšå¼)  
        # L2: 1<Î´â‰¤3, Îºâ‰¤2 (ä¸­ç­‰éšå¼)
        # L3: Î´>3 æˆ– Îº>2 (æ·±åº¦éšå¼)
```

### 3.3 éšå¼å…³ç³»æ ‡æ³¨
**æ–‡ä»¶**: `src/processors/implicit_relation_annotator.py`

```python
class ImplicitRelationAnnotator:
    def annotate_implicit_relations(self, text: str) -> List[Dict]:
        # è¯†åˆ«6ç§å…³ç³»ç±»å‹:
        # 1. æ•°å­¦è¿ç®—å…³ç³» (35.2%)
        # 2. å•ä½è½¬æ¢å…³ç³» (18.7%)
        # 3. ç‰©ç†çº¦æŸå…³ç³» (16.4%)
        # 4. æ—¶é—´å…³ç³» (12.3%)
        # 5. å‡ ä½•å±æ€§å…³ç³» (10.8%)
        # 6. æ¯”ä¾‹å…³ç³» (6.6%)
```

## ğŸ§ª 4. å®éªŒè¯„ä¼°æµç¨‹

### 4.1 æ–¹æ³•æ‰§è¡Œ
å¯¹æ¯ä¸ªæ•°æ®é›†è¿è¡Œ7ç§æ–¹æ³•:

```python
methods = [
    "Claude-3.5-Sonnet",
    "GPT-4o", 
    "Qwen2.5-Math-72B",
    "InternLM2.5-Math-7B",
    "DeepSeek-Math-7B",
    "ToRA-13B",
    "COT-DIR"  # æˆ‘ä»¬çš„æ–¹æ³•
]

for method in methods:
    for dataset in datasets:
        results = evaluate_method_on_dataset(method, dataset)
```

### 4.2 æ€§èƒ½è¯„ä¼°
**æ–‡ä»¶**: `src/evaluators/performance_evaluator.py`

```python
class PerformanceEvaluator:
    def evaluate_overall_accuracy(self, predictions, ground_truth):
        # è®¡ç®—æ•´ä½“å‡†ç¡®ç‡
        
    def evaluate_by_complexity_level(self, predictions, ground_truth, levels):
        # æŒ‰L0-L3å¤æ‚åº¦çº§åˆ«è¯„ä¼°
        
    def calculate_robustness_score(self, level_results):
        # è®¡ç®—é²æ£’æ€§è¯„åˆ†
```

### 4.3 å…³ç³»å‘ç°è¯„ä¼°
**æ–‡ä»¶**: `src/evaluators/relation_discovery_evaluator.py`

```python
class RelationDiscoveryEvaluator:
    def evaluate_relation_discovery(self, discovered, true_relations):
        # è®¡ç®—ç²¾åº¦ã€å¬å›ç‡ã€F1åˆ†æ•°
        # è¯„ä¼°è¯­ä¹‰å‡†ç¡®æ€§
        # ç»Ÿè®¡å…³ç³»å‘ç°æ•°é‡
```

### 4.4 æ¨ç†é“¾è´¨é‡è¯„ä¼°  
**æ–‡ä»¶**: `src/evaluators/reasoning_chain_evaluator.py`

```python
class ReasoningChainEvaluator:
    def evaluate_reasoning_quality(self, reasoning_chain):
        # 5ä¸ªç»´åº¦è¯„ä¼°:
        # 1. é€»è¾‘æ­£ç¡®æ€§
        # 2. å®Œæ•´æ€§  
        # 3. è¿è´¯æ€§
        # 4. æ•ˆç‡
        # 5. å¯éªŒè¯æ€§
```

## ğŸ“Š 5. ç»“æœç»Ÿè®¡ä¸åˆ†æ

### 5.1 å®éªŒç»“æœæ”¶é›†
å®éªŒå®Œæˆåï¼Œæ”¶é›†æ‰€æœ‰ç»“æœæ•°æ®:

```python
# æ”¶é›†æ€§èƒ½æ•°æ®
performance_results = {}
for method in methods:
    for dataset in datasets:
        accuracy = calculate_accuracy(method, dataset)
        performance_results[method][dataset] = accuracy

# æ”¶é›†å¤æ‚åº¦æ€§èƒ½
complexity_results = {}
for method in methods:
    for level in ["L0", "L1", "L2", "L3"]:
        accuracy = calculate_complexity_accuracy(method, level)
        complexity_results[method][level] = accuracy
```

### 5.2 ç»Ÿè®¡åˆ†æ
**æ–‡ä»¶**: `src/data/performance_analysis.py`

å°†å®éªŒç»“æœæ•´ç†æˆç»“æ„åŒ–æ•°æ®:

```python
PERFORMANCE_DATA = {
    "COT-DIR": MethodPerformance(
        method_name="COT-DIR",
        math23k=87.3,  # å®éªŒå¾—å‡ºçš„å‡†ç¡®ç‡
        gsm8k=91.2,
        mawps=94.1,
        # ... å…¶ä»–æ•°æ®é›†ç»“æœ
    )
}

COMPLEXITY_PERFORMANCE = {
    "COT-DIR": ComplexityPerformance(
        method_name="COT-DIR", 
        l0_explicit=95.1,  # L0çº§åˆ«å‡†ç¡®ç‡
        l1_shallow=90.7,   # L1çº§åˆ«å‡†ç¡®ç‡
        l2_medium=83.4,    # L2çº§åˆ«å‡†ç¡®ç‡
        l3_deep=73.2,      # L3çº§åˆ«å‡†ç¡®ç‡
        robustness_score=0.82  # è®¡ç®—å¾—å‡ºçš„é²æ£’æ€§
    )
}
```

## ğŸ“‹ 6. è¡¨æ ¼ç”Ÿæˆ

### 6.1 Table 3: æ•°æ®é›†ç‰¹å¾ç»Ÿè®¡
**æ•°æ®æ¥æº**: å¯¹åŸå§‹æ•°æ®é›†çš„ç»Ÿè®¡åˆ†æ

```python
# 1. ç»Ÿè®¡æ•°æ®é›†è§„æ¨¡
dataset_size = len(load_dataset(dataset_name))

# 2. åˆ†æå¤æ‚åº¦åˆ†å¸ƒ
complexity_dist = complexity_classifier.analyze_dataset(dataset)

# 3. è®¡ç®—DIRè¯„åˆ†
dir_score = complexity_classifier.calculate_dir_score(dataset)

# 4. ç”ŸæˆTable 3æ•°æ®
DATASET_CHARACTERISTICS = {
    "Math23K": DatasetInfo(
        name="Math23K",
        size=23162,  # ç»Ÿè®¡å¾—å‡º
        language="Chinese",  # äººå·¥æ ‡æ³¨
        domain="Elementary",  # äººå·¥æ ‡æ³¨  
        l0_percent=38.2,  # å¤æ‚åº¦åˆ†æå¾—å‡º
        l1_percent=31.4,
        l2_percent=19.7, 
        l3_percent=10.7,
        dir_score=2.03  # è®¡ç®—å¾—å‡º
    )
}
```

### 6.2 Table 4: æ€§èƒ½å¯¹æ¯”
**æ•°æ®æ¥æº**: 7ç§æ–¹æ³•åœ¨8ä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœ

```python
# å®éªŒæµç¨‹
for method in methods:
    for dataset in datasets:
        # 1. åŠ è½½æ•°æ®é›†
        data = dataset_loader.load_dataset(dataset)
        
        # 2. è¿è¡Œæ–¹æ³•
        predictions = run_method(method, data)
        
        # 3. è¯„ä¼°æ€§èƒ½
        accuracy = performance_evaluator.evaluate(predictions, ground_truth)
        
        # 4. è®°å½•ç»“æœ
        PERFORMANCE_DATA[method].dataset = accuracy
```

### 6.3 Table 5: å¤æ‚åº¦æ€§èƒ½åˆ†æ
**æ•°æ®æ¥æº**: æŒ‰å¤æ‚åº¦çº§åˆ«åˆ†å±‚çš„æ€§èƒ½è¯„ä¼°

```python
# æŒ‰å¤æ‚åº¦åˆ†å±‚è¯„ä¼°
for method in methods:
    level_results = {}
    for level in ["L0", "L1", "L2", "L3"]:
        # 1. ç­›é€‰ç‰¹å®šå¤æ‚åº¦çº§åˆ«çš„é—®é¢˜
        level_problems = filter_by_complexity(dataset, level)
        
        # 2. è¿è¡Œæ–¹æ³•å¹¶è¯„ä¼°
        predictions = run_method(method, level_problems)
        accuracy = evaluate_accuracy(predictions, ground_truth)
        level_results[level] = accuracy
    
    # 3. è®¡ç®—é²æ£’æ€§è¯„åˆ†
    robustness = calculate_robustness(level_results)
    
    COMPLEXITY_PERFORMANCE[method] = ComplexityPerformance(
        l0_explicit=level_results["L0"],
        l1_shallow=level_results["L1"], 
        l2_medium=level_results["L2"],
        l3_deep=level_results["L3"],
        robustness_score=robustness
    )
```

### 6.4 Table 6-10: ä¸“é¡¹è¯„ä¼°
**æ•°æ®æ¥æº**: ç‰¹å®šè¯„ä¼°å™¨çš„å®éªŒç»“æœ

```python
# Table 6: å…³ç³»å‘ç°è´¨é‡
relation_evaluator = RelationDiscoveryEvaluator()
for method in methods:
    discovered_relations = extract_relations(method, dataset)
    metrics = relation_evaluator.evaluate(discovered_relations, true_relations)
    RELATION_DISCOVERY_DATA[method] = metrics

# Table 7: æ¨ç†é“¾è´¨é‡  
reasoning_evaluator = ReasoningChainEvaluator()
for method in methods:
    reasoning_chains = extract_reasoning(method, dataset)
    quality = reasoning_evaluator.evaluate(reasoning_chains)
    REASONING_CHAIN_DATA[method] = quality

# Table 8: æ¶ˆèç ”ç©¶
ablation_configs = ["COT-DIR (Full)", "w/o IRD", "w/o MLR", "w/o CV"]
for config in ablation_configs:
    results = run_ablation_experiment(config, dataset)
    ABLATION_DATA[config] = results
```

## ğŸ”„ 7. æ•°æ®éªŒè¯ä¸ä¸€è‡´æ€§æ£€æŸ¥

### 7.1 æ•°æ®å®Œæ•´æ€§æ£€æŸ¥
```python
def validate_experimental_data():
    # 1. æ£€æŸ¥æ‰€æœ‰æ–¹æ³•åœ¨æ‰€æœ‰æ•°æ®é›†ä¸Šéƒ½æœ‰ç»“æœ
    for method in methods:
        for dataset in datasets:
            assert method in PERFORMANCE_DATA
            assert hasattr(PERFORMANCE_DATA[method], dataset.lower())
    
    # 2. æ£€æŸ¥å¤æ‚åº¦æ•°æ®ä¸€è‡´æ€§
    for method in COMPLEXITY_PERFORMANCE:
        levels = ["l0_explicit", "l1_shallow", "l2_medium", "l3_deep"]
        for level in levels:
            assert hasattr(COMPLEXITY_PERFORMANCE[method], level)
    
    # 3. éªŒè¯æ•°å€¼èŒƒå›´åˆç†æ€§
    for method_data in PERFORMANCE_DATA.values():
        for dataset_score in [method_data.math23k, method_data.gsm8k, ...]:
            assert 0 <= dataset_score <= 100  # å‡†ç¡®ç‡åº”åœ¨0-100%
```

## ğŸ“ˆ 8. æœ€ç»ˆæ•°æ®è¾“å‡º

### 8.1 æºæ•°æ®æ–‡ä»¶
é€šè¿‡ `generate_source_data_files.py` ç”Ÿæˆ:

```python
# ä»å®éªŒæ•°æ®æ¨¡å—å¯¼å…¥
from src.data.performance_analysis import PERFORMANCE_DATA, COMPLEXITY_PERFORMANCE
from src.data.dataset_characteristics import DATASET_CHARACTERISTICS

# ç”Ÿæˆå¤šç§æ ¼å¼çš„æºæ•°æ®æ–‡ä»¶
generate_table3_source_data()  # æ•°æ®é›†ç‰¹å¾
generate_table4_source_data()  # æ€§èƒ½å¯¹æ¯”
generate_table5_source_data()  # å¤æ‚åº¦åˆ†æ
# ... å…¶ä»–è¡¨æ ¼
```

### 8.2 è®ºæ–‡è¡¨æ ¼
é€šè¿‡ `tables/` æ¨¡å—ç”ŸæˆLaTeXã€Markdownç­‰æ ¼å¼çš„æœ€ç»ˆè¡¨æ ¼ã€‚

## ğŸ¯ æ€»ç»“

**å®Œæ•´æ•°æ®æµç¨‹**:
1. **åŸå§‹æ•°æ®** (`Data/`) â†’ å„ç§æ ¼å¼çš„æ•°å­¦é¢˜æ•°æ®é›†
2. **æ•°æ®åŠ è½½** (`DatasetLoader`) â†’ æ ‡å‡†åŒ–çš„é—®é¢˜-ç­”æ¡ˆå¯¹
3. **é¢„å¤„ç†** (`NLPProcessor`, `ComplexityClassifier`) â†’ å¤æ‚åº¦æ ‡æ³¨å’Œç‰¹å¾æå–
4. **å®éªŒæ‰§è¡Œ** â†’ 7ç§æ–¹æ³•åœ¨8ä¸ªæ•°æ®é›†ä¸Šè¿è¡Œ
5. **è¯„ä¼°ç»Ÿè®¡** (`Evaluators`) â†’ å¤šç»´åº¦æ€§èƒ½æŒ‡æ ‡è®¡ç®—
6. **æ•°æ®æ•´ç†** (`src/data/`) â†’ ç»“æ„åŒ–çš„å®éªŒç»“æœæ•°æ®
7. **è¡¨æ ¼ç”Ÿæˆ** (`tables/`, `generate_source_data_files.py`) â†’ è®ºæ–‡ä¸­çš„æœ€ç»ˆè¡¨æ ¼

**å…³é”®ç‰¹ç‚¹**:
- **å¯é‡ç°æ€§**: æ‰€æœ‰å®éªŒæ­¥éª¤éƒ½æœ‰å¯¹åº”çš„ä»£ç æ¨¡å—
- **æ•°æ®æº¯æº**: æ¯ä¸ªè¡¨æ ¼æ•°æ®éƒ½èƒ½è¿½æº¯åˆ°åŸå§‹å®éªŒç»“æœ
- **æ¨¡å—åŒ–è®¾è®¡**: å„ä¸ªå¤„ç†æ­¥éª¤ç›¸äº’ç‹¬ç«‹ï¼Œä¾¿äºè°ƒè¯•å’Œæ‰©å±•
- **å¤šæ ¼å¼æ”¯æŒ**: åŒä¸€ä»½å®éªŒæ•°æ®å¯ä»¥è¾“å‡ºå¤šç§æ ¼å¼çš„è¡¨æ ¼

è¿™å°±æ˜¯ä»åŸå§‹æ•°æ®é›†åˆ°è®ºæ–‡è¡¨æ ¼çš„å®Œæ•´**å®éªŒæ•°æ®ç®¡é“**ï¼ 