"""
ğŸ“Š Batch Processor - æ‰¹é‡å¤„ç†å’Œè´¨é‡è¯„ä¼°
æ ‡å‡†åŒ–æµç¨‹ï¼Œæ™ºèƒ½è´¨é‡æ§åˆ¶å’Œè¯„ä¼°ç³»ç»Ÿ
"""

import asyncio
import json
import logging
import statistics
import time
from collections import defaultdict
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor
from dataclasses import asdict, dataclass
from datetime import datetime, timedelta
from enum import Enum
from pathlib import Path
from typing import Any, Callable, Dict, List, Optional, Tuple, Union

import numpy as np


class ProcessingStatus(Enum):
    """å¤„ç†çŠ¶æ€"""
    PENDING = "å¾…å¤„ç†"
    PROCESSING = "å¤„ç†ä¸­"
    COMPLETED = "å·²å®Œæˆ"
    FAILED = "å¤±è´¥"
    CANCELLED = "å·²å–æ¶ˆ"


class QualityLevel(Enum):
    """è´¨é‡ç­‰çº§"""
    EXCELLENT = "ä¼˜ç§€"     # 90-100%
    GOOD = "è‰¯å¥½"          # 70-89%
    AVERAGE = "ä¸€èˆ¬"       # 50-69%
    POOR = "è¾ƒå·®"          # 30-49%
    UNACCEPTABLE = "ä¸å¯æ¥å—"  # 0-29%


@dataclass
class BatchJob:
    """æ‰¹å¤„ç†ä»»åŠ¡"""
    job_id: str
    name: str
    input_data: List[Any]
    processor_config: Dict[str, Any]
    status: ProcessingStatus = ProcessingStatus.PENDING
    created_at: datetime = None
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None
    progress: float = 0.0
    results: List[Any] = None
    errors: List[str] = None
    quality_metrics: Dict[str, float] = None
    
    def __post_init__(self):
        if self.created_at is None:
            self.created_at = datetime.now()
        if self.results is None:
            self.results = []
        if self.errors is None:
            self.errors = []
        if self.quality_metrics is None:
            self.quality_metrics = {}


@dataclass
class QualityMetrics:
    """è´¨é‡æŒ‡æ ‡"""
    accuracy: float = 0.0
    completeness: float = 0.0
    consistency: float = 0.0
    processing_time: float = 0.0
    error_rate: float = 0.0
    overall_score: float = 0.0
    quality_level: QualityLevel = QualityLevel.UNACCEPTABLE
    recommendations: List[str] = None
    
    def __post_init__(self):
        if self.recommendations is None:
            self.recommendations = []


@dataclass
class ProcessingReport:
    """å¤„ç†æŠ¥å‘Š"""
    job_id: str
    total_items: int
    processed_items: int
    successful_items: int
    failed_items: int
    processing_time: float
    average_time_per_item: float
    quality_metrics: QualityMetrics
    error_summary: Dict[str, int]
    performance_stats: Dict[str, float]
    generated_at: datetime = None
    
    def __post_init__(self):
        if self.generated_at is None:
            self.generated_at = datetime.now()


class BatchProcessor:
    """ğŸ“Š æ‰¹é‡å¤„ç†å™¨"""
    
    def __init__(self, 
                 max_workers: int = 4,
                 use_multiprocessing: bool = False,
                 quality_threshold: float = 0.7,
                 enable_monitoring: bool = True):
        """
        åˆå§‹åŒ–æ‰¹é‡å¤„ç†å™¨
        
        Args:
            max_workers: æœ€å¤§å·¥ä½œçº¿ç¨‹/è¿›ç¨‹æ•°
            use_multiprocessing: æ˜¯å¦ä½¿ç”¨å¤šè¿›ç¨‹
            quality_threshold: è´¨é‡é˜ˆå€¼
            enable_monitoring: æ˜¯å¦å¯ç”¨ç›‘æ§
        """
        self.max_workers = max_workers
        self.use_multiprocessing = use_multiprocessing
        self.quality_threshold = quality_threshold
        self.enable_monitoring = enable_monitoring
        
        # æ‰§è¡Œå™¨
        if use_multiprocessing:
            self.executor = ProcessPoolExecutor(max_workers=max_workers)
        else:
            self.executor = ThreadPoolExecutor(max_workers=max_workers)
        
        # ä»»åŠ¡ç®¡ç†
        self.jobs: Dict[str, BatchJob] = {}
        self.processing_queue = []
        self.completed_jobs = []
        
        # è´¨é‡è¯„ä¼°å™¨
        self.quality_evaluators: Dict[str, Callable] = {}
        self._setup_default_evaluators()
        
        # ç›‘æ§æ•°æ®
        self.performance_stats = {
            'total_jobs': 0,
            'total_items_processed': 0,
            'average_processing_time': 0.0,
            'error_rate': 0.0,
            'quality_distribution': defaultdict(int)
        }
        
        # è®¾ç½®æ—¥å¿—
        self._setup_logging()
        
        print(f"ğŸ“Š æ‰¹é‡å¤„ç†å™¨å·²åˆå§‹åŒ– (å·¥ä½œè€…: {max_workers}, å¤šè¿›ç¨‹: {use_multiprocessing})")
    
    def _setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        self.logger = logging.getLogger('BatchProcessor')
        self.logger.setLevel(logging.INFO)
        
        if not self.logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            self.logger.addHandler(handler)
    
    def _setup_default_evaluators(self):
        """è®¾ç½®é»˜è®¤è´¨é‡è¯„ä¼°å™¨"""
        self.quality_evaluators = {
            'math_problem_solver': self._evaluate_math_solution_quality,
            'classification': self._evaluate_classification_quality,
            'general': self._evaluate_general_quality
        }
    
    def submit_job(self, 
                   name: str,
                   input_data: List[Any],
                   processor_func: Callable,
                   processor_config: Optional[Dict] = None,
                   quality_evaluator: Optional[str] = None) -> str:
        """
        ğŸ“¤ æäº¤æ‰¹å¤„ç†ä»»åŠ¡
        
        Args:
            name: ä»»åŠ¡åç§°
            input_data: è¾“å…¥æ•°æ®
            processor_func: å¤„ç†å‡½æ•°
            processor_config: å¤„ç†å™¨é…ç½®
            quality_evaluator: è´¨é‡è¯„ä¼°å™¨åç§°
            
        Returns:
            ä»»åŠ¡ID
        """
        job_id = f"job_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{len(self.jobs)}"
        
        if processor_config is None:
            processor_config = {}
        
        processor_config['processor_func'] = processor_func
        processor_config['quality_evaluator'] = quality_evaluator or 'general'
        
        job = BatchJob(
            job_id=job_id,
            name=name,
            input_data=input_data,
            processor_config=processor_config
        )
        
        self.jobs[job_id] = job
        self.processing_queue.append(job_id)
        
        self.logger.info(f"ğŸ“¤ æäº¤ä»»åŠ¡: {name} (ID: {job_id}, æ•°æ®é‡: {len(input_data)})")
        
        return job_id
    
    async def process_job_async(self, job_id: str) -> ProcessingReport:
        """ğŸ”„ å¼‚æ­¥å¤„ç†ä»»åŠ¡"""
        if job_id not in self.jobs:
            raise ValueError(f"ä»»åŠ¡ {job_id} ä¸å­˜åœ¨")
        
        job = self.jobs[job_id]
        
        try:
            # æ›´æ–°çŠ¶æ€
            job.status = ProcessingStatus.PROCESSING
            job.started_at = datetime.now()
            
            self.logger.info(f"ğŸ”„ å¼€å§‹å¤„ç†ä»»åŠ¡: {job.name}")
            
            # è·å–å¤„ç†å‡½æ•°å’Œé…ç½®
            processor_func = job.processor_config['processor_func']
            quality_evaluator = job.processor_config.get('quality_evaluator', 'general')
            
            # æ‰¹é‡å¤„ç†
            results = []
            errors = []
            
            total_items = len(job.input_data)
            processed_count = 0
            
            # ä½¿ç”¨æ‰§è¡Œå™¨å¹¶è¡Œå¤„ç†
            tasks = []
            batch_size = min(self.max_workers * 2, total_items)
            
            for i in range(0, total_items, batch_size):
                batch = job.input_data[i:i + batch_size]
                if self.use_multiprocessing:
                    # å¤šè¿›ç¨‹å¤„ç†
                    future = self.executor.submit(self._process_batch, batch, processor_func)
                else:
                    # å¤šçº¿ç¨‹å¤„ç†
                    future = self.executor.submit(self._process_batch, batch, processor_func)
                tasks.append((i, future))
            
            # æ”¶é›†ç»“æœ
            for batch_start, future in tasks:
                try:
                    batch_results, batch_errors = future.result(timeout=300)  # 5åˆ†é’Ÿè¶…æ—¶
                    results.extend(batch_results)
                    errors.extend(batch_errors)
                    
                    processed_count += len(batch_results) + len(batch_errors)
                    job.progress = processed_count / total_items
                    
                    if self.enable_monitoring:
                        self.logger.info(f"  è¿›åº¦: {job.progress:.1%} ({processed_count}/{total_items})")
                
                except Exception as e:
                    error_msg = f"æ‰¹æ¬¡å¤„ç†å¤±è´¥: {str(e)}"
                    errors.append(error_msg)
                    self.logger.error(error_msg)
            
            # æ›´æ–°ä»»åŠ¡ç»“æœ
            job.results = results
            job.errors = errors
            job.completed_at = datetime.now()
            job.status = ProcessingStatus.COMPLETED
            
            # è´¨é‡è¯„ä¼°
            quality_metrics = self._evaluate_job_quality(job, quality_evaluator)
            job.quality_metrics = asdict(quality_metrics)
            
            # ç”ŸæˆæŠ¥å‘Š
            report = self._generate_report(job)
            
            # æ›´æ–°ç»Ÿè®¡
            self._update_performance_stats(report)
            
            self.completed_jobs.append(job_id)
            if job_id in self.processing_queue:
                self.processing_queue.remove(job_id)
            
            self.logger.info(f"âœ… ä»»åŠ¡å®Œæˆ: {job.name} (è´¨é‡: {quality_metrics.quality_level.value})")
            
            return report
            
        except Exception as e:
            job.status = ProcessingStatus.FAILED
            job.errors.append(f"ä»»åŠ¡å¤„ç†å¤±è´¥: {str(e)}")
            job.completed_at = datetime.now()
            
            self.logger.error(f"âŒ ä»»åŠ¡å¤±è´¥: {job.name} - {str(e)}")
            raise
    
    def process_job(self, job_id: str) -> ProcessingReport:
        """ğŸ”„ åŒæ­¥å¤„ç†ä»»åŠ¡"""
        return asyncio.run(self.process_job_async(job_id))
    
    def _process_batch(self, batch_data: List[Any], processor_func: Callable) -> Tuple[List[Any], List[str]]:
        """å¤„ç†æ•°æ®æ‰¹æ¬¡"""
        results = []
        errors = []
        
        for item in batch_data:
            try:
                result = processor_func(item)
                results.append(result)
            except Exception as e:
                error_msg = f"å¤„ç†é¡¹ç›®å¤±è´¥: {str(e)}"
                errors.append(error_msg)
        
        return results, errors
    
    def _evaluate_job_quality(self, job: BatchJob, evaluator_name: str) -> QualityMetrics:
        """è¯„ä¼°ä»»åŠ¡è´¨é‡"""
        evaluator = self.quality_evaluators.get(evaluator_name, self._evaluate_general_quality)
        
        return evaluator(job)
    
    def _evaluate_math_solution_quality(self, job: BatchJob) -> QualityMetrics:
        """è¯„ä¼°æ•°å­¦è§£é¢˜è´¨é‡"""
        total_items = len(job.input_data)
        successful_items = len(job.results)
        failed_items = len(job.errors)
        
        # è®¡ç®—åŸºæœ¬æŒ‡æ ‡
        completeness = successful_items / total_items if total_items > 0 else 0
        error_rate = failed_items / total_items if total_items > 0 else 1
        
        # åˆ†æè§£é¢˜å‡†ç¡®æ€§ï¼ˆå‡è®¾ç»“æœåŒ…å«æ­£ç¡®æ€§ä¿¡æ¯ï¼‰
        correct_solutions = 0
        for result in job.results:
            if isinstance(result, dict) and result.get('is_correct', False):
                correct_solutions += 1
        
        accuracy = correct_solutions / successful_items if successful_items > 0 else 0
        
        # å¤„ç†æ—¶é—´åˆ†æ
        processing_time = 0
        if job.started_at and job.completed_at:
            processing_time = (job.completed_at - job.started_at).total_seconds()
        
        # ä¸€è‡´æ€§è¯„ä¼°ï¼ˆè§£é¢˜æ­¥éª¤çš„å®Œæ•´æ€§ï¼‰
        consistent_solutions = 0
        for result in job.results:
            if isinstance(result, dict) and result.get('solution_steps'):
                consistent_solutions += 1
        
        consistency = consistent_solutions / successful_items if successful_items > 0 else 0
        
        # è®¡ç®—æ€»ä½“åˆ†æ•°
        overall_score = (accuracy * 0.4 + completeness * 0.3 + 
                        consistency * 0.2 + (1 - error_rate) * 0.1)
        
        # ç¡®å®šè´¨é‡ç­‰çº§
        quality_level = self._determine_quality_level(overall_score)
        
        # ç”Ÿæˆå»ºè®®
        recommendations = self._generate_quality_recommendations(
            accuracy, completeness, consistency, error_rate
        )
        
        return QualityMetrics(
            accuracy=accuracy,
            completeness=completeness,
            consistency=consistency,
            processing_time=processing_time,
            error_rate=error_rate,
            overall_score=overall_score,
            quality_level=quality_level,
            recommendations=recommendations
        )
    
    def _evaluate_classification_quality(self, job: BatchJob) -> QualityMetrics:
        """è¯„ä¼°åˆ†ç±»è´¨é‡"""
        total_items = len(job.input_data)
        successful_items = len(job.results)
        
        # åŸºæœ¬æŒ‡æ ‡
        completeness = successful_items / total_items if total_items > 0 else 0
        error_rate = len(job.errors) / total_items if total_items > 0 else 1
        
        # åˆ†ç±»ç½®ä¿¡åº¦åˆ†æ
        confidence_scores = []
        high_confidence_count = 0
        
        for result in job.results:
            if isinstance(result, dict) and 'confidence' in result:
                confidence = result['confidence']
                confidence_scores.append(confidence)
                if confidence > 0.8:
                    high_confidence_count += 1
        
        accuracy = high_confidence_count / successful_items if successful_items > 0 else 0
        consistency = statistics.mean(confidence_scores) if confidence_scores else 0
        
        # å¤„ç†æ—¶é—´
        processing_time = 0
        if job.started_at and job.completed_at:
            processing_time = (job.completed_at - job.started_at).total_seconds()
        
        overall_score = (accuracy * 0.4 + completeness * 0.3 + 
                        consistency * 0.2 + (1 - error_rate) * 0.1)
        
        quality_level = self._determine_quality_level(overall_score)
        recommendations = self._generate_quality_recommendations(
            accuracy, completeness, consistency, error_rate
        )
        
        return QualityMetrics(
            accuracy=accuracy,
            completeness=completeness,
            consistency=consistency,
            processing_time=processing_time,
            error_rate=error_rate,
            overall_score=overall_score,
            quality_level=quality_level,
            recommendations=recommendations
        )
    
    def _evaluate_general_quality(self, job: BatchJob) -> QualityMetrics:
        """è¯„ä¼°é€šç”¨è´¨é‡"""
        total_items = len(job.input_data)
        successful_items = len(job.results)
        
        completeness = successful_items / total_items if total_items > 0 else 0
        error_rate = len(job.errors) / total_items if total_items > 0 else 1
        accuracy = completeness  # å¯¹äºé€šç”¨æƒ…å†µï¼Œå®Œæˆåº¦å³å‡†ç¡®åº¦
        consistency = 1.0 if successful_items == total_items else 0.8
        
        processing_time = 0
        if job.started_at and job.completed_at:
            processing_time = (job.completed_at - job.started_at).total_seconds()
        
        overall_score = (accuracy * 0.5 + completeness * 0.3 + (1 - error_rate) * 0.2)
        quality_level = self._determine_quality_level(overall_score)
        
        return QualityMetrics(
            accuracy=accuracy,
            completeness=completeness,
            consistency=consistency,
            processing_time=processing_time,
            error_rate=error_rate,
            overall_score=overall_score,
            quality_level=quality_level,
            recommendations=[]
        )
    
    def _determine_quality_level(self, score: float) -> QualityLevel:
        """ç¡®å®šè´¨é‡ç­‰çº§"""
        if score >= 0.9:
            return QualityLevel.EXCELLENT
        elif score >= 0.7:
            return QualityLevel.GOOD
        elif score >= 0.5:
            return QualityLevel.AVERAGE
        elif score >= 0.3:
            return QualityLevel.POOR
        else:
            return QualityLevel.UNACCEPTABLE
    
    def _generate_quality_recommendations(self, accuracy: float, completeness: float, 
                                        consistency: float, error_rate: float) -> List[str]:
        """ç”Ÿæˆè´¨é‡æ”¹è¿›å»ºè®®"""
        recommendations = []
        
        if accuracy < 0.7:
            recommendations.append("å‡†ç¡®ç‡åä½ï¼Œå»ºè®®ä¼˜åŒ–ç®—æ³•æˆ–å¢åŠ è®­ç»ƒæ•°æ®")
        
        if completeness < 0.9:
            recommendations.append("å®Œæˆç‡ä¸è¶³ï¼Œå»ºè®®æ£€æŸ¥è¾“å…¥æ•°æ®è´¨é‡å’Œå¤„ç†é€»è¾‘")
        
        if consistency < 0.8:
            recommendations.append("ä¸€è‡´æ€§è¾ƒå·®ï¼Œå»ºè®®æ ‡å‡†åŒ–å¤„ç†æµç¨‹")
        
        if error_rate > 0.1:
            recommendations.append("é”™è¯¯ç‡è¾ƒé«˜ï¼Œå»ºè®®å¢å¼ºå¼‚å¸¸å¤„ç†æœºåˆ¶")
        
        return recommendations
    
    def _generate_report(self, job: BatchJob) -> ProcessingReport:
        """ç”Ÿæˆå¤„ç†æŠ¥å‘Š"""
        total_items = len(job.input_data)
        processed_items = len(job.results) + len(job.errors)
        successful_items = len(job.results)
        failed_items = len(job.errors)
        
        processing_time = 0
        if job.started_at and job.completed_at:
            processing_time = (job.completed_at - job.started_at).total_seconds()
        
        average_time_per_item = processing_time / total_items if total_items > 0 else 0
        
        # é”™è¯¯ç±»å‹ç»Ÿè®¡
        error_summary = defaultdict(int)
        for error in job.errors:
            error_type = error.split(':')[0] if ':' in error else 'Unknown'
            error_summary[error_type] += 1
        
        # æ€§èƒ½ç»Ÿè®¡
        performance_stats = {
            'throughput': total_items / processing_time if processing_time > 0 else 0,
            'success_rate': successful_items / total_items if total_items > 0 else 0,
            'error_rate': failed_items / total_items if total_items > 0 else 0
        }
        
        # æ„å»ºè´¨é‡æŒ‡æ ‡å¯¹è±¡
        quality_metrics = QualityMetrics(**job.quality_metrics) if job.quality_metrics else QualityMetrics()
        
        return ProcessingReport(
            job_id=job.job_id,
            total_items=total_items,
            processed_items=processed_items,
            successful_items=successful_items,
            failed_items=failed_items,
            processing_time=processing_time,
            average_time_per_item=average_time_per_item,
            quality_metrics=quality_metrics,
            error_summary=dict(error_summary),
            performance_stats=performance_stats
        )
    
    def _update_performance_stats(self, report: ProcessingReport):
        """æ›´æ–°æ€§èƒ½ç»Ÿè®¡"""
        self.performance_stats['total_jobs'] += 1
        self.performance_stats['total_items_processed'] += report.total_items
        
        # æ›´æ–°å¹³å‡å¤„ç†æ—¶é—´
        total_time = (self.performance_stats['average_processing_time'] * 
                     (self.performance_stats['total_jobs'] - 1) + report.processing_time)
        self.performance_stats['average_processing_time'] = total_time / self.performance_stats['total_jobs']
        
        # æ›´æ–°é”™è¯¯ç‡
        total_error_rate = (self.performance_stats['error_rate'] * 
                           (self.performance_stats['total_jobs'] - 1) + 
                           report.performance_stats['error_rate'])
        self.performance_stats['error_rate'] = total_error_rate / self.performance_stats['total_jobs']
        
        # è´¨é‡åˆ†å¸ƒ
        self.performance_stats['quality_distribution'][report.quality_metrics.quality_level.value] += 1
    
    def get_job_status(self, job_id: str) -> Dict[str, Any]:
        """ğŸ“‹ è·å–ä»»åŠ¡çŠ¶æ€"""
        if job_id not in self.jobs:
            return {"error": f"ä»»åŠ¡ {job_id} ä¸å­˜åœ¨"}
        
        job = self.jobs[job_id]
        
        return {
            "job_id": job.job_id,
            "name": job.name,
            "status": job.status.value,
            "progress": job.progress,
            "created_at": job.created_at.isoformat(),
            "started_at": job.started_at.isoformat() if job.started_at else None,
            "completed_at": job.completed_at.isoformat() if job.completed_at else None,
            "total_items": len(job.input_data),
            "processed_items": len(job.results) + len(job.errors),
            "errors_count": len(job.errors)
        }
    
    def get_performance_dashboard(self) -> Dict[str, Any]:
        """ğŸ“Š è·å–æ€§èƒ½ä»ªè¡¨æ¿"""
        return {
            "æ€»ä½“ç»Ÿè®¡": self.performance_stats,
            "æ´»è·ƒä»»åŠ¡": len([j for j in self.jobs.values() if j.status == ProcessingStatus.PROCESSING]),
            "å¾…å¤„ç†ä»»åŠ¡": len(self.processing_queue),
            "å·²å®Œæˆä»»åŠ¡": len(self.completed_jobs),
            "è´¨é‡åˆ†å¸ƒ": dict(self.performance_stats['quality_distribution'])
        }
    
    def export_report(self, job_id: str, output_path: str):
        """ğŸ’¾ å¯¼å‡ºæŠ¥å‘Š"""
        if job_id not in self.jobs:
            raise ValueError(f"ä»»åŠ¡ {job_id} ä¸å­˜åœ¨")
        
        job = self.jobs[job_id]
        if job.status != ProcessingStatus.COMPLETED:
            raise ValueError(f"ä»»åŠ¡ {job_id} å°šæœªå®Œæˆ")
        
        report = self._generate_report(job)
        
        export_data = {
            "report": asdict(report),
            "job_details": asdict(job),
            "export_time": datetime.now().isoformat()
        }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, ensure_ascii=False, indent=2, default=str)
        
        print(f"ğŸ’¾ æŠ¥å‘Šå·²å¯¼å‡ºåˆ°: {output_path}")
    
    def cleanup_completed_jobs(self, keep_recent: int = 10):
        """ğŸ§¹ æ¸…ç†å·²å®Œæˆçš„ä»»åŠ¡"""
        if len(self.completed_jobs) > keep_recent:
            to_remove = self.completed_jobs[:-keep_recent]
            for job_id in to_remove:
                if job_id in self.jobs:
                    del self.jobs[job_id]
            self.completed_jobs = self.completed_jobs[-keep_recent:]
            
            print(f"ğŸ§¹ æ¸…ç†äº† {len(to_remove)} ä¸ªå·²å®Œæˆä»»åŠ¡")
    
    def __del__(self):
        """æ¸…ç†èµ„æº"""
        if hasattr(self, 'executor'):
            self.executor.shutdown(wait=True)


# ä½¿ç”¨ç¤ºä¾‹å’Œæµ‹è¯•
def demo_batch_processor():
    """æ¼”ç¤ºæ‰¹é‡å¤„ç†å™¨"""
    print("ğŸ“Š Batch Processor Demo")
    print("=" * 50)
    
    # åˆ›å»ºå¤„ç†å™¨
    processor = BatchProcessor(max_workers=2, enable_monitoring=True)
    
    # ç¤ºä¾‹å¤„ç†å‡½æ•°
    def simple_math_processor(problem):
        """ç®€å•æ•°å­¦å¤„ç†å™¨ç¤ºä¾‹"""
        time.sleep(0.1)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
        
        if isinstance(problem, dict) and 'expression' in problem:
            try:
                result = eval(problem['expression'])
                return {
                    'problem': problem,
                    'result': result,
                    'is_correct': True,
                    'solution_steps': [f"è®¡ç®— {problem['expression']} = {result}"]
                }
            except:
                return {
                    'problem': problem,
                    'result': None,
                    'is_correct': False,
                    'error': 'è®¡ç®—å¤±è´¥'
                }
        
        return {'problem': problem, 'result': None, 'is_correct': False}
    
    # å‡†å¤‡æµ‹è¯•æ•°æ®
    test_data = [
        {'expression': '2 + 3'},
        {'expression': '5 * 4'},
        {'expression': '10 / 2'},
        {'expression': '7 - 3'},
        {'expression': '6 + 8'},
        {'expression': 'invalid'},  # æ•…æ„çš„é”™è¯¯æ•°æ®
    ]
    
    # æäº¤ä»»åŠ¡
    job_id = processor.submit_job(
        name="æ•°å­¦è®¡ç®—æµ‹è¯•",
        input_data=test_data,
        processor_func=simple_math_processor,
        quality_evaluator='math_problem_solver'
    )
    
    print(f"ğŸ“¤ æäº¤ä»»åŠ¡: {job_id}")
    
    # å¤„ç†ä»»åŠ¡
    report = processor.process_job(job_id)
    
    # æ˜¾ç¤ºç»“æœ
    print(f"\nğŸ“‹ å¤„ç†æŠ¥å‘Š:")
    print(f"  ä»»åŠ¡ID: {report.job_id}")
    print(f"  æ€»é¡¹ç›®æ•°: {report.total_items}")
    print(f"  æˆåŠŸé¡¹ç›®: {report.successful_items}")
    print(f"  å¤±è´¥é¡¹ç›®: {report.failed_items}")
    print(f"  å¤„ç†æ—¶é—´: {report.processing_time:.2f}ç§’")
    print(f"  è´¨é‡ç­‰çº§: {report.quality_metrics.quality_level.value}")
    print(f"  æ•´ä½“åˆ†æ•°: {report.quality_metrics.overall_score:.2f}")
    
    if report.quality_metrics.recommendations:
        print(f"  æ”¹è¿›å»ºè®®:")
        for rec in report.quality_metrics.recommendations:
            print(f"    - {rec}")
    
    # æ˜¾ç¤ºæ€§èƒ½ä»ªè¡¨æ¿
    dashboard = processor.get_performance_dashboard()
    print(f"\nğŸ“Š æ€§èƒ½ä»ªè¡¨æ¿:")
    for key, value in dashboard.items():
        print(f"  {key}: {value}")
    
    return processor, report


if __name__ == "__main__":
    demo_batch_processor() 