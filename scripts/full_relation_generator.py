"""
ğŸ”— COT-DIR å…¨é‡å…³ç³»è§£ç­”ç”Ÿæˆå™¨
Full Relation Generator - ä¸ºå…¨éƒ¨14,097é“é¢˜ç›®ç”ŸæˆåŸºäºå…³ç³»çš„è§£ç­”

æ ¸å¿ƒåŠŸèƒ½ï¼š
- æ˜¾æ€§å…³ç³»è¯†åˆ«
- L1/L2/L3éšå«å…³ç³»æ¨ç†
- å…³ç³»é“¾åˆ†æ
- å®Œæ•´è§£ç­”ç”Ÿæˆ
"""

import concurrent.futures
import json
import random
import re
import time
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

# å¤ç”¨å…³ç³»ç”Ÿæˆå™¨çš„æ ¸å¿ƒé€»è¾‘
from relation_based_solution_generator import RelationBasedSolutionGenerator


class FullRelationGenerator(RelationBasedSolutionGenerator):
    """å…¨é‡å…³ç³»è§£ç­”ç”Ÿæˆå™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–å…¨é‡å…³ç³»ç”Ÿæˆå™¨"""
        super().__init__()
        print("ğŸš€ åˆå§‹åŒ–COT-DIRå…¨é‡å…³ç³»è§£ç­”ç”Ÿæˆå™¨")
        print("ğŸ¯ ç›®æ ‡: ä¸ºå…¨éƒ¨14,097é“é¢˜ç›®ç”ŸæˆåŸºäºå…³ç³»çš„è§£ç­”")
    
    def process_all_problems_with_relations(self, use_parallel: bool = True, max_workers: int = 8):
        """å¤„ç†æ‰€æœ‰é¢˜ç›®å¹¶ç”Ÿæˆå…³ç³»è§£ç­”"""
        print("ğŸ”— å¼€å§‹å…¨é‡å…³ç³»è§£ç­”ç”Ÿæˆ...")
        
        # åŠ è½½åŸå§‹è§£ç­”æ•°æ®
        solution_files = list(Path(".").glob("maximum_solutions_*.json"))
        if not solution_files:
            print("âŒ æœªæ‰¾åˆ°åŸå§‹è§£ç­”æ–‡ä»¶")
            return []
        
        latest_file = max(solution_files, key=lambda p: p.stat().st_mtime)
        print(f"ğŸ“ åŠ è½½åŸå§‹è§£ç­”æ–‡ä»¶: {latest_file}")
        
        with open(latest_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
            original_solutions = data.get('solutions', [])
        
        print(f"ğŸ“Š å¼€å§‹ä¸º{len(original_solutions):,}ä¸ªé—®é¢˜ç”ŸæˆåŸºäºå…³ç³»çš„è§£ç­”...")
        
        start_time = time.time()
        relation_solutions = []
        
        if use_parallel and len(original_solutions) > 100:
            print(f"âš¡ ä½¿ç”¨{max_workers}ä¸ªå¹¶è¡Œè¿›ç¨‹å¤„ç†")
            
            # å‡†å¤‡é—®é¢˜æ•°æ®
            problems = []
            for solution in original_solutions:
                problem = {
                    'problem_id': solution.get('problem_id'),
                    'question': solution.get('question'),
                    'answer': solution.get('final_answer'),
                    'dataset_source': solution.get('dataset_source')
                }
                problems.append(problem)
            
            # å¹¶è¡Œå¤„ç†
            with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
                future_to_problem = {executor.submit(self.generate_relation_based_solution, problem): problem 
                                   for problem in problems}
                
                completed = 0
                for future in concurrent.futures.as_completed(future_to_problem):
                    relation_solution = future.result()
                    relation_solutions.append(relation_solution)
                    completed += 1
                    
                    if completed % 1000 == 0:
                        elapsed = time.time() - start_time
                        rate = completed / elapsed
                        eta = (len(problems) - completed) / rate if rate > 0 else 0
                        print(f"   è¿›åº¦: {completed:,}/{len(problems):,} ({completed/len(problems)*100:.1f}%) - "
                              f"é€Ÿåº¦: {rate:.0f}é¢˜/ç§’ - é¢„è®¡å‰©ä½™: {eta:.0f}ç§’")
        else:
            print("ğŸ”„ ä½¿ç”¨ä¸²è¡Œå¤„ç†")
            for i, solution in enumerate(original_solutions):
                problem = {
                    'problem_id': solution.get('problem_id'),
                    'question': solution.get('question'),
                    'answer': solution.get('final_answer'),
                    'dataset_source': solution.get('dataset_source')
                }
                
                relation_solution = self.generate_relation_based_solution(problem)
                relation_solutions.append(relation_solution)
                
                if (i + 1) % 1000 == 0:
                    print(f"   å·²å®Œæˆ: {i + 1}/{len(original_solutions)} é¢˜")
        
        total_time = time.time() - start_time
        
        self.processing_stats = {
            'total_processed': len(relation_solutions),
            'successful_solutions': sum(1 for s in relation_solutions if s.confidence_score > 0),
            'total_time': total_time,
            'avg_time_per_problem': total_time / len(relation_solutions) if relation_solutions else 0,
            'processing_rate': len(relation_solutions) / total_time if total_time > 0 else 0
        }
        
        self.generated_solutions = relation_solutions
        
        print(f"âœ… å…¨é‡å…³ç³»è§£ç­”ç”Ÿæˆå®Œæˆ!")
        self._print_comprehensive_relation_summary()
        
        return relation_solutions
    
    def _print_comprehensive_relation_summary(self):
        """æ‰“å°å…¨é¢çš„å…³ç³»åˆ†ææ‘˜è¦"""
        stats = self.processing_stats
        
        print(f"\nğŸ”— å…¨é‡å…³ç³»è§£ç­”ç”Ÿæˆæ‘˜è¦:")
        print("=" * 80)
        print(f"ğŸ”¢ æ€»å¤„ç†é¢˜ç›®: {stats['total_processed']:,} é¢˜")
        print(f"âœ… æˆåŠŸç”Ÿæˆè§£ç­”: {stats['successful_solutions']:,} é¢˜")
        print(f"ğŸ“ˆ æˆåŠŸç‡: {stats['successful_solutions']/stats['total_processed']*100:.1f}%")
        print(f"â±ï¸  æ€»å¤„ç†æ—¶é—´: {stats['total_time']:.1f} ç§’")
        print(f"âš¡ å¹³å‡å¤„ç†é€Ÿåº¦: {stats['processing_rate']:.0f} é¢˜/ç§’")
        print(f"ğŸ¯ å¹³å‡æ¯é¢˜æ—¶é—´: {stats['avg_time_per_problem']*1000:.2f} æ¯«ç§’")
        
        # å…³ç³»ç»Ÿè®¡
        total_explicit = sum(len(s.explicit_relations) for s in self.generated_solutions)
        total_L1 = sum(len(s.implicit_relations_L1) for s in self.generated_solutions)
        total_L2 = sum(len(s.implicit_relations_L2) for s in self.generated_solutions)
        total_L3 = sum(len(s.implicit_relations_L3) for s in self.generated_solutions)
        total_relations = total_explicit + total_L1 + total_L2 + total_L3
        
        print(f"\nğŸ” å…³ç³»å‘ç°æ€»ä½“ç»Ÿè®¡:")
        print(f"   æ˜¾æ€§å…³ç³»: {total_explicit:,} ä¸ª ({total_explicit/total_relations*100:.1f}%)")
        print(f"   L1éšå«å…³ç³»: {total_L1:,} ä¸ª ({total_L1/total_relations*100:.1f}%)")
        print(f"   L2éšå«å…³ç³»: {total_L2:,} ä¸ª ({total_L2/total_relations*100:.1f}%)")
        print(f"   L3éšå«å…³ç³»: {total_L3:,} ä¸ª ({total_L3/total_relations*100:.1f}%)")
        print(f"   å…³ç³»æ€»æ•°: {total_relations:,} ä¸ª")
        print(f"   å¹³å‡æ¯é¢˜å…³ç³»æ•°: {total_relations/len(self.generated_solutions):.1f} ä¸ª")
        
        # å±‚æ¬¡åˆ†å¸ƒè¯¦ç»†ç»Ÿè®¡
        L1_problems = sum(1 for s in self.generated_solutions if len(s.implicit_relations_L1) > 0)
        L2_problems = sum(1 for s in self.generated_solutions if len(s.implicit_relations_L2) > 0)
        L3_problems = sum(1 for s in self.generated_solutions if len(s.implicit_relations_L3) > 0)
        
        print(f"\nğŸ“Š å…³ç³»å±‚æ¬¡è¦†ç›–ç»Ÿè®¡:")
        print(f"   æ¶‰åŠL1å…³ç³»çš„é¢˜ç›®: {L1_problems:,} ({L1_problems/len(self.generated_solutions)*100:.1f}%)")
        print(f"   æ¶‰åŠL2å…³ç³»çš„é¢˜ç›®: {L2_problems:,} ({L2_problems/len(self.generated_solutions)*100:.1f}%)")
        print(f"   æ¶‰åŠL3å…³ç³»çš„é¢˜ç›®: {L3_problems:,} ({L3_problems/len(self.generated_solutions)*100:.1f}%)")
        
        # å¤æ‚åº¦åˆ†å¸ƒ
        complex_problems = sum(1 for s in self.generated_solutions 
                             if len(s.implicit_relations_L1) > 0 and len(s.implicit_relations_L2) > 0)
        advanced_problems = sum(1 for s in self.generated_solutions 
                              if len(s.implicit_relations_L1) > 0 and len(s.implicit_relations_L2) > 0 and len(s.implicit_relations_L3) > 0)
        
        print(f"\nğŸŒŸ å…³ç³»å¤æ‚åº¦åˆ†å¸ƒ:")
        print(f"   å¤æ‚é¢˜ç›® (L1+L2): {complex_problems:,} ({complex_problems/len(self.generated_solutions)*100:.1f}%)")
        print(f"   é«˜çº§é¢˜ç›® (L1+L2+L3): {advanced_problems:,} ({advanced_problems/len(self.generated_solutions)*100:.1f}%)")
        
        # æŒ‰æ•°æ®é›†çš„å…³ç³»åˆ†æ
        dataset_stats = {}
        for solution in self.generated_solutions:
            dataset = solution.dataset_source
            if dataset not in dataset_stats:
                dataset_stats[dataset] = {
                    'count': 0, 'total_relations': 0, 'L1_count': 0, 'L2_count': 0, 'L3_count': 0
                }
            
            stats_item = dataset_stats[dataset]
            stats_item['count'] += 1
            stats_item['total_relations'] += (len(solution.explicit_relations) + 
                                            len(solution.implicit_relations_L1) + 
                                            len(solution.implicit_relations_L2) + 
                                            len(solution.implicit_relations_L3))
            if len(solution.implicit_relations_L1) > 0:
                stats_item['L1_count'] += 1
            if len(solution.implicit_relations_L2) > 0:
                stats_item['L2_count'] += 1
            if len(solution.implicit_relations_L3) > 0:
                stats_item['L3_count'] += 1
        
        print(f"\nğŸ“ˆ æŒ‰æ•°æ®é›†å…³ç³»åˆ†æ (Top 8):")
        sorted_datasets = sorted(dataset_stats.items(), key=lambda x: x[1]['count'], reverse=True)[:8]
        for dataset, stats_item in sorted_datasets:
            avg_relations = stats_item['total_relations'] / stats_item['count']
            L3_rate = stats_item['L3_count'] / stats_item['count'] * 100
            print(f"   {dataset}: {stats_item['count']:,}é¢˜, å¹³å‡{avg_relations:.1f}å…³ç³»/é¢˜, L3è¦†ç›–{L3_rate:.1f}%")
    
    def save_full_relation_solutions(self, output_file: str = None):
        """ä¿å­˜å…¨é‡å…³ç³»è§£ç­”"""
        if output_file is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = f"full_relation_solutions_{timestamp}.json"
        
        print(f"ğŸ’¾ ä¿å­˜{len(self.generated_solutions):,}ä¸ªåŸºäºå…³ç³»çš„è§£ç­”åˆ° {output_file}...")
        
        solutions_data = []
        for solution in self.generated_solutions:
            solutions_data.append({
                'problem_id': solution.problem_id,
                'question': solution.question,
                'problem_type': solution.problem_type,
                'explicit_relations': solution.explicit_relations,
                'implicit_relations_L1': solution.implicit_relations_L1,
                'implicit_relations_L2': solution.implicit_relations_L2,
                'implicit_relations_L3': solution.implicit_relations_L3,
                'relation_discovery_steps': solution.relation_discovery_steps,
                'relation_reasoning_chain': solution.relation_reasoning_chain,
                'relation_based_solution_steps': solution.relation_based_solution_steps,
                'mathematical_analysis': solution.mathematical_analysis,
                'final_answer': solution.final_answer,
                'verification_process': solution.verification_process,
                'confidence_score': solution.confidence_score,
                'processing_time': solution.processing_time,
                'dataset_source': solution.dataset_source,
                'generated_at': datetime.now().isoformat()
            })
        
        # è®¡ç®—å…³ç³»ç»Ÿè®¡ä¿¡æ¯
        relation_summary = {
            'total_explicit_relations': sum(len(s.explicit_relations) for s in self.generated_solutions),
            'total_L1_relations': sum(len(s.implicit_relations_L1) for s in self.generated_solutions),
            'total_L2_relations': sum(len(s.implicit_relations_L2) for s in self.generated_solutions),
            'total_L3_relations': sum(len(s.implicit_relations_L3) for s in self.generated_solutions),
            'problems_with_L1': sum(1 for s in self.generated_solutions if len(s.implicit_relations_L1) > 0),
            'problems_with_L2': sum(1 for s in self.generated_solutions if len(s.implicit_relations_L2) > 0),
            'problems_with_L3': sum(1 for s in self.generated_solutions if len(s.implicit_relations_L3) > 0),
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump({
                'metadata': {
                    'generator_type': 'full_relation_based',
                    'total_solutions': len(solutions_data),
                    'generation_stats': self.processing_stats,
                    'relation_summary': relation_summary,
                    'generated_at': datetime.now().isoformat(),
                    'description': 'COT-DIRå…¨é‡åŸºäºå…³ç³»çš„è§£ç­”ç”Ÿæˆç»“æœ - çªå‡ºæ˜¾æ€§å…³ç³»å’ŒL1/L2/L3éšå«å…³ç³»æ¨ç†'
                },
                'solutions': solutions_data
            }, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… å·²ä¿å­˜ {len(solutions_data):,} ä¸ªåŸºäºå…³ç³»çš„è§£ç­”")
        print(f"ğŸ“ æ–‡ä»¶å¤§å°: {Path(output_file).stat().st_size / 1024 / 1024:.1f} MB")
        
        return output_file

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”— COT-DIR å…¨é‡å…³ç³»è§£ç­”ç”Ÿæˆç³»ç»Ÿ")
    print("=" * 80)
    print("ğŸ¯ ç›®æ ‡: ä¸ºå…¨éƒ¨14,097é“é¢˜ç›®ç”ŸæˆåŸºäºå…³ç³»çš„è§£ç­”")
    print("ğŸ§  æ ¸å¿ƒ: æ˜¾æ€§å…³ç³» + L1/L2/L3éšå«å…³ç³»æ¨ç†")
    print("âš¡ ç‰¹ç‚¹: å¹¶è¡Œå¤„ç†ã€å…³ç³»é“¾åˆ†æã€å¤šå±‚æ¨ç†")
    print("=" * 80)
    
    generator = FullRelationGenerator()
    
    # å¤„ç†å…¨éƒ¨é¢˜ç›®
    print("ğŸš€ å¼€å§‹å¤„ç†å…¨éƒ¨14,097é“é¢˜ç›®...")
    solutions = generator.process_all_problems_with_relations(use_parallel=True, max_workers=8)
    
    # ä¿å­˜ç»“æœ
    output_file = generator.save_full_relation_solutions()
    
    # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
    print(f"\nğŸ‰ å…¨é‡å…³ç³»è§£ç­”ç”Ÿæˆä»»åŠ¡å®Œæˆ!")
    print(f"ğŸ“Š æ€»å…±ç”Ÿæˆäº† {len(solutions):,} ä¸ªåŸºäºå…³ç³»çš„è¯¦ç»†è§£ç­”")
    print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_file}")
    print(f"ğŸ† è¿™æ˜¯COT-DIRç³»ç»Ÿå®Œæ•´çš„å…³ç³»æ¨ç†èƒ½åŠ›å±•ç¤º")

if __name__ == "__main__":
    main() 